% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  twoside,symmetric]{report}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[BoldFont=Technika-Regular,BoldItalicFont=Technika-Italic]{Latin
Modern Roman}
  \setsansfont[UprightFont = *-Light,,BoldFont = *-Regular,,ItalicFont =
*-LightItalic,,BoldItalicFont = *-Italic,]{Technika}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[a4paper,top=32mm,left=35.6mm,right=35.6mm,bottom=30mm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textbf{#1}}
\newcommand{\AnnotationTok}[1]{\textit{#1}}
\newcommand{\AttributeTok}[1]{#1}
\newcommand{\BaseNTok}[1]{#1}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textit{#1}}
\newcommand{\CommentVarTok}[1]{\textit{#1}}
\newcommand{\ConstantTok}[1]{#1}
\newcommand{\ControlFlowTok}[1]{\textbf{#1}}
\newcommand{\DataTypeTok}[1]{\underline{#1}}
\newcommand{\DecValTok}[1]{#1}
\newcommand{\DocumentationTok}[1]{\textit{#1}}
\newcommand{\ErrorTok}[1]{\textbf{#1}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{#1}
\newcommand{\FunctionTok}[1]{#1}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textit{#1}}
\newcommand{\KeywordTok}[1]{\textbf{#1}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{#1}
\newcommand{\OtherTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textbf{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{#1}
\newcommand{\SpecialStringTok}[1]{#1}
\newcommand{\StringTok}[1]{#1}
\newcommand{\VariableTok}[1]{#1}
\newcommand{\VerbatimStringTok}[1]{#1}
\newcommand{\WarningTok}[1]{\textit{#1}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\usepackage{svg}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{english}
\ifPDFTeX
\else
\babelfont{rm}[BoldFont=Technika-Regular,BoldItalicFont=Technika-Italic]{Latin
Modern Roman}
\fi
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\input{../template/style.tex}
\input{../template/front.tex}
\University{Czech Technical University in Prague}
\Faculty{Faculty of Electrical Engineering}
\Department{Department of Measurement}
\StudyProgram{Open Informatics}
\FieldOfStudy{Computer Engineering}
\Supervisor{Ing. Pavel Píša Ph.D.}
\Advisor{MSc. Arthur Cohen}
\makeatletter
\@ifpackageloaded{subfig}{}{\usepackage{subfig}}
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\captionsetup[subfloat]{margin=0.5em}
\AtBeginDocument{%
\renewcommand*\figurename{Figure}
\renewcommand*\tablename{Table}
}
\AtBeginDocument{%
\renewcommand*\listfigurename{List of Figures}
\renewcommand*\listtablename{List of Tables}
}
\newcounter{pandoccrossref@subfigures@footnote@counter}
\newenvironment{pandoccrossrefsubfigures}{%
\setcounter{pandoccrossref@subfigures@footnote@counter}{0}
\begin{figure}\centering%
\gdef\global@pandoccrossref@subfigures@footnotes{}%
\DeclareRobustCommand{\footnote}[1]{\footnotemark%
\stepcounter{pandoccrossref@subfigures@footnote@counter}%
\ifx\global@pandoccrossref@subfigures@footnotes\empty%
\gdef\global@pandoccrossref@subfigures@footnotes{{##1}}%
\else%
\g@addto@macro\global@pandoccrossref@subfigures@footnotes{, {##1}}%
\fi}}%
{\end{figure}%
\addtocounter{footnote}{-\value{pandoccrossref@subfigures@footnote@counter}}
\@for\f:=\global@pandoccrossref@subfigures@footnotes\do{\stepcounter{footnote}\footnotetext{\f}}%
\gdef\global@pandoccrossref@subfigures@footnotes{}}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
% Make links footnotes instead of hotlinks:
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
\hypersetup{
  pdftitle={Memory Safety Analysis in Rust GCC},
  pdfauthor={Jakub Dupák},
  pdflang={en},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Memory Safety Analysis in Rust GCC}
\author{Jakub Dupák}
\date{January 2024}

\begin{document}
\maketitle

\pagenumbering{roman}

\includepdf[pages=-]{Thesis_Assignment_Jakub_Dupák_Memory_safety_analysis_in_Rust_GCC.pdf}

\clearpage

\ack{I express my gratitude to Jeremy Bennett for providing me with the opportunity to work on this project. I would also like to thank Arthur Cohen and Philip Herron, the maintainers of the Rust GCC project, for their consultations and reviews, and Pavel Píša for my introduction to the professional open-source developer community. \\ Furthermore, I would like to acknowledge our entire study group, Max Hollmann, Matěj Kafka, Vojtěch Štěpančík and Jáchym Herynek, for endless technical discussions and mental support. \\ Finally, I would like to thank my family for their continuous support.}

\declaration

\abstract{This thesis presents the first attempt to implement a memory safety analysis, known as the borrow checker, within the Rust GCC compiler. It utilizes the Polonius engine, which was designed as the next-generation borrow checker for rustc. The text describes the design of this analysis, the necessary modifications of the compiler, and compares the internal representations between rustc and gccrs. This comparison highlights the challenges in adapting the rustc borrow checker design to gccrs. The thesis concludes with a discussion of the results and known limitations.}{compiler, Rust, borrow checker, static analysis, GCC, Polonius}{Tato práce představuje první pokus o realizaci analýzy paměťové bezpečnosti, nazývané borrow-checker, v překladači Rust GCC. Analýza využívá systém Polonius, který je vytvořen jako nová generace borrow-checkeru pro překladač rustc. Práce popisuje návrh analýzy, úprav překladače a porovnává vnitřní reprezentaci překladačů rustc a gccrs a poukazuje na problémy při adaptaci návrhu borrow-checkeru z překladače rustc na překladač gccrs. Práci uzavírá diskusí o výsledcích a známých omezeních.}{překladač, Rust, borrow checker, statická analýza, GCC, Polonius}

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\clearpage
\pagenumbering{arabic}

\chapter{Introduction}\label{introduction}

Rust is a modern systems programming language that aims to provide
memory safety without runtime
overhead\citeproc{ref-Matsakis2014}{{[}1{]}}. To achieve this goal, a
Rust compiler has to perform a static analysis to ensure that the memory
safety rules are not violated. This analysis is commonly called the
\emph{borrow checker}. The borrow checker is a complex analysis that has
been evolving throughout the history of the Rust language and its
reference implementation compiler, \emph{rustc}. It evolved from a
simple lexical analysis to a control-flow sensitive analysis, gradually
providing a more precise validation. The experimental version of the
rustc compiler uses a new analysis engine and algorithm called
\emph{Polonius}. The algorithm changes some fundamental views on the
internal semantics of the analysis to allow more programs to be accepted
and provides better error reporting for rejected
programs\citeproc{ref-RustBelt}{{[}2{]}}. The
\href{https://rust-lang.github.io/compiler-team/working-groups/polonius/}{Polonius
Working Group} is planning to replace the current rustc borrow checker
with one based on Polonius in the Rust language edition
2024\citeproc{ref-poloniusupdate}{{[}3{]}}.

Rust GCC, also known as gccrs, is one of the emerging alternative Rust
compilers. Unlike mrustc and rustc\_codegen\_gcc, gccrs aims to build a
complete general-purpose Rust compiler independent of rustc. Gccrs aims
to offer a rustc-compatible, drop-in replacement, capitalizing on the
mature and diverse features of the GCC infrastructure. GCC (compared to
LLVM) offers more target platforms and different optimizations and
provides security plugins (originally designed for C) that could be used
to find errors in
\href{https://doc.rust-lang.org/reference/unsafety.html}{\emph{unsafe}}
Rust code\citeproc{ref-eurorust}{{[}4{]}}. The goal of this thesis was
to start the development of a Polonius-based borrow checker in gccrs.

The first chapter introduces the problem of borrow checking. It gives a
brief overview of the development of the borrow checker in the rustc
compiler, up to the Polonius project. The second chapter describes the
Polonius analysis engine and its API. The third chapter compares the
internal representations of rustc and gccrs to highlight the challenges
of adapting the rustc borrow checker design to gccrs. The next chapter
explains the design of the borrow checker implemented in gccrs as part
of this work. It maps the experiments that lead to the current design
and describes the new intermediate representation and its usage in the
analysis. Later sections of the chapter describe other modifications of
the rest of the compiler necessary to support borrow checking. The final
chapter elaborates on the implementation, its development, the current
state and the known missing features and limitations.

\chapter{The Problem of Borrow
Checking}\label{the-problem-of-borrow-checking}

This section introduces the concept of borrow checking and traces its
development within the Rust programming language. First, it presents the
simple lexical approach, followed by an explanation of a more advanced
control-flow sensitive analysis. Finally, the section then provides an
introduction to the Polonius analysis engine, the latest approach to
borrow checking in Rust. Since this work utilizes the Polonius engine,
it is described in more detail in the following chapter.

Typical programming language implementations manage memory with dynamic
storage duration in one of two ways\footnote{Dynamic storage duration
  means that it is unknown at compile time when storage can be safely
  reclaimed. In contrast, memory with static storage duration is
  reclaimed at the end of the program, and memory with automatic storage
  duration is bound to a function call.}. Languages like C employ manual
memory management, where programmers explicitly allocate and free
memory, a method prone to errors\citeproc{ref-nsa}{{[}5{]}}. In
contrast, higher-level languages such as Java and Python use automatic
memory management, where runtime garbage collectors handle memory
management tasks.

Addressing the pitfalls of manual memory management, languages like C++
and \href{https://ziglang.org/}{Zig} have introduced tools for more
implicit memory deallocation. In simple situations, these tools tie
memory deallocation to the destruction of objects, utilizing concepts
like \href{https://en.cppreference.com/w/cpp/language/raii}{RAII},
\href{https://en.cppreference.com/w/cpp/memory\#Smart_pointers}{smart-pointers},
and \href{https://ziglang.org/documentation/master/\#defer}{defer
statements}. Here, the key difference from stack allocation is that the
ownership can be dynamically transferred between objects. In more
complex situations, where multiple objects share memory and deallocation
is tied to the last object's destruction, these languages opt-in for
runtime solutions like
\href{https://en.wikipedia.org/wiki/Reference_counting}{reference
counting}.

Despite these improvements, two serious problems remain. First,
programmers can incorrectly establish and maintain ownership binds,
especially during dynamic ownership transfers between objects. This
issue can very often occur when interfacing systems with differing
memory management models\footnote{An interface between a C++ application
  with
  \href{https://www.cppreference.com/Cpp_STL_ReferenceManual.pdf}{STL-based}
  memory management and the \href{https://www.qt.io/}{Qt GUI framework},
  where all Qt API methods take raw pointers (as opposed to smart
  pointers). Some of those methods assume that the ownership is
  transferred, and some of them do not. These methods can only be
  differentiated using their documentation.}. Second, issue appears when
the ownership is not transferred, but a copy of the pointer is used
temporarily (this is called ``borrowing'' in Rust). The assumption that
the owning object will exist for the whole time this copy is used is
often wrong. This kind of mistake is called a ``dangling
pointer.''\citeproc{ref-danglingpointer}{{[}6{]}}.

The Rust language builds on the RAII approach; however, it adds a
built-in static analysis called the borrow checker to ensure that the
errors mentioned above cannot occur. To make such an analysis feasible,
Rust only allows a conservative subset of memory-safe operations.
Furthermore, Rust adds further limitations to ensure that memory use is
safe even during multithreaded execution. Because these restrictions are
very strict and would severely limit the language, Rust provides a
feature to lift some of those restrictions in clearly denoted ``unsafe''
areas. The responsibility for maintaining the safety invariants in
``unsafe'' code falls on the programmer.

The key idea behind Rust memory safety is to strictly (using the type
system) differentiate the two problematic cases: ownership transfers and
borrowings. The ownership transfer binds all unique resources owned to
another object, detaching them from the current object. This operation
is called ``move'' in Rust (and C++). Unlike C++, Rust does not allow
objects to store a reference to themselves, simplifying the ownership
transfer semantics to just a bitwise copy. Rust static analysis also
ensures that the old object is not used after it has been ``moved
from.''

Borrowing is a temporary usage of an object without ownership transfer.
A typical example is a method call. For borrows, Rust uses static
analysis to ensure that the borrowed object cannot be deallocated while
in use (in Rust terms, the borrowed object has to \emph{outlive} the
borrow). However, since a whole-program analysis would be very
expensive, Rust performs the analysis only inside a single function. It
requires the programmer to formally describe the invariants of lifetimes
(subsets of the program where each reference has to be valid) on a
function boundary. Invariants are checked inside the function and
assumed outside the function, resulting in a safe program. The
invariants are described using what are called lifetime annotations. The
programmer can think of a lifetime annotation as an inference variable.
The variable domain represents a subset of the program (set of lines,
expressions, or control flow graph nodes). The task of the borrow
checker is to resolve each inference variable to an actual subset of the
program where the borrow is valid. This subset may not be unique. The
existence of such a subset is sufficient to prove that the program is
safe.

The annotations are related to each other by ``outlives'' relations,
which require one reference lifetime to be a subset of another lifetime.
These constraints are used to describe the relationship of the inputs
and outputs of a function, providing a simplified and conservative
description of all relevant code outside of the function.

\begin{quote}
\textbf{Example}: We have a vector-like structure (a dynamic array) and
we want to store references to integers as elements. We need to make
sure that as long as the vector exists, all references stored in it are
valid. However, we do not want the vector to own the integers. First, we
introduce a lifetime parameter \texttt{\textquotesingle{}a}, which
represents all the regions where the vector itself is alive. This
parameter will be substituted at a particular use site with a concrete
lifetime.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \DataTypeTok{Vec}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \OperatorTok{\{} \OperatorTok{...} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then, for the add method, we introduce a lifetime parameter
\texttt{\textquotesingle{}b}, which restricts the inserted reference.
This parameter is substituted with a concrete lifetime of each reference
when the method is invoked. Finally, we will require that the method can
only be used with lifetimes, for which we can guarantee that
\texttt{\textquotesingle{}b} is a subset of \texttt{\textquotesingle{}a}
(in terms of parts of the program). We do that by adding the
\texttt{\textquotesingle{}a:\ \textquotesingle{}b} constraint.
\texttt{\textquotesingle{}a:\ \textquotesingle{}b} usually reads as
``\texttt{\textquotesingle{}a} outlives '\texttt{b},'' and it means that
``'a lasts at least as long as 'b, so a reference
\texttt{\&\textquotesingle{}a\ i32} is valid whenever
\texttt{\&\textquotesingle{}b\ i32} is
valid.''\href{https://doc.rust-lang.org/reference/trait-bounds.html\#lifetime-bounds}{\citeproc{ref-reference}{{[}7{]}}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \DataTypeTok{Vec}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \OperatorTok{\{}
  \KeywordTok{fn}\NormalTok{ add}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}b}\OperatorTok{\textgreater{}} \KeywordTok{where} \OtherTok{\textquotesingle{}a}\OperatorTok{:} \OtherTok{\textquotesingle{}b}\NormalTok{ (}\OperatorTok{\&}\KeywordTok{mut} \KeywordTok{self}\OperatorTok{,}\NormalTok{ x}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}b} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{\{} \OperatorTok{...} \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\section{The Evolution of Borrow Checking in Rustc}\label{sec:evolution}

This section describes how the analysis evolved, gradually rejecting
less memory-safe programs. rustc started with lexical (scope-based
analysis), followed by the first non-lexical (CFG-based) analysis, which
is being extended by the Polonius project. This section strongly builds
upon RFC 2094\citeproc{ref-rfc2094nll}{{[}8{]}}, which introduced
non-lexical borrow checking to Rust. Examples from that RFC are
presented in this section.

The simplest variant of borrow checker is based on stack variable
scopes. A reference is valid from the point in the program (here in
terms of statements and expressions) where it is created until the end
of the current scope. This approach can be extended to handle some
common programming patterns as special cases. For example, when a
reference is created in function parameters, it is valid until the end
of the function call.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;} \CommentTok{// {-}{-}+ \textquotesingle{}scope}
\NormalTok{    capitalize(}\OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{])}\OperatorTok{;}          \CommentTok{//   |}
 \CommentTok{// \^{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{} \textquotesingle{}lifetime //   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

However, a very common modification might cause the program to be
rejected. Since the reference is not created in the list of function
arguments, but rather as a local variable, the special case does not
apply and the reference must be valid until the end of the scope of the
variable \texttt{slice}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ slice }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{]}\OperatorTok{;} \CommentTok{// \textless{}{-}+ \textquotesingle{}lifetime}
\NormalTok{    capitalize(slice)}\OperatorTok{;}         \CommentTok{//   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

Now, there is no simple way to say when the lifetime of the reference
should end to prove that his program is safe from its syntactic
structure. This code can be fixed by explicitly specifying where the
lifetime should end. However, this clutters up the code and cannot be
used for more advanced cases.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
    \OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ slice }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{]}\OperatorTok{;} \CommentTok{// \textless{}{-}+ \textquotesingle{}lifetime}
\NormalTok{        capitalize(slice)}\OperatorTok{;}         \CommentTok{//   |}
    \OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

One of those more advanced cases occurs when lifetimes are not symmetric
in conditional branches. A typical case is where a condition checks the
presence of a value. In the positive branch, we have a reference to the
value, but in the negative branch, we do not. Therefore, it is safe to
create a new reference in the negative branch. By ``safe,'' we mean that
there will be only one reference pointing to the \texttt{map} object at
any time. A convenient way to describe ``at any time'' is to use the
control flow graph (CFG) representation of the program.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut}\NormalTok{ map }\OperatorTok{=} \OperatorTok{...;}
\KeywordTok{let}\NormalTok{ key }\OperatorTok{=} \OperatorTok{...;}
\ControlFlowTok{match}\NormalTok{ map}\OperatorTok{.}\NormalTok{get\_mut(}\OperatorTok{\&}\NormalTok{key) }\OperatorTok{\{} \CommentTok{// {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+ \textquotesingle{}lifetime}
    \ConstantTok{Some}\NormalTok{(value) }\OperatorTok{=\textgreater{}}\NormalTok{ process(value)}\OperatorTok{,}     \CommentTok{// |}
    \ConstantTok{None} \OperatorTok{=\textgreater{}} \OperatorTok{\{}                          \CommentTok{// |}
\NormalTok{        map}\OperatorTok{.}\NormalTok{insert(key}\OperatorTok{,} \PreprocessorTok{V::}\KeywordTok{default}\NormalTok{())}\OperatorTok{;} \CommentTok{// |}
        \CommentTok{//  \^{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{} ERROR.              // |}
    \OperatorTok{\}}                                  \CommentTok{// |}
\OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

For more examples, see RFC 2094\citeproc{ref-rfc2094nll}{{[}8{]}}.
However, the provided examples should be sufficient to demonstrate that
analyzing the program on a control flow graph (CFG) instead of the
syntactic structure (AST) enables the borrow checker to validate and
ensure the safety of complex programs that were previously rejected.

The above analysis thinks of lifetimes as regions (set of points in CFG)
where the reference is valid. The goal of the analysis is to find the
smallest regions so that the reference is not required to be valid
outside of those regions. The smaller the regions, the more references
can coexist at the same time, allowing more programs to be accepted.

The next generation of borrow checker in Rust is based on the Polonius
analysis engine. Polonius is an extension of NLL (non-lexical
lifetimes), which is capable of proving move programs to be safe by
using a different interpretation of lifetimes.

NLL cannot handle the following code, but Polonius can handle it. The
problem here is that everything that is tied to external lifetimes
(\texttt{\textquotesingle{}a}) has to be valid for the whole function.
Since \texttt{v} is returned, it has to outlive the lifetime
\texttt{\textquotesingle{}a}. However, the lifetime of \texttt{v} is
bound to the lifetime of the reference to the hashmap it is stored in.
It forces the \texttt{map} to be borrowed (transitively) for at least
the whole function. This includes the \texttt{map.insert} call, which
needs to borrow the hashmap itself, resulting in an error. However, we
can clearly see that no reference to \texttt{map} is available in the
\texttt{None} branch. Here Polonius can help.

Instead of starting with references and figuring out where they need to
be valid, Polonius goes in the other direction and tracks what
references need to be valid at each point in the program. As we have
determined in the example above, there is no preexisting reference to
the \texttt{map} in the \texttt{None} branch.

It is important to note that only internal computations inside the
compiler are changed by this. This change does not affect the language
semantics. It only removes some limitations of the compiler.

Another significant contribution of the Polonius project is the fact
that it replaces many handwritten checks with formal logical rules.
Also, because it knows which references are conflicting, it can be used
to provide better error messages.

\chapter{Polonius Engine}\label{polonius-engine}

The Polonius engine was created by
\href{https://github.com/nikomatsakis}{Niko Matsakis} and extended by
\href{https://github.com/lqd/}{Rémy Rakic} and Albin
Stjerna\citeproc{ref-Stjerna2020}{{[}9{]}} as a next-generation
control-flow sensitive borrow checking analysis for rustc. It was
designed as an independent library that can be used both by the rustc
compiler and by different research projects, making it suitable for
usage in gccrs. Polonius interfaces with the compiler by passing around
a struct of vectors\footnote{A contiguous growable array type from the
  Rust standard library.
  (\url{https://doc.rust-lang.org/std/vec/struct.Vec.html})} of facts,
where each fact is represented by a tuple of integers\footnote{\texttt{usize}}
(or types convertible to integers). It is completely unaware of the
compiler internals.

In the previous chapter, we mentioned that Polonius differs from NLL in
its interpretation of lifetimes. Polonius uses the term ``Origin'' to
better describe the concept. An origin is a set of loans that can be
referenced using a variable at each CFG point. In other words, it tracks
where the references that are used could have originated.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ r}\OperatorTok{:} \OperatorTok{\&}\CharTok{\textquotesingle{}}\DecValTok{0} \DataTypeTok{i32} \OperatorTok{=} \ControlFlowTok{if}\NormalTok{ (cond) }\OperatorTok{\{}
    \OperatorTok{\&}\NormalTok{x }\CommentTok{/* Loan L0 */}
\OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
    \OperatorTok{\&}\NormalTok{y }\CommentTok{/* Loan L1 */}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} The origin of the reference \texttt{r} (denoted as
\texttt{\textquotesingle{}0}) is the set of loans \texttt{L0} and
\texttt{L1}. Note that this fact is initially unknown and that it is the
task of the analysis to compute it.
\end{quote}

The engine first pre-processes the input facts. It computes transitive
closures of relations and analyzes all the initializations and
deinitializations that occur over the CFG. Then, it checks for move
errors, i.e.~when ownership of some object is transferred more than
once. In the next step, the liveness of variables and the ``outlives''
graph (transitive constraints of lifetimes at each CFG point) are
computed\citeproc{ref-polonius2}{{[}10{]}}. All origins that appear in
the type of live variable are considered live.

Then Polonius needs to figure out the \emph{active loans}. A loan is
active at a CFG point if two conditions hold. Any origin that contains
the loan is live (i.e., there is a variable that might reference it),
and the variable/place referencing the loan was not reassigned. (When a
reference variable is reassigned, it points to something else.)

The compiler has to specify all the points in the control flow graph
where a loan being alive would violate the memory safety rules. Polonius
then checks whether such a situation can happen. If it can, it reports
the facts involved in the violation. For example, if a mutable loan of a
variable is alive, then any read/write/borrow operation on the variable
invalidates the loan.

\begin{figure}
\centering
\includesvg{polonius.svg}
\caption{Steps performed by Polonius to find error. (Adapted from
\citeproc{ref-Stjerna2020}{{[}9{]}}.)}
\end{figure}

\section{Polonius Facts}\label{polonius-facts}

This section provides a list of facts taken by Polonius to give the
reader a better idea of the work that the compiler needs to do. The
facts are grouped into categories and briefly described. The full list
of facts can be found in the
\href{https://github.com/rust-lang/polonius/blob/master/polonius-engine/src/facts.rs}{Polonius
source code} and the Polonius Book\citeproc{ref-polonius}{{[}11{]}}.

\begin{itemize}
\tightlist
\item
  Control flow graph edges (\texttt{cfg\_edge:\ (Point,\ Point)}).
\item
  Facts regarding variable usage and its effects.

  \begin{itemize}
  \tightlist
  \item
    \texttt{var\_used\_at:\ (Variable,\ Point)} - Any usage of a
    variable except for a drop (destructor).
  \item
    \texttt{var\_defined\_at:\ (Variable,\ Point)} - Start of scope or
    reassignment. This reassignment treatment makes the variable act
    similarly to an
    \href{https://en.wikipedia.org/wiki/Static_single-assignment_form}{SSA
    variable}.
  \item
    \texttt{var\_dropped\_at:\ (Variable,\ Point)} - Drop (destructor
    call) of the variable.
  \item
    \texttt{use\_of\_var\_derefs\_origin:\ (Variable,\ Origin)} - The
    type of the variable contains the origin.
  \item
    \texttt{drop\_of\_var\_derefs\_origin:\ (Variable,\ Origin)} - When
    the drop implementation used the origin.
  \end{itemize}
\item
  Facts regarding paths and their usages. Paths represent indirect or
  partial access to a variable (e.g., field access or cast).

  \begin{itemize}
  \tightlist
  \item
    \texttt{path\_is\_var:\ (Path,\ Variable)} - Lists ``trivial'' paths
    that are just a variable.
  \item
    \texttt{child\_path:\ (Path,\ Path)} - Describes hierarchical
    (nontransitive) relationships between paths. For example, a field
    path is a child path of the variable path from which it is accessed.
  \item
    \texttt{path\_assigned\_at\_base:\ (Path,\ Point)} - The path is
    assigned at the CFG point. ``base'' means that this fact is emitted
    only for the exact path used, not all its parent paths.
  \item
    \texttt{path\_moved\_at\_base:\ (Path,\ Point)} - Ownership of
    origins is transferred at the CFG point.
  \item
    \texttt{path\_accessed\_at\_base:\ (Path,\ Point)} - Any memory
    access to the path (read or write).
  \end{itemize}
\item
  Facts about relationships (subset relation) of origins.

  \begin{itemize}
  \tightlist
  \item
    \texttt{known\_placeholder\_subset:\ (Origin,\ Origin)} -
    Constraints on universal origins (those representing loans that
    happened outside the function).
  \item
    \texttt{universal\_region:\ (Origin)} - List of universal origins.
    (See the previous point.)
  \item
    \texttt{subset\_base:\ (Origin,\ Origin)} - Any relationship between
    origins required by the subtyping rules.
  \item
    \texttt{placeholder:\ (Origin,\ Loan)} - Associates an origin with a
    loan.
  \end{itemize}
\item
  Facts about loans.

  \begin{itemize}
  \tightlist
  \item
    \texttt{loan\_issued\_at:\ (Loan,\ Point)} - Result of borrow
    expression.
  \item
    \texttt{loan\_killed\_at:\ (Loan,\ Point)} - Loan is no longer live
    after this point.
  \item
    \texttt{loan\_invalidated\_at:\ (Loan,\ Point)} - If the loan is
    live at this point, it is an error.
  \end{itemize}
\end{itemize}

\chapter{Comparison of Internal
Representations}\label{comparison-of-internal-representations}

The execution of a borrow checker with an external analysis engine
consists of two steps. First, we need to collect the relevant
information about the program. We will call that information
\emph{facts}. Second, we need to send those facts to the external engine
and process them. Before we can discuss the \emph{collection} of facts
itself, we need to understand how programs are represented inside the
compiler. We will use the term \emph{internal representation} (IR) to
refer to the representation of the program inside the compiler. We will
compare the IRs used by rustc and gccrs to highlight the differences
between the two compilers. This will help us understand the challenges
of adapting the borrow checker design from rustc to gccrs. First, we
will describe the IRs used by rustc and then compare them with those
used in gccrs.

\section{GCC and LLVM}\label{gcc-and-llvm}

To understand the differences between each of the compilers, we must
first explore the differences between the compiler platforms on which
they are built (GCC and LLVM). We will only focus on the middle-end of
each platform, since the back-end does not influence the front-end
directly.

The core of LLVM is a three-address code (3-AD)\footnote{Three-address
  code represents the program as sequences of statements (we call such
  sequence a \emph{basic block}), connected by control flow
  instructions, forming a control flow graph (CFG).} representation,
called the \emph{LLVM intermediate representation} (LLVM IR)
\citeproc{ref-llvm}{{[}12{]}}, llvm-ir. This IR is the interface between
front-ends and the compiler platform (the middle-end and the back-end).
Each front-end is responsible for transforming its custom AST
IR\footnote{The abstract syntax tree (AST) is a data structure that is
  used to represent the structure of the program. It is the direct
  product of program parsing. For example, an expression
  \texttt{1\ +\ (2\ -\ 7)} would be represented as a node
  \texttt{subtraction}, with the left child being the number one and the
  right child being the AST for the subexpression \texttt{(2\ -\ 7)}.}
into the LLVM IR. The LLVM IR is stable and strictly separated from the
front-end; therefore, it cannot be easily extended to include
language-specific constructs.

\begin{figure}
\centering
\includesvg[width=0.9\textwidth,height=\textheight]{llvm-ir-cfg-example.svg}
\caption{LLVM IR CFG Example (generated by Compiler Explorer)}
\end{figure}

GCC, on the other hand, interfaces with the front-ends using a
tree-based representation called GENERIC\citeproc{ref-gccint}{{[}13, p.
175{]}}. GENERIC was created as a generalized form of AST shared by most
front-ends. GCC provides a set of common tree nodes to describe all the
standard language constructs in the GENERIC IR. Front-ends may define
language-specific constructs and provide hooks for their
handling.\citeproc{ref-gccint}{{[}13, p. 212{]}} This representation is
then transformed into the GIMPLE representation, which is
mostly\footnote{``GIMPLE that is not fully lowered is known as `High
  GIMPLE' and consists of the IL before the \texttt{pass\_lower\_cf}.
  High GIMPLE contains some container statements such as lexical scopes
  and nested expressions, while ``Low GIMPLE'' exposes all of the
  implicit jumps for control and exception expressions directly in the
  IL and EH region trees.''\citeproc{ref-gccint}{{[}13, p. 225{]}}} a
3-AD representation. It does so by breaking down expressions into a
sequence of statements and introducing temporary variables. This
transformation is done inside the compiler platform, not in the
front-end. This approach makes the front-ends smaller and shifts more
work into the shared part. The GIMPLE representation does not contain
information specific to each front-end (programming language). However,
it is possible to store language-specific information in GIMPLE by
adding entirely new statements.\citeproc{ref-gccint}{{[}13, p. 262{]}}
This is possible because GIMPLE is not a stable interface.

The key takeaway from this section is that rustc has to transform the
tree-based representation into a 3-AD representation by itself. That
means that it can access the program's control flow graph (CFG). This is
not the case for gccrs. In GCC, the CFG is only available in the
\emph{Low GIMPLE} representation, deep inside the middle-end where the
IR is language independent.

\section{Rustc Representation}\label{rustc-representation}

In the previous section, we have seen that rustc is responsible for
transforming the code from the raw text to the LLVM IR. Given the high
complexity of the Rust language, rustc uses multiple intermediate
representations (IRs) to simplify the process (see the diagram below).
The text is first tokenized and parsed into an abstract syntax tree
(AST), and then transformed into the high-level intermediate
representation (HIR). For transformation into a middle-level
intermediate representation (MIR), the HIR is first transformed into a
typed HIR (THIR). The MIR is then transformed into the LLVM IR.

\begin{figure}
\centering
\includesvg[width=0.75\textwidth,height=\textheight]{./pipeline.svg}
\caption{Comparison of compiler pipelines with a focus on internal
representations}
\end{figure}

AST is a tree-based representation of the program, closely following
each source code token. At this stage, rustc performs macro-expansion
and a partial name resolution (macros and imports)
\citeproc{ref-devguide}{{[}14{]}} \footnote{\url{https://rustc-dev-guide.rust-lang.org/macro-expansion.html}}
\footnote{\url{https://rustc-dev-uide.rust-lang.org/name-resolution.html}}.
As the AST is lowered to HIR, some complex language constructs are
desugared to simpler constructs. For example, various types of loops are
transformed into a single infinite loop construct (Rust \texttt{loop}
keyword), and many structures that can perform pattern matching
(\texttt{if\ let}, \texttt{while\ let}, \texttt{?} operator) are
transformed into the `match`` construct\citeproc{ref-reference}{{[}7{]}}
\footnote{\href{https://doc.rust-lang.\%20org/reference/expressions/if-expr.html\#if-let-expressions}{https://doc.rust-lang.org/reference/expressions/if-expr.html\#if-let-expressions}}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Foo(i31)}\OperatorTok{;}

\KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:}\NormalTok{ i31) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{    Foo(x)}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} This very simple code will be used as an example
throughout this section.
\end{quote}

\begin{quote}
\begin{verbatim}
Fn {
  generics: Generics { ... },
  sig: FnSig {
    header: FnHeader { ... },
      decl: FnDecl {
        inputs: [
          Param {
            ty: Ty {
              Path { segments: [ PathSegment { ident: i32#0 } ] }
            }
            pat: Pat { Ident(x#0) }
          },
        ],
        output: Ty {
            Path { segments: [ PathSegment { ident: Foo#0 } ]
        }
      },
  },
  ... 
}
\end{verbatim}

\hfill\break
\textbf{Example:} This is a textual representation of a small and
simplified part of the abstract syntax tree (AST) of the example
program. The full version can be found in the
\hyperref[abstract-syntax-tree-ast]{appendix}.
\end{quote}

HIR is the primary representation used for most rustc
operations\citeproc{ref-devguide}{{[}14{]}}, HIR. It combines a
simplified version of the AST with additional tables and maps for quick
access to additional information. Those tables contain, for example,
information about the types of expressions and statements. These tables
are used for analysis passes, e.g., the full (late) name resolution and
type checking. The type-checking process includes checking the type
correctness of the program, type inference, and resolution of
type-dependent implicit language
constructs.\citeproc{ref-devguide}{{[}14{]}} \footnote{\url{https://rustc-dev-guide.rust-lang.org/type-checking.html}}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
 \AttributeTok{\#[}\NormalTok{prelude\_import}\AttributeTok{]}
 \KeywordTok{use} \PreprocessorTok{::std::prelude::rust\_2015::}\OperatorTok{*;}
 \AttributeTok{\#[}\NormalTok{macro\_use}\AttributeTok{]}
 \KeywordTok{extern} \KeywordTok{crate}\NormalTok{ std}\OperatorTok{;}
 \KeywordTok{struct}\NormalTok{ Foo(}\DataTypeTok{i32}\NormalTok{)}\OperatorTok{;}

 \KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}\NormalTok{ Foo(x) }\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} One of HIR dump formats: HIR structure still
corresponds to a valid Rust program, equivalent to the original one.
\texttt{rustc} provides a textual representation of HIR, which displays
such a program.
\end{quote}

The HIR representation can contain many placeholders and ``optional''
fields that are resolved during the HIR analysis. To simplify further
processing, parts of HIR that correspond to executable code (e.g., not
type definitions) are transformed into THIR (Typed High-Level
Intermediate Representation), where all the missing information must be
resolved. The reader can think about HIR and THIR in terms of the
\href{https://en.wikipedia.org/wiki/Builder_pattern}{builder pattern}.
HIR provides a flexible interface for modification, while THIR is the
final immutable representation of the program. This involves not only
the data stored in HIR helper tables, but also parts of the program that
are implied from the type system. This means that operator overloading,
automatic references, and automatic dereferences are all resolved into
explicit code at this stage.

The final \texttt{rustc} IR, which is lowered directly to the LLVM IR,
is the Mid-level Intermediate Representation (MIR). We will pay extra
attention to MIR because it is the primary representation used by the
borrow checker. MIR is a three-address code representation, similar to
LLVM IR but with Rust-specific constructs. It contains information about
types, including lifetimes. It differentiates pointers and references,
as well as mutable and immutable references. It is aware of panics and
stack unwinding. It contains additional information for borrow checker,
like storage live/dead annotations, which denote when a place (an
abstract representation of a memory location) is first used or last
used, and fake operations, which help with the analysis. For example, a
fake unwind operation inside infinite loops ensures an exit edge in the
CFG. Fake operations can be critical for algorithms that process the CFG
in reverse order.

MIR consists of sequences of statements (basic blocks) connected by
control flow instructions. This structure forms a control flow graph.
MIR statements operate on places (often called lvalue in other
languages) and rvalues. A place can represent either a local variable or
a value derived from the variable (e.g., a field, an index, or a cast).

Rustc also uses a special IR, called TyTy, to represent types.
Initially, types are represented in HIR on a syntactic level. Every
mention of a type in the program compiles into a distinct HIR node.
These HIR nodes are compiled into the TyTy representation during the HIR
analysis. Each type (all its occurrences in the program) is represented
by a single TyTy object instance. This is achieved by
\href{https://en.wikipedia.org/wiki/Interning_\%28computer_science\%29}{interning}.
Note that there can be multiple equivalent types of different
structures. Those are represented by different TyTy instances. Each
non-primitive type forms a tree (e.g., reference to a pair of an integer
and a character), where the inner nodes are shared between types due to
interning. Generic types, which are of particular interest to borrow
checking, are represented as a pair: an inner type and a list of generic
arguments. When generic type parameters are substituted for concrete
types, the concrete type is placed into the argument list. The inner
type is left unchanged. When the type substitution is complete, there is
a procedure that transforms the generic type into a concrete type.

Inside the HIR, after the type-checking analysis, TyTy types of nodes
can be looked up based on the node's ID in one of the helper tables
(namely, the type-check context). Each \texttt{THIR} node directly
contains a pointer to its type. In MIR, the type is stored inside each
place.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ foo(\_1}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{    debug x }\OperatorTok{=\textgreater{}}\NormalTok{ \_1}\OperatorTok{;}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ \_0}\OperatorTok{:}\NormalTok{ Foo}\OperatorTok{;}

\NormalTok{    bb0}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{        \_0 }\OperatorTok{=}\NormalTok{ Foo(\_1)}\OperatorTok{;}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} MIR dump For further details, see the chapter ``Source
Code Representation'' in \citeproc{ref-devguide}{{[}14{]}}.
\end{quote}

\section{Rust GCC Resentation}\label{rust-gcc-resentation}

This section discusses intermediate representations in gccrs. Since
gccrs is a second implementation of the Rust compiler, it is heavily
inspired by rustc. Therefore, this section assumes familiarity with the
rustc intermediate representations, described in the previous section.
We will focus on similarities and differences between rustc and gccrs,
rather than describing the gccrs intermediate representation in full
detail.

The gccrs representation is strongly inspired by rustc. It diverges
mostly for two reasons: for simplicity, since gccrs is still in an early
stage of development, and due to the specifics of the GCC platform.
Gccrs uses its own variants of AST, HIR, and TyTy representations, but
does not use a THIR or MIR.

AST and HIR representations are similar to rustc, with fewer features
supported. The main difference is the structure of the representation.
Rustc takes advantage of algebraic data types, resulting in a very
fine-grained representation. On the other hand, gccrs is severely
limited by the capabilities of C++11 and is forced to use an
object-oriented approach.

There are no THIR and MIR or any equivalent in gccrs. MIR cannot be used
in GCC unless the whole gccrs code generation is rewritten to output
(low) GIMPLE instead of GENERIC, which would be much more complex than
the current approach. Given the limited development resources of gccrs,
this is not a viable option.\citeproc{ref-zulip}{{[}15{]}}

The TyTy-type representation is simplified in gccrs and provides no
uniqueness guarantees. There is a notable difference in the
representation of generic types. Instead of being built on top of the
types (by composition) like in rustc, types that support generic
parameters inherit from a common base class. That means that the type
definition is not shared between different generic types. The advantage
of this approach is that during the substitution of generic parameters,
the inner types are modified during each type substitution, simplifying
intermediate handling, like type inference.

\chapter{Rust GCC Borrow Checker
Design}\label{rust-gcc-borrow-checker-design}

The Rust GCC borrow checker is designed to be as similar to the rustc
borrow checker as possible within the constraints of the Rust GCC. This
allows us to leverage existing knowledge about borrow checking in Rust.
The analysis works in two phases. First, it collects relevant
information (called facts) about the program, which is stored as tuples
of numbers. Each number represents a CFG node, variable, path/place, or
loan (a borrow expression). Then, the borrow checker passes the facts to
the analysis engine, which computes the results of the analysis. The
compiler receives back the facts involved in memory safety violations
and translates them into error messages. The main decision of the Rust
GCC borrow checker is to reuse the analysis engine from rustc. To
connect the Polonius engine written in Rust to the gccrs compiler
written in C++, we use the C ABI and a thin Rust wrapper.

This chapter describes the process of designing the gccrs borrow
checker, the decisions made during the process, and the final design.
Special emphasis is placed on a new borrow checker intermediate
representation (BIR) and its usage in the analysis. The chapter also
describes other modifications of the compiler necessary to support
borrow checking. The final section briefly describes the design of error
reporting.

\section{Analysis of the Fact Collection
Problem}\label{sec:analysis-of-the-fact-collection-problem}

This section described options for fact collection in gccrs that were
considered and experimented with during the initial design phase. Due to
the differences between internal representations of rustc and gccrs, it
was impossible to copy the rustc approach exactly. The options
considered were to use HIR directly, to implement MIR in gccrs, or to
design a new IR for borrow checking with multiple options to place it
inside the compilation pipeline.

The analysis has been control-flow sensitive since NLL's introduction in
rustc (see sec.~\ref{sec:evolution}), requiring us to match the required
facts, which are specific to Rust semantics, with control-flow graph
nodes. We need to distinguish between pointers (in unsafe Rust) and
references. Pointers are not subject to borrow checking, but references
are. Furthermore, we need to distinguish between mutable and immutable
references, since they have different rules, which is essential for
borrow checking\footnote{The critical rule of borrow checking is that
  for a single borrowed variable, there can only be a single mutable
  borrow or only immutable borrows valid at each point of the CFG.}.
Each type must carry information about its lifetimes and their variances
(described later in this chapter). We need to store the explicit
lifetime parameters from explicit user type annotation.

The only IR in GCC that contains CFG information is GIMPLE; however,
under normal circumstances, GIMPLE is language agnostic. It is possible
to annotate GIMPLE statements with language-specific information using
special statements that would have to be generated from special
information that would need to be added to GENERIC. The statements would
need to be preserved by the middle-end passes until the pass building
the CFG (which includes 11 passes), after which facts could be
collected. After that, the facts would need to be discarded to avoid
complicating the tens of subsequent
passes\footnote{See file \texttt{gcc/passes.def} in the GCC source code.}\citeproc{ref-gccint}{{[}13,
p. 141{]}}, and RTL generation. This approach was discussed with senior
GCC developers and quickly rejected as it would require a large amount
of work and leak front-end-specific information into the middle-end,
making it more complex. No attempt was made to experiment with this
approach.

It was clear that we needed to build a CFG. Luckily, working with a
particular control flow graph created by the compiler is unnecessary.
Any CFG that is consistent with Rust semantics is sufficient. In
particular, adding any edges and merging nodes in the CFG is
conservative with regard to the borrow checking analysis. In many cases,
it does not change the result at all.

Initially, we tried to collect information from the HIR directly and
compute an approximate CFG on the fly. That worked nicely for simple
language constructs that are local, but it gets very complicated for
more complex constructs like patterns and loops with \texttt{break} and
\texttt{continue} statements. Since no representation is generated,
there is no easy way to verify the process, not even by manual checking.
Furthermore, it was not clear how to handle panics and stack unwinding
in this model.

An option to ease such problems was to radically desugared the HIR to
only basic constructs. An advantage of this approach is that it would
leverage the code already existing in the code generator, making code
generation easier. Also, the code generator already performs some of
those transformations locally (not applying them back to HIR, but using
them directly for GENERIC generation), so those could be reused. The
problem that quickly arose was that the HIR visitor system was not
designed for HIR-to-HIR transformations, where new nodes would be
created. Many such transformations, such as explicit handling of
automatic referencing and dereferencing, would require information about
the type of each node, which would, in return, require name resolution
results. Therefore, that transformation would have to happen after all
analysis passes on the HIR are completed. However, all information
stored alongside HIR would need to be updated for each newly created
node. The code generator partly avoids this problem by querying the
GENERIC API for the information it needs about the code already
compiled. This fact would complicate the use of existing transformations
on the HIR-to-HIR level. Rustc avoids this problem by doing such
transformations on the HIR-THIR boundary and not modifying the HIR
itself. Since this modification would be complicated and would only be a
preparation for borrow checking, it was decided not to proceed in this
direction at that time. However, we found that some transformation can
be performed on the AST-HIR boundary. This approach can be done mostly
independently (only code handling the removed nodes is also removed, but
no additions or modifications are needed). It was agreed that such
transformations are useful and should be implemented regardless of the
path taken by the borrow checker. Those transformations include mainly
loops and pattern-matching structures. These transformations are even
documented in the rust reference\citeproc{ref-reference}{{[}7{]}}.

\begin{quote}
At the time of writing, desugaring of the for loop was implemented by
Philip Herron. More desugaring work is in progress or is planned.
However, I have focused on the borrow checking itself. For the time
being, I have ignored the complex constructs, assuming that they will be
eventually desugared into constructs that the borrow checker would
already be able to handle.
\end{quote}

To ensure that all possible approaches were considered, we discussed the
possibility of implementing MIR in gccrs. This approach has some
advantages and many problems. Should the MIR be implemented in a
completely compatible way, it would be possible to use tools like
\href{https://github.com/rust-lang/miri}{MIRI} with gccrs. The borrow
checking would be very similar to rustc's borrow checking, and parts of
rustc's code might even be reused. Gccrs would also be more ready for
Rust-specific optimizations within the front-end. The final advantage is
that the current test suite would cover the process of lowering the HIR
to MIR, as all transformations would affect the code generation. The
main problem with this approach is that it would require a large portion
of gccrs to be reimplemented, delaying the project by a considerable
amount of time. Should such an approach be taken, any effort on borrow
checking would be delayed until the MIR is implemented. The
maintainers\citeproc{ref-zulip}{{[}15{]}} decided that such an approach
is not feasible and that gccrs will not use MIR in any foreseeable
future.

After Arthur Cohen suggested keeping things simpler, I decided to
experiment with a different, minimalistic approach: building a radically
simplified MIR-like IR that keeps only the bare minimum of information
needed for borrow checking. Given the unexpected productivity of this
approach, it was decided to continue. This IR, later called the borrow
checker IR (BIR), focuses only on the flow of data, and ignores the
actual data transformations. The main disadvantage of this approach is
that it creates a dead branch of the compilation pipeline that is not
used for code generation, and therefore it is not covered by the
existing test suite. To overcome this difficulty, the BIR and its
textual representation (dump) are designed to be as similar to rustc's
MIR as possible. This feature allows us to check the generated BIR
against the MIR generated by rustc, at least for simple programs. The
use of BIR is the final approach used in this work. Details of the BIR
design are described in the next section.

\begin{figure}
\centering
\includesvg[width=0.35\textwidth,height=\textheight]{./bir.svg}
\caption{Placement of the borrow checker IR in the compilation pipeline}
\end{figure}

\section{The Borrow Checking Process}\label{the-borrow-checking-process}

Before the borrow checking itself can be performed, specific information
about types needs to be collected when the HIR is type-checked and TyTy
types are created and processed. The TyTy needs to resolve and store
information about lifetimes and their constraints. At this point,
lifetimes are resolved from string names, and their bounding clauses are
found. There are different kinds of lifetimes in the Rust language.
Inside types, the lifetimes are bound to the lifetime parameters of
generic types. In function pointers, lifetimes can be universally
quantified (meaning that the function must be memory-safe for every
possible lifetime). In function definitions, lifetimes can be elided
when all references have the same lifetime. In function bodies,
lifetimes can be bound to the lifetime parameters of the function, or
they can be omitted, in which case they are inferred \footnote{At least
  Rust semantics thinks about it that way. In reality, the compiler only
  checks that there exists some lifetime that could be used in that
  position by collecting constraints that would apply to such a
  lifetime.}. The type-checked HIR is then transformed into the borrow
checker IR (BIR). The BIR is then processed to extract facts for
Polonius. At this phase, some errors that are easy to detect can be
emitted. The collected facts are then passed to Polonius, which computes
the results of the analysis. The results are then passed back to the
compiler, which translates them into error messages.

\section{Representation of Lifetimes in
TyTy}\label{representation-of-lifetimes-in-tyty}

\begin{quote}
The term \emph{lifetime} is used in this work to refer to the syntactic
object in HIR and AST. In the source code, it corresponds to either
explicit universal\footnote{There are two kinds of lifetimes in Rust
  semantics: universal and existential. Universal lifetimes correspond
  to code that occurs outside the function. It is called universal
  because the concerned borrow checking rules use the universal
  quantifier. That means that the function has to be valid \emph{for
  all} possible outside code that satisfies the specified (or implied)
  constraints. Existential lifetimes correspond to the code that happens
  inside the function. The existential quantifier is used in the rules
  regarding existential lifetimes. That means that the code has to be
  valid \emph{for some} set of \emph{loans} (or CFG points).} lifetime
annotation (\texttt{\textquotesingle{}a}), elided universal lifetime
annotation\href{https://doc.rust-lang.org/reference/lifetime-elision.html}{\citeproc{ref-reference}{{[}7{]}}},
and local/existential lifetimes, which are always inferred. In contrast,
\emph{region}/\emph{origin} is used to refer to the semantic object. The
object is, in fact, an inference variable, and its value is computed by
the borrow checker. The term \emph{region} is used by NLL to refer to a
set of CFG points. Polonius introduced the term \emph{origin} to refer
to a set of \emph{loans}. In this text and in the implementation, we use
the two terms interchangeably.
\end{quote}

In order to analyze more complex lifetimes than just simple references,
it was necessary to add a representation of lifetime parameters to the
type system and unify it with the representation of lifetimes in the
rest of the compiler. The first step is to resolve the lifetimes and
bind them to their binding clauses. Gccrs recognizes four kinds of
regions. In a function body, explicit lifetimes annotations result in
``named'' lifetimes, and implicit lifetimes annotations result in
``anonymous'' lifetimes. Within generic data types, lifetimes resolved
to lifetime parameters are called ``early-bound.'' For function pointers
and traits, lifetimes can be universally quantified using the
\texttt{for} clause\footnote{\texttt{for\textless{}\textquotesingle{}a\textgreater{}\ fn(\&\textquotesingle{}a\ i32)\ -\textgreater{}\ \&\textquotesingle{}a\ i32}}.
These lifetimes are not resolved when the definition is analyzed, but
only when this type is used. Hence, the name is ``late-bound''
lifetimes. In addition, there is a representation for unresolved
lifetimes. It is used, for example, when a generic type is defined, but
the generic arguments have not been provided yet. Any occurrence of an
unresolved lifetime after type checking is to be treated as a compiler
bug.

Inside TyTy, lifetimes are represented in the following ways. Named
lifetimes are enumerated. Anonymous lifetimes are assumed to be always
distinct (but they are represented by an identical object at this
stage). Early bound lifetimes are represented by the relative position
of the lifetime parameter to which they are bound. In generic types, the
lifetime arguments are stored together with the type arguments, which
ensures their automatic propagation. One issue with this automatic
propagation is that the bindings of early bound lifetimes are updated.
This means that by a simple inspection of the body of the generic type,
one would not be able to resolve the lifetimes. A trick solves this
problem. Each TyTy type is identified by an ID. When generic arguments
are substituted, a clone of the type with a fresh ID is created. What we
would like to achieve is to have the same state as in rustc: the
original body and an up-to-date list of generic arguments. This can be
achieved by storing the ID of the original type in addition to the
current ID. The original ID can be used to lookup the original type when
needed.\footnote{This was once revealed to me in a dream.} The analysis
can then traverse the original type, and when a type placeholder is
encountered, the appropriate argument is looked up in the current type.

\section{Borrow Checker IR Design}\label{borrow-checker-ir-design}

The borrow checker IR (BIR) is a three-address code representation
designed to be close to a subset of the rustc MIR. Like MIR, it
represents the body of a single function (or a function-like item, for
example, a closure), since borrow checking is performed on each function
separately. It ignores particular operations and merges them into a few
abstract operations that focus on data flow.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ fib(\_1}\OperatorTok{:} \DataTypeTok{usize}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \DataTypeTok{i32} \OperatorTok{\{}
\NormalTok{    bb0}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{        \_4 }\OperatorTok{=}\NormalTok{ Operator(\_1}\OperatorTok{,} \KeywordTok{const} \DataTypeTok{usize}\NormalTok{)}\OperatorTok{;}
\NormalTok{        switchInt(\_4) }\OperatorTok{{-}\textgreater{}}\NormalTok{ [bb1}\OperatorTok{,}\NormalTok{ bb2]}\OperatorTok{;}
    \OperatorTok{\}}

    \CommentTok{// ... (rest of the code)}

\NormalTok{    bb6}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{        \_8 }\OperatorTok{=}\NormalTok{ Operator(\_1}\OperatorTok{,} \KeywordTok{const} \DataTypeTok{usize}\NormalTok{)}\OperatorTok{;}
\NormalTok{        \_9 }\OperatorTok{=}\NormalTok{ Call(fib)(\_8}\OperatorTok{,}\NormalTok{ ) }\OperatorTok{{-}\textgreater{}}\NormalTok{ [bb7]}\OperatorTok{;}
    \OperatorTok{\}}

\NormalTok{    bb7}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{        \_10 }\OperatorTok{=}\NormalTok{ Operator(\_7}\OperatorTok{,}\NormalTok{ \_9)}\OperatorTok{;}
\NormalTok{        \_2 }\OperatorTok{=}\NormalTok{ \_10}\OperatorTok{;}
\NormalTok{        goto }\OperatorTok{{-}\textgreater{}}\NormalTok{ bb8}\OperatorTok{;}
    \OperatorTok{\}}

\NormalTok{    bb8}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{        \_0 }\OperatorTok{=}\NormalTok{ \_2}\OperatorTok{;}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} A shortened example of a BIR dump of a simple Rust
program. The program computes the nth Fibonacci number. The source code,
full dump, and legend can be found in
\hyperref[appendix-c-bir-dump-example]{\emph{appendix C}}. This example
comes from the ``BIR Design Notes'' document, which is part of the
source tree and provides an introduction to developers getting familiar
with the basic aspects of the borrow checker implementation.
\end{quote}

The BIR of a single function is composed of basic metadata about the
function (such as arguments, return type, or explicit lifetimes), a list
of basic blocks, and a list of places.

A basic block is identified by its index in the function's basic block
list. It contains a list of BIR statements and a list of successor basic
block indices in the CFG. BIR statements are of three categories: An
assignment of an expression to a local (place), a control flow operation
(switch, return), or a special statement (not executable), which carries
additional information for the borrow checker (explicit type
annotations, information about variable scope, etc.). BIR statements
correspond to the MIR \texttt{StatementKind} enum.

Expressions represent the executable parts of the rust code. Many
different Rust constructs are represented by a single expression. Only
data (and lifetime) flow needs to be tracked. Some expressions are
differentiated only to allow for a better debugging experience. BIR
expressions correspond to the MIR \texttt{RValue} enum.

Expressions and statements operate on places. A place is an abstract
representation of a memory location. It is either a variable, a field,
an index, or a dereference of another place. For simplicity, constants
are also represented as places. Since exact values are not important for
borrow checking and constants are, from principle, immutable with static
storage duration, a single place can represent all constants of a single
type. Rustc MIR cannot afford this simplification, and keeps constants
separate. The \texttt{Operand} enum is a common interface for places and
constants. However, since operations use constants and lvalues in the
same way, MIR introduces a special layer of lvalues.

Places are identified by the index in the place database. The database
stores a list of places and their properties. The properties include an
identifier, used to always resolve the same variable (field, index,
etc.) to the same place, move and copy flags, type, a list of fresh
regions (lifetimes), and a relationship to other places (e.g., a field
of a struct). Temporaries are treated just like variables but are
differentiated in the place database because of place lookup. The place
database also keeps track of scopes and existing loans. The place
database structure is based on rustc
\href{https://rustc-dev-guide.rust-lang.org/borrow_check/moves_and_initialization/move_paths.html}{\texttt{MovePathData}}.
It combines the handling of places done by both MIR and borrow checker
separately in rustc.

It is important to highlight that different fields are assigned to
different places; however, all indices are assigned to the same place
(both in gccrs and rustc). This fact has a strong impact on the strength
and complexity of the analysis, because the number of fields is static
and typically small, the size of arrays is unbound and depends on
runtime information.

\begin{quote}
\textbf{Structure of the BIR Function}

\begin{itemize}
\tightlist
\item
  basic block list

  \begin{itemize}
  \tightlist
  \item
    basic block
  \item
    \texttt{Statement}

    \begin{itemize}
    \tightlist
    \item
      \texttt{Assignment}

      \begin{itemize}
      \tightlist
      \item
        \texttt{InitializerExpr}
      \item
        \texttt{Operator\textless{}ARITY\textgreater{}}
      \item
        \texttt{BorrowExpr}
      \item
        \texttt{AssignmentExpr} (copy)
      \item
        \texttt{CallExpr}
      \end{itemize}
    \item
      \texttt{Switch}
    \item
      \texttt{Goto}
    \item
      \texttt{Return}
    \item
      \texttt{StorageLive} (start of variable scope)
    \item
      \texttt{StorageDead} (end of variable scope)
    \item
      \texttt{UserTypeAsscription} (explicit type annotation)
    \end{itemize}
  \end{itemize}
\item
  place database
\item
  arguments
\item
  return type
\item
  universal lifetimes
\item
  universal lifetime constraints
\end{itemize}
\end{quote}

\section{BIR Building}\label{bir-building}

The BIR is built by visiting the HIR tree of the function. There are
specialized visitors for expressions and statements, patterns, and a
top-level visitor that handles function headers (arguments, return,
lifetimes, etc.). Whenever a new place is created in the compilation
database, a list of fresh regions\footnote{In this text, we use the term
  lifetime for the syntactic object in the code and region for the
  semantic object in the analysis. It is called a region because it
  represents a set of points in the control flow graph (CFG). At this
  point, the set is not yet known. It is the main task of the borrow
  checker analysis engine to compute the set of points for each region.}
is created for it. At this point, we need to figure out the number of
lifetimes mentioned in a type. For basic types, this is achieved by
traversing the type and counting the number of lifetime parameters. For
generic types, the inner structure is ignored, and only the lifetime and
type parameters are considered. Note that the type parameters can be
generic, creating a structure known as
\href{https://rustc-dev-guide.rust-lang.org/what-does-early-late-bound-mean.html\#early-and-late-bound-parameter-definitions}{higher-kinded}
lifetimes. This counting is performed (as a side product) during the
variance analysis (explained below) to simplify the type traversing
code. All types are independently queried for each node from the HIR
(they are not derived inside the BIR).

\begin{quote}
Example: For a BIR code that reads a field from a variable, the type is
not computed from the variable. Rather, it is queried from the HIR for
both the variable and the field.
\end{quote}

BIR building itself is fairly straightforward. However, some extra
handling was added to produce a code that is more similar to
\texttt{rustc}'s MIR. For example, instead of eagerly assigning computed
expressions to temporaries, it is checked whether the caller did not
provide a destination place. This transformation removes some of the
\texttt{\_10\ =\ \_11} statements from the BIR dump. The BIR dump also
renumbers all places to produce a closer match with the BIR dump. This
can cause some confusion during debugging because Polonius is receiving
the original place numbers. When debugging using the Polonius debug
output, the dump can be switched to show the original place numbers.

\begin{quote}
This handling was especially important when testing the initial BIR
builder, since it makes the dump more similar to the MIR dump and,
therefore, easier for manual comparison.
\end{quote}

\section{BIR Fact Collection and
Checking}\label{bir-fact-collection-and-checking}

The BIR fact collection extracts the Polonius facts from the BIR and
performs additional checks. Polonius is responsible for checking
lifetime (region) constraints, moves, and conflicts between borrows. For
lifetimes, it checks that the constraints are satisfied and that all
required constraints are present in the program. For moves, it checks
that each place is moved at most once. For borrows, it checks that any
two conflicting borrows (e.g., two mutable borrows of the same place)
are not alive at the same time. Sets of conflicting borrows have to be
supplied to Polonius manually. The borrow checker itself is responsible
for violations that are not control-flow sensitive, like modification of
an immutably borrowed place or moving from behind a reference.

The fact collection is performed in two phases. First, static facts are
collected from the place database. These include universal region
constraints (constraints corresponding to lifetime parameters of the
function) collected during BIR construction and facts collected from the
place database. Polonius needs to know which places correspond to
variables and which form paths (see the definition below). Furthermore,
it needs to sanitize fresh regions of places that are related (e.g., a
field and a parent variable) by adding appropriate constraints between
them. The relations of the regions depend on the variance of the region
within the type. (See Variance Analysis below.)

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Path }\OperatorTok{=}\NormalTok{ Variable}
     \OperatorTok{|}\NormalTok{ Path }\StringTok{"."}\NormalTok{ Field }\CommentTok{// field access}
     \OperatorTok{|}\NormalTok{ Path }\StringTok{"["} \StringTok{"]"}   \CommentTok{// index}
     \OperatorTok{|} \StringTok{"*"}\NormalTok{ Path}
\end{Highlighting}
\end{Shaded}

Formal definition of paths from the Polonius
book\citeproc{ref-polonius}{{[}11{]}}.
\end{quote}

In the second phase, the BIR is traversed along the CFG, and dynamic
facts are collected. For each statement, two CFG nodes are added. Two
nodes are needed to model the parts of semantics where the statement
takes effect immediately or after the statement is executed. For each
statement and (if present) its expression, Polonius facts are collected.
These include generic facts related to read and write operations, as
well as facts specific to borrows and function calls. For the function,
we need to instantiate fresh regions for the function's lifetime
parameters, which need to be correctly bound together.

\subsection{Subtyping and Variance}\label{subtyping-and-variance}

In the basic interpretation of Rust language semantics (one used by
programmers to reason about their code, not the one used by the
compiler), lifetimes are part of the type and are always present. If a
lifetime is not mentioned in the program explicitly, it is inferred the
same way as a part of type would be (e.g.,
\texttt{let\ a\ =\ (\_,\ i32)\ =\ (true,\ 5);} completes the type to
\texttt{(bool,\ i32)}) Note that it is actually impossible to write
those lifetimes. In the Rust program, all explicit lifetime annotations
correspond to any borrow that occurred \textbf{outside} the function,
and therefore, it is alive for the whole body of the function. Explicit
lifetime annotations corresponding to regions that span only a part of
the function body would be pointless. Borrows inside a function can be
analyzed precisely by the borrow checker. Explicit annotations are only
used to represent constraints following from the code that the borrow
checker cannot see.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{let} \KeywordTok{mut}\NormalTok{ x}\OperatorTok{;}
 \ControlFlowTok{if}\NormalTok{ (b) }\OperatorTok{\{}
\NormalTok{     x }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;} \CommentTok{// a: \&\textquotesingle{}a T}
 \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
\NormalTok{     x }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;} \CommentTok{// b: \&\textquotesingle{}b T}
 \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} We need to infer the type of x, so that it is a
subtype of both \texttt{\&\textquotesingle{}a\ T} and
\texttt{\&\textquotesingle{}b\ T}. We need to make sure that if we
further use x, that is safe with regard to all loans it can contain
(here \texttt{a} or \texttt{b}).
\end{quote}

In Rust, unlike object-oriented languages like Java or C++, the only
subtyping relation other than identity is caused by
lifetimes\footnote{During the type inference computation, there can also
  be a subtyping relation with a general kind of types (like ), which is
  mostly used for literals without a type annotation, where we know it
  is ``some kind'' of integer, but we do not yet know which one}. Two
regions (corresponding to lifetimes) can be unrelated, a subset of each
other (in terms of a set of CFG nodes) (denoted
\texttt{\textquotesingle{}a:\ \textquotesingle{}b}), or equal (typically
a result of \texttt{\textquotesingle{}a:\ \textquotesingle{}b} and
\texttt{\textquotesingle{}b:\ \textquotesingle{}a}). The dependency of
subtyping on the inner parameter is called variance.

\begin{quote}
\textbf{Definition} \citeproc{ref-reference}{{[}7{]}}

\texttt{F\textless{}T\textgreater{}} is covariant over \texttt{T} if
\texttt{T} being a subtype of \texttt{U} implies that
\texttt{F\textless{}T\textgreater{}} is a subtype of
\texttt{F\textless{}U\textgreater{}} (subtyping ``passes through'')

\texttt{F\textless{}T\textgreater{}} is contravariant over \texttt{T} if
\texttt{T} being a subtype of \texttt{U} implies that
\texttt{F\textless{}U\textgreater{}} is a subtype of F

\texttt{F\textless{}T\textgreater{}} is invariant over \texttt{T}
otherwise (no subtyping relation can be derived)
\end{quote}

Let us see what that means on an example specific to lifetimes. For a
simple reference type \texttt{\&\textquotesingle{}a\ T}, the lifetime
parameter \texttt{\textquotesingle{}a} is covariant. This means that if
we have a reference \texttt{\&\textquotesingle{}a\ T} we can coerce it
to \texttt{\&\textquotesingle{}b\ T}, then \texttt{\textquotesingle{}a}
is a subtype of \texttt{\textquotesingle{}b}. In other words, if we are
storing a reference to some memory, it is sound to assign it to a
reference that lives for a shorter period of time. That is, if it is
safe to dereference a reference within any point of period
\texttt{\textquotesingle{}a}, it is also safe to dereference it within
any point of period \texttt{\textquotesingle{}b},
(\texttt{\textquotesingle{}}b\texttt{is\ a\ subset\ of}'\texttt{a})
\footnote{A subset of CFG nodes.}.

The situation is different when we pass a reference to a function as an
argument. In that case, the lifetime parameter is contravariant. For
function parameters, we need to ensure that the parameter lives as long
as the function needs it to. If we have a function pointer of type
\texttt{fn\ foo\textless{}\textquotesingle{}a\textgreater{}(x:\ \&\textquotesingle{}a\ T)},
we can coerce it to
\texttt{fn\ foo\textless{}\textquotesingle{}b\textgreater{}(x:\ \&\textquotesingle{}b\ T)},
where \texttt{\textquotesingle{}b} lives longer than
\texttt{\textquotesingle{}a}. This conversion is safe because it only
restricts the possible values of the parameter \texttt{x}.

Let us look at that visually. In the following code, we have region
\texttt{\textquotesingle{}a}, where it is safe to reference the storage
of \texttt{x}, and region \texttt{\textquotesingle{}b} where it is safe
to reference the storage of \texttt{y}. If a function safely works with
a reference of lifetime \texttt{\textquotesingle{}b}, it will also
safely work with a reference of lifetime \texttt{\textquotesingle{}a}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]

 \KeywordTok{let}\NormalTok{ x }\OperatorTok{=} \DecValTok{5}\OperatorTok{;}        \CommentTok{// region \textquotesingle{}a}
 \OperatorTok{\{}                 \CommentTok{//}
     \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \DecValTok{7}\OperatorTok{;}    \CommentTok{//            // region \textquotesingle{}b        }
 \OperatorTok{\}}                 \CommentTok{//}
\end{Highlighting}
\end{Shaded}
\end{quote}

The return type of the function is effectively an assignment to a local
variable (just across function boundaries) and therefore is covariant.

The situation becomes interesting when the two rules are combined. Let
us have a function
\texttt{fn\ foo\textless{}\textquotesingle{}a\textgreater{}(x:\ \&\textquotesingle{}a\ T)\ -\textgreater{}\ \&\textquotesingle{}a\ T}.
The return type requires the function to be covariant over
\texttt{\textquotesingle{}a}, while the parameter requires it to be
contravariant. This is called \emph{invariance}.

For non-generic types, its variance immediately follows from the type
definition. For generic types, the situation is more complex.

\subsection{Variance of Generic Types}\label{variance-of-generic-types}

There are multiple approaches to the variance of generic types. It can
be either derived from the usage of the type or its
definition\citeproc{ref-Altidor2011}{{[}16{]}}. For non-generic types,
use-site variance is used.\footnote{For
  \texttt{\&\textquotesingle{}a\ T}, if the reference is used as a
  function parameter, it is contravariant; if it is used as a return
  type, it is covariant.} For generic types, Rust uses definition-site
variance. This means that the variance is computed solely from the
definition of the type (effectively, usage constraint to the body of the
type), not from its usage (inside functions). The situation becomes
complicated when a generic type is used inside another generic type,
possibly even in a recursive fashion. In that situation, the variance
has to be computed using a fixed-point algorithm (further referred to as
the ``variance analysis'').

\subsubsection{Variance Analysis}\label{variance-analysis}

Both rustc and gccrs variance analysis implementation is based on
Section 4 of the paper \citeproc{ref-Altidor2011}{{[}16{]}}. The
notation from the paper is followed in the documentation of both
compilers, their documentation, and in this text. The paper primarily
focuses on variance of complex types, like in the case of Java, but it
introduces an effective formal calculus, which works nicely with
higher-kinded lifetimes.

The exact rules are best understood from the paper and from the code
itself. Therefore, we will only provide a simple overview here. The
analysis uses an iterative fixed-point computation, where variables form
a semi-lattice with an additional binary operation. A single variable
corresponds to a single lifetime or type parameter. Variables are
initialized as bivariant.

The visitor traverses each type with the current variance of the visited
expression as input. Each member of a type is in a covariant position.
Each member of a function parameter is in a contravariant position. The
return type is in the covariant position. The position of the generic
argument is determined by the variance of the generic parameter (a
variable in this computation). The variance of the current node within
the type is computed by the \texttt{transform} function, taking the
variance of the parent node and the variance based on the position of
the current node. When a lifetime or type parameter is encountered, then
if the current variance expression is constant, the variable is updated
to the new variance using the join operation with the current value. For
an expression that contains at least one variable, the expression is
added to the list of constraints. Here, the fixed-point computation
requirement arises.

\begin{quote}
\textbf{Example of Algorithm Execution}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{struct}\NormalTok{ Foo}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{,} \OtherTok{\textquotesingle{}b}\OperatorTok{,}\NormalTok{ T}\OperatorTok{\textgreater{}} \OperatorTok{\{}
\NormalTok{     x}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}a}\NormalTok{ T}\OperatorTok{,}
\NormalTok{     y}\OperatorTok{:}\NormalTok{ Bar}\OperatorTok{\textless{}}\NormalTok{T}\OperatorTok{\textgreater{},}
 \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Struct foo has three generic parameters, leading to 3 variables.
  \texttt{f0=o}, \texttt{f1=o} and \texttt{f2=o}.
\item
  \texttt{x} is processed first, in the covariant position.
\item
  \texttt{\&\textquotesingle{}a\ T} is in covariant position; therefore,
  the variables are updated to \texttt{f0=+} and \texttt{f2=+}.
\item
  \texttt{y} is processed second, in the covariant position.
\item
  \texttt{Bar\textless{}T\textgreater{}} is in covariant position.

  \begin{itemize}
  \tightlist
  \item
    \texttt{T} is inside a generic argument; therefore, its position is
    computed as a term \texttt{transform(+,\ b0)}.

    \begin{itemize}
    \tightlist
    \item
      New constant \texttt{f2\ =\ join(f2,\ transform(+,\ b0))} is
      added.
    \end{itemize}
  \end{itemize}
\item
  All types are processed. Let us assume that \texttt{Bar} is an
  external type with variances \texttt{{[}-{]}} Now a fixed-point
  computation is performed.
\item
  Iteration 1:

  \begin{itemize}
  \tightlist
  \item
    Current values are \texttt{f0=+}, \texttt{f1=o} and \texttt{f2=+}
  \item
    Processing constraint \texttt{f2\ =\ join(f2,\ transform(+,\ b0))}
  \item
    \texttt{transform(+,\ b0)} where \texttt{b0=-} yields \texttt{-}
  \item
    \texttt{join(+,\ -)} yields \texttt{*}
  \item
    \texttt{f2} is updated, therefore, another iteration is needed.
  \end{itemize}
\item
  Iteration 2:

  \begin{itemize}
  \tightlist
  \item
    Current values are \texttt{f0=+}, \texttt{f1=o} and \texttt{f2=*}
  \item
    Processing constraint \texttt{f2\ =\ join(f2,\ transform(+,\ b0))}
  \item
    \texttt{transform(+,\ b0)} where \texttt{b0=-} yields \texttt{-}
  \item
    \texttt{join(*,\ -)} yields \texttt{*}
  \item
    \texttt{f2} is not updated, therefore, the computation is finished.
  \end{itemize}
\item
  The final variance is \texttt{f0=+}, \texttt{f1=o} and \texttt{f2=*}:
\item
  \texttt{f0} is evident,
\item
  \texttt{f1} stayed bivariant, because it was not mentioned in the
  type,
\item
  \texttt{f2} is invariant, because it s is used in both covariant and
  contravariant positions.
\end{itemize}
\end{quote}

Once all types in the crate are processed, the constraints are solved
using a fixed-point computation. Note that the current crate can use
generic types from other crates, and therefore, it has to export/load
the variance of public types.

\section{Error Reporting}\label{error-reporting}

As each function is analyzed separately, the compiler can easily report
which functions violate the rules. Currently, only the kind of violation
is communicated from the Polonius engine to the compiler. More detailed
reporting is an issue for future work.

There are three possible ways for the more detailed reporting to be
implemented.

The first is to pass all the violations back to the compiler to be
processed as a return value of the Polonius FFI invocation. This variant
provides a simple separation of roles between the compiler and the
analysis engine. However, it might be difficult to implement correctly
with regard to memory ownership around the FFI boundary, since Polonius
would need to allocate dynamically sized memory to pass the result.
Polonius would need to implement a special API to release the memory.

The second variant is to pass a callback function to report the errors
found to the Polonius engine, which would be called for each violation.
However, Polonius only has information in terms of the enumerated nodes
of the control flow graph. Therefore, a pointer to an instance of the
borrow checker would need to be passed to the Polonius engine to be used
in combination with the callback to resolve the nodes to the actual
code. The separation of roles, where Polonius and Polonius FFI are used
just as external computation engines, is broken.

A compromise between these variants would be to provide Polonius with
callback functions, which would send the violations to the compiler one
by one, leaving the allocation on the compiler side only.

Moreover, the borrow checker currently does not store information to map
the nodes back to the source code locations. This issue is clearly
technical only, and the functionality can be added easily with local
changes only. Since this work has an experimental character, work on the
analysis itself was prioritized over more detailed error reporting.

The final stage of the development of the borrow checker would be to
implement heuristics to guess the reason for the error and suggest
possible fixes.

\chapter{Implementation}\label{implementation}

After the initial experiments described in
sec.~\ref{sec:analysis-of-the-fact-collection-problem}, the project was
implemented in the following phases: First, an initial version of the
borrow checker IR (BIR), lowering from HIR to BIR (the BIR builder), and
textual BIR dump were implemented. Second, the first version of the BIR
fact collection and the Polonius FFI were implemented. At this stage,
the first simple error detections were tested. Next, the implementation
had to be extended to handle more complex data types, especially generic
ones. Finally, the BIR fact collection was extended to handle the new
information and emit all available facts.

The initial version of the borrow checker included only the minimal
possible information that the borrow checker was expected to need. The
builder was able to lower most operator and initializer expressions,
borrow expressions, function calls, and simple control flow operations
(\texttt{if}, \texttt{if/else}, \texttt{while}, \texttt{loop},
\texttt{return}). The whole compiler was
\href{https://github.com/Rust-GCC/gccrs/pull/2689}{extended} to handle
labeled\href{https://doc.rust-lang.org/reference/expressions/loop-expr.html\#labelled-block-expressions}{blocks}
to be able to lower (and test) \texttt{break} and \texttt{continue}
expressions. Note that in the Rustc language, \texttt{break} and
\texttt{continue} keywords can be used with a label identifier to break
out of a nested loop, and it can be used to return a value out of any
labeled block\citeproc{ref-reference}{{[}7{]}}. The BIR dump was
designed to be as similar to MIR as possible to allow for manual
verification of the BIR. This part turned out to have some issues
because rustc performs many transformations of MIR, and there are many
versions of the dump available. Originally, the dump from the online
\href{https://godbolt.org/}{Compiler Explorer} was used as it was easily
available. However, this version of MIR is optimized and cleaned up. It
was very complicated to keep up with this dump, as it required some
additional transformation of the BIR. This fact led to the decision to
change the reference MIR dump. MIR after each MIR pass can be exported
from rustc using the flag \texttt{-Zdump-mir=*}. In addition, there is
also the option \texttt{-Zunpretty=mir}. The logical choice was to
continue with the MIR version used for borrow checking
(\texttt{-Zdump-mir=nll}). This version is not very optimized and
contains additional information for borrow checking. Most of the BIR
transformations had to be removed after this change of the reference MIR
dump. This initial version of BIR and related infrastructure was
submitted to Rust GCC in
\href{https://github.com/Rust-GCC/gccrs/pull/2702}{pull request 2702}.
This PR added 3,779 lines of new code. This included a document called
``BIR Design Notes'' that was written to help new developers get
familiar with the borrow checker implementation. It can be found in the
file
\href{https://github.com/Rust-GCC/gccrs/blob/df5b6a371dba385e4bb03ebd638cd473c4cc38eb/gcc/rust/checks/errors/borrowck/bir-design-notes.md}{\texttt{gcc/rust/checks/errors/borrowck/bir-design-notes.md}}.

In the second phase, the fact collection and an interface to the
Polonius engine were implemented. At this stage, only lifetimes of
simple references were handled (at most one lifetime per type). Fact
collection processed all the places in the place database and walked the
BIR control flow graphs. The interface to Polonius consists of a C ABI
in gccrs and a C ABI (generated by
\href{https://github.com/rust-lang/rust-bindgen}{rust-bindgen} and
manually cleaned up and extended) in a small static library in Rust (FFI
Polonius). The role of the FFI Polonius library is to invoke the
Polonius engine. A discussion about the integration of this interface
into the GCC build system was started in
\href{https://github.com/Rust-GCC/gccrs/pull/2716}{pull request draft
2716}. This problem is very complicated because it requires compilation
of Rustc code that is beyond the current capabilities of gccrs. For
development purposes, the Cargo build system (rustc) is invoked from the
GCC Makefile. This solution is not viable for production because it does
not handle cross-compilation well. However, this solution is the best
for developer experience. It was decided that, for the time being, the
build integration will be kept downstream. The most viable solution for
upstreaming is to release the Polonius FFI as a dynamic library and keep
the building outside GCC. The final decision will be made when the
borrow checker is ready for a public release. For this reason, this
phase was not submitted to Rust GCC. Newer independent commits are
rebased below the FFI commit and submitted separately. At this stage,
the borrow checker successfully detected
\href{https://doc.rust-lang.org/error_codes/E0382.html}{repeated moves},
basic subset errors (i.e., insufficient constraints between inputs and
outputs of the function were specified), and
\href{https://doc.rust-lang.org/error_codes/E0507.html}{moves behind} a
reference{]}(https://doc.rust-lang.org/error\_codes/E0507.html). At this
stage, error output was implemented using only the FFI Polonius debug
output (see the example).

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{[}\DecValTok{34}\OperatorTok{/}\DecValTok{35}\NormalTok{] Checking function test\_move}
\NormalTok{Polonius analysis completed}\OperatorTok{.}\NormalTok{ Results}\OperatorTok{:}
\NormalTok{Errors}\OperatorTok{:} \OperatorTok{\{\}}
\NormalTok{Subset error}\OperatorTok{:} \OperatorTok{\{\}}
\NormalTok{Move error}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{   GccrsAtom(}
       \DecValTok{11}\OperatorTok{,}
\NormalTok{   )}\OperatorTok{:}\NormalTok{ [}
\NormalTok{       GccrsAtom(}
           \DecValTok{2}\OperatorTok{,}
\NormalTok{       )}\OperatorTok{,}
\NormalTok{   ]}\OperatorTok{,}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} FFI Polonius debug output for a simple program with a
move error.
\end{quote}

In the third (and final) phase, the whole borrow checker, the TyTy IR,
and the type checker had to be extended to support complex types with
multiple lifetimes (regions). Variance analysis and helper region tools
were implemented. The BIR builder and fact collection were extended to
handle the new information and emit all the available facts. Correct
fact collection is a very complicated subject because there is very
little documentation of the facts and their relation with Rust code. The
current implementation is based on the Polonius
Book\citeproc{ref-polonius}{{[}11{]}}, the Polonius source
code\citeproc{ref-poloniusSource}{{[}17{]}}, the rustc source
code\citeproc{ref-rustcSource}{{[}18{]}}, and experiments using rustc
and the Polonius CLI. Some facts are probably missing or incorrectly
collected.

The borrow checker could find most errors that violate the access rules
(number of loans of a given type allowed, loan/access conflicts),
move/initialization errors, and subset errors. To demonstrate the
functionality, a small test suite was created. It was based on tests
included in the Polonius project and extended with custom ones. A
logical step would be to test the borrow checker against the rustc test
suite. However, at the current stage of Rust GCC, most of the test suite
used by rustc to check its borrow checker are incompatible because it
uses the Rust standard library, which gccrs is unable to compile.
Examples from the gccrs borrow checker test suite can be found in the
appendix.

This phase is awaiting final cleanup and submission in branch
\href{https://github.com/jdupak/gccrs/tree/borrowck-stage2}{borrowck-stage2}.
It includes 5146 additions and 720 deletions. This phase is expected to
be submitted to Rust GCC in the near future.

\section{Limitations}\label{limitations}

The main bottleneck of the current implementation is the BIR builder.
After covering a subset of Rust that was sufficient to handle enough
examples to test the error detection capability, this work focused on
other parts of the borrow checker to implement all necessary parts, even
if in a limited fashion. Following is a list of known limitations of the
current implementation.

\subsection{BIR and BIR Builder}\label{sec:bir-and-bir-builder}

\begin{itemize}
\tightlist
\item
  Only nongeneric functions (not closures or
  \href{https://doc.rust-lang.org/nightly/reference/items/associated-items.html\#associated-functions-and-methods}{associated
  functions and methods}) are currently supported. Other function-like
  items require special top-level handling. The handling of the body is
  identical. Generic functions must be monomorphised before checking.
\item
  Method calls are not handled due to implicit coercion of the
  \texttt{self} argument.
\item
  Operator \texttt{?} and \texttt{while\ let} are not handled. They are
  planned to be removed from HIR and desugared on the
  \texttt{AST-\textgreater{}HIR} boundary.
\item
  \texttt{if\ let} and \texttt{match} expressions are not handled due to
  missing handling for pattern detection (the selection of variant).
  Pattern destructuring is mostly implemented and used for \texttt{let}
  expressions and for function parameters. The
  \href{https://doc.rust-lang.org/reference/patterns.html\#or-patterns}{\texttt{or}
  pattern} is not supported. The declaration of a pattern without
  initial value is not supported except for the
  \href{https://doc.rust-lang.org/reference/patterns.html\#identifier-patterns}{identifier
  pattern}.
\item
  \href{https://doc.rust-lang.org/reference/types/enum.html}{Enums} are
  not supported.
\item
  Unsafe blocks are not supported.
\item
  Asynchronous code is completely unsupported in the compiler.
\item
  Unwind paths (drops) are not created. Drops are not supported by the
  compiler.
\item
  \href{https://rustc-dev-guide.rust-lang.org/borrow_check/two_phase_borrows.html}{Two-phase
  borrowing} is not implemented. This is not needed for correctness, but
  it reduced false positives of the borrow checker.
\item
  Location information is not stored. This is necessary for practical
  error reporting.
\item
  Copy trait probing is not performed. The \texttt{Copy} trait is only
  derived for primitive types and tuples of primitive types.
\item
  Not all fake operations are represented and emitted (e.g.,
  \texttt{fake\_unwind}).
\item
  Advanced projections like \texttt{cast} might need more complex
  handling.
\end{itemize}

\subsection{Parsing, AST, HIR, TyTy}\label{parsing-ast-hir-tyty}

\begin{itemize}
\tightlist
\item
  \href{https://doc.rust-lang.org/nightly/reference/lifetime-elision.html\#lifetime-elision}{Lifetime
  elision} is not handled.
\item
  Variance analysis does not import and export variance information
  using the metadata export. Currently, the analysis only considers one
  crate.
\item
  Region propagation in the type checker needs more testing. Especially
  cases regarding traits.
\item
  \href{https://doc.rust-lang.org/reference/trait-bounds.html\#higher-ranked-trait-bounds}{Late-bound
  lifetimes} are not handled.
\end{itemize}

\subsection{Fact Collection}\label{fact-collection}

\begin{itemize}
\tightlist
\item
  The implicit constraint between a reference and its base type
  (\texttt{\&\textquotesingle{}a\ T\ =\textgreater{}\ T:\ \textquotesingle{}a})
  is not collected.
\item
  The collection of the \texttt{loan\_killed\_at} fact is simplified.
\item
  Drop and unwind-related handling is not implemented due to incomplete
  support in other parts of the borrow checker.
\item
  \href{https://rustc-dev-guide.rust-lang.org/borrow_check/two_phase_borrows.html}{Two-phase
  borrowing} is not implemented. See sec.~\ref{sec:bir-and-bir-builder}.
\item
  The reason for loan invalidation is not stored. This is necessary for
  practical error reporting.
\item
  Rustc stores priority for subset facts to display more relevant
  errors. This is not implemented in gccrs.
\end{itemize}

\subsection{Polonius FFI and Error
Reporting}\label{polonius-ffi-and-error-reporting}

\begin{itemize}
\tightlist
\item
  Current integration with the build system is not viable for
  production. See the beginning of this
  \hyperref[implementation]{chapter}.
\item
  Only information about the violation's presence and its category is
  passed back to the borrow checker- no details about the violation
  itself are passed back.
\item
  Errors are reported only on function level (and using debug output).
  This can be problematic for automated testing because the test might
  fail/succeed for the wrong reason.
\end{itemize}

\section{Building, Usage, and
Debugging}\label{building-usage-and-debugging}

This section provides the reader with basic information on how to build
gccrs and use the borrow checker. It also provides tips for debugging.

The latest source code is available in the author's
\href{https://github.com/jdupak/gccrs/}{fork} in the branch
\href{https://github.com/jdupak/gccrs/tree/borrowck-stage2}{\texttt{borrowck-stage2}}.

Detailed instructions on how to build gccrs can be found in the
\texttt{README.md} in the root of the project. For tips on a better
development experience (e.g., faster builds), the reader can refer to
\citeproc{ref-svp}{{[}19{]}}.

The compiler binary is called \texttt{crab1}, and after building, it is
located in the \texttt{gcc} directory in the chosen build directory.
Since gccrs is still very experimental, a special flag
\texttt{-frust-incomplete-and-experimental-compiler-do-not-use} needs to
be added to use the compiler. Subsequently, the
\texttt{-frust-borrowcheck} flag needs to be used to enable the borrow
checker. If any borrow checker error is detected, it will be reported as
a standard compilation error.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{$ crab1 {-}frust{-}incomplete{-}and{-}experimental{-}compiler{-}do{-}not{-}use \textbackslash{}}
\NormalTok{      {-}frust{-}borrowcheck some\_rust\_code.rs}

\NormalTok{../../gcc/testsuite/rust/borrowck/borrowck{-}assign{-}comp.rs:5:1:}
\NormalTok{error: Found loan errors in function a}
\NormalTok{5 | fn a() \{ // \{ dg{-}error "Found loan errors in function a" \}}
\NormalTok{| \^{}\textasciitilde{} }
\end{Highlighting}
\end{Shaded}
\end{quote}

To further inspect the working of the borrow checker, a debug build of
the compiler is needed. The flag \texttt{-frust-debug} enables debug
logs that include the work of the borrow checker. Unfortunately, the GCC
debug logging does not support filtering by category. Three parts may
interest the reader: log of the variance analysis, log of the borrow
checker (BIR build and fact collector), and debug output of Polonius.
This flag also enables the BIR dump (saved to
\texttt{./bir\_dump/\textless{}crate\_name?\textgreater{}/\textless{}function\_name?\textgreater{}.bir.dump})
and facts dump (saved to
\texttt{nll\_facts\_gccrs/\textless{}function\_name\textgreater{}.facts}).

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{crab1: note: Variance analysis solving started:}
\NormalTok{crab1: note: Variance analysis results:}
\NormalTok{crab1: note:  Point\textless{}\textgreater{}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{../../}\NormalTok{gcc}\OperatorTok{/}\NormalTok{testsuite}\OperatorTok{/}\NormalTok{rust}\OperatorTok{/}\NormalTok{borrowck}\OperatorTok{/}\NormalTok{borrowck}\OperatorTok{{-}}\NormalTok{assign}\OperatorTok{{-}}\NormalTok{comp}\OperatorTok{.}\NormalTok{rs}\OperatorTok{:}\DecValTok{5}\OperatorTok{:}\DecValTok{1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:} 
\NormalTok{ Checking function a}

    \DecValTok{5} \OperatorTok{|} \KeywordTok{fn}\NormalTok{ a() }\OperatorTok{\{} \CommentTok{// \{ dg{-}error "Found loan errors in function a" \}}
      \OperatorTok{|} \OperatorTok{\^{}\textasciitilde{}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:} \PreprocessorTok{BIR::Builder::}\NormalTok{build function}\OperatorTok{=\{}\NormalTok{a}\OperatorTok{\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  ctx}\OperatorTok{.}\NormalTok{fn\_free\_region}\OperatorTok{=\{\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  handle\_lifetime\_param\_constraints}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{ visit\_statemensts}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize constraints of Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_4 }\OperatorTok{=}\NormalTok{ BorrowExpr(\_1)}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{      push\_subset}\OperatorTok{:} \CharTok{\textquotesingle{}}\ErrorTok{?2: }\CharTok{\textquotesingle{}}\OperatorTok{?}\DecValTok{1}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_5 }\OperatorTok{=}\NormalTok{ Assignment(\_6) at }\DecValTok{0}\OperatorTok{:}\DecValTok{5}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_9 }\OperatorTok{=}\NormalTok{ Assignment(\_8) at }\DecValTok{0}\OperatorTok{:}\DecValTok{7}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_0 }\OperatorTok{=}\NormalTok{ Assignment(\_10) at }\DecValTok{0}\OperatorTok{:}\DecValTok{11}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize field }\OperatorTok{.}\DecValTok{0}\NormalTok{ of Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize deref of }\OperatorTok{\&}\NormalTok{ Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize field }\OperatorTok{.}\DecValTok{0}\NormalTok{ of Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Subsets}\OperatorTok{:}
\NormalTok{ Mid(bb0[}\DecValTok{3}\NormalTok{])}\OperatorTok{:} \OperatorTok{\{}
     \DecValTok{2} \OperatorTok{\textless{}=} \DecValTok{1}
 \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

To get the corresponding output from rustc, use flags
\texttt{-Znll-facts\ -Zdump-mir=nll\ -Zidentify-regions}. With a debug
build of rustc, the reader can also enable the debug log of the borrow
checker using the environmental variable
\texttt{RUSTC\_LOG=rustc\_borrowck}. Building of the rustc compiler is
described in the
\href{https://rustc-dev-guide.rust-lang.org/building/how-to-build-and-run.html}{Rustc
Developer Guide}.

For more complex debugging and inspection, gdb/lldb can be used as
usual. One issue the reader may encounter is that LLDB might not be able
to identify virtual classes correctly. A simple LLDB formatter to
resolve TyTy classes based on internal identifiers can be found in
\href{https://gist.github.com/jdupak/68af0f0ad91f3e6eba2c478dc4f662dd}{this
gist}.

\chapter{Conclusion}\label{conclusion}

The goal of this project was to implement a prototype of a
Polonius-based borrow checker for Rustc GCC to explore the feasibility
of this approach and provide code infrastructure for further
development. The project was implemented in a
\href{https://github.com/jdupak/gccrs/}{personal fork}, and stabilized
parts are being submitted to the main
\href{https://github.com/Rust-GCC/gccrs}{Rustc GCC GitHub repository}.
All accepted changes are scheduled to be included in the
\href{https://gcc.gnu.org/git/}{central GCC repository} by the
maintainers of Rust CGG with the help of the author.

This text described the problem of borrow checking, mapped the situation
in rustc and gccrs, and presented the design of the solution, as well as
the experiments that led to this design. The prototype version of the
implemented borrow checker can detect the most common errors in simple
Rust code. Those include violations of access rules (number of allowed
loans of a given type, loan/access conflicts), move/initialization
errors, and subset errors. Examples of detected errors can be found in
the appendix.

The last chapter provides an overview of the limitations of the current
implementation. The limitations are not fundamental and should be
possible to resolve by simple extensions and implementation of missing
cases in the existing code. Future work should address this limitation
to provide a production-ready solution.

The problem of borrow checking is very complex, and a complete solution
is expected to take months, if not years, of future work. This project
provides a significant stepping stone on the way to a production ready
solution, as the prototype provides substantive infrastructure for
further development and solutions to most of the hard problems.

I believe that the Rust programming language will play a significant
role in systems programming, and I would like to continue working on
this project, other problems in Rustc GCC, or the rustc compiler itself.
It would seem that there is considerable interest in the industry as
well, since Bradley Spengler, President of Open Source Security, Inc.,
one of two main sponsors of Rust GCC, expressed interest in financially
supporting my continued work on Rust GCC. I am very grateful for this
opportunity.

\appendix

\chapter{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{0}
\bibitem[\citeproctext]{ref-Matsakis2014}
\CSLLeftMargin{{[}1{]} }%
\CSLRightInline{N. D. Matsakis and F. S. Klock, {``The rust language,''}
in \emph{Proceedings of the 2014 ACM SIGAda annual conference on high
integrity language technology}, Oct. 2014. doi:
\href{https://doi.org/10.1145/2663171.2663188}{10.1145/2663171.2663188}.}

\bibitem[\citeproctext]{ref-RustBelt}
\CSLLeftMargin{{[}2{]} }%
\CSLRightInline{N. Matsakis, {``Polonius: Either borrower or lender be,
but responsibly.''} Rust Belt Rust Conference, Jan. 2020. Accessed: Jan.
04, 2024. {[}Online{]}. Available:
\url{https://www.youtube.com/watch?v=_agDeiWek8w}}

\bibitem[\citeproctext]{ref-poloniusupdate}
\CSLLeftMargin{{[}3{]} }%
\CSLRightInline{R. Rakic and N. Matsakis, {``Polonius update.''} Oct.
2023. Accessed: Jan. 04, 2024. {[}Online{]}. Available:
\url{https://blog.rust-lang.org/inside-rust/2023/10/06/polonius-update.html}}

\bibitem[\citeproctext]{ref-eurorust}
\CSLLeftMargin{{[}4{]} }%
\CSLRightInline{A. Cohen, {``The road to compiling the standard library
with gccrs.''} EuroRust, 2023. Accessed: Jan. 05, 2024. {[}Online{]}.
Available: \url{https://www.youtube.com/watch?v=WgqGahDl-sY}}

\bibitem[\citeproctext]{ref-nsa}
\CSLLeftMargin{{[}5{]} }%
\CSLRightInline{\emph{{{``Software Memory Safety''}} {C}ybersecurity
{I}nformation {S}heet}. The National Security Agency, 2022. Accessed:
Dec. 29, 2023. {[}Online{]}. Available:
\url{https://media.defense.gov/2022/nov/10/2003112742/-1/-1/0/csi_software_memory_safety.pdf}}

\bibitem[\citeproctext]{ref-danglingpointer}
\CSLLeftMargin{{[}6{]} }%
\CSLRightInline{Mitre, {``CWE-416: Use after free.''} Accessed: Dec. 20,
2023. {[}Online{]}. Available:
\url{https://cwe.mitre.org/data/definitions/416.html}}

\bibitem[\citeproctext]{ref-reference}
\CSLLeftMargin{{[}7{]} }%
\CSLRightInline{Rustc developers, \emph{Reference}. Rust Foundation,
2023. Accessed: Dec. 07, 2023. {[}Online{]}. Available:
\url{https://doc.rust-lang.org/reference/}}

\bibitem[\citeproctext]{ref-rfc2094nll}
\CSLLeftMargin{{[}8{]} }%
\CSLRightInline{N. Matsakis, {``2094-nll,''} in \emph{The {R}ust {RFC}
{B}ook}, Rust Foundation, 2017. Accessed: Dec. 18, 2023. {[}Online{]}.
Available: \url{https://rust-lang.github.io/rfcs/2094-nll.html}}

\bibitem[\citeproctext]{ref-Stjerna2020}
\CSLLeftMargin{{[}9{]} }%
\CSLRightInline{A. Stjerna, {``{M}odelling {R}ust's {R}eference
{O}wnership {A}nalysis {D}eclaratively in {D}atalog,''} Master's thesis,
Uppsala University, 2020. Accessed: Dec. 28, 2023. {[}Online{]}.
Available:
\url{https://www.diva-portal.org/smash/get/diva2:1684081/fulltext01.pdf}}

\bibitem[\citeproctext]{ref-polonius2}
\CSLLeftMargin{{[}10{]} }%
\CSLRightInline{N. Matsakis, {``Polonius revisited, part 1.''} Sep. 22,
2023. Accessed: Dec. 17, 2023. {[}Online{]}. Available:
\url{https://smallcultfollowing.com/babysteps/blog/2023/09/22/polonius-part-1/}}

\bibitem[\citeproctext]{ref-polonius}
\CSLLeftMargin{{[}11{]} }%
\CSLRightInline{N. Matsakis, R. Rakic, \emph{et al.}, {``{T}he
{P}olonius {B}ook.''} Rust Foundation, 2021.}

\bibitem[\citeproctext]{ref-llvm}
\CSLLeftMargin{{[}12{]} }%
\CSLRightInline{\emph{Reference}. LLVM Project, 2023. Accessed: Dec. 15,
2023. {[}Online{]}. Available:
\url{https://llvm.org/docs/Reference.html}}

\bibitem[\citeproctext]{ref-gccint}
\CSLLeftMargin{{[}13{]} }%
\CSLRightInline{R. M. Stallman and the GCC Developer Community,
\emph{{GNU} {C}ompiler {C}ollection {I}nternals}, 14th ed. Free Software
Foundation, 2023. Accessed: Dec. 18, 2023. {[}Online{]}. Available:
\url{https://gcc.gnu.org/onlinedocs/gccint/}}

\bibitem[\citeproctext]{ref-devguide}
\CSLLeftMargin{{[}14{]} }%
\CSLRightInline{\emph{{R}ust {C}ompiler {D}evelopment {G}uide}. Rust
Foundation, 2023. Accessed: Dec. 18, 2023. {[}Online{]}. Available:
\url{https://rustc-dev-guide.rust-lang.org/index.html}}

\bibitem[\citeproctext]{ref-zulip}
\CSLLeftMargin{{[}15{]} }%
\CSLRightInline{{``{\#}{c}ompiler-development \textgreater{}
{B}orrowchecking vs ({H})IR - GCC rust - zulip.''} Sep. 05, 2023.
Accessed: Dec. 05, 2023. {[}Online{]}. Available:
\url{https://gcc-rust.zulipchat.com/\#narrow/stream/281658-compiler-development/topic/Borrowchecking.20vs.20.28H.29IR}}

\bibitem[\citeproctext]{ref-Altidor2011}
\CSLLeftMargin{{[}16{]} }%
\CSLRightInline{J. Altidor, S. S. Huang, and Y. Smaragdakis, {``Taming
the wildcards: Combining definition- and use-site variance,''} \emph{ACM
SIGPLAN Notices}, vol. 46, no. 6, pp. 602--613, Jun. 2011, doi:
\href{https://doi.org/10.1145/1993316.1993569}{10.1145/1993316.1993569}.}

\bibitem[\citeproctext]{ref-poloniusSource}
\CSLLeftMargin{{[}17{]} }%
\CSLRightInline{{``Polonius.''} Rust Foundation. Accessed: Dec. 29,
2023. {[}Online{]}. Available:
\url{https://github.com/rust-lang/polonius/}}

\bibitem[\citeproctext]{ref-rustcSource}
\CSLLeftMargin{{[}18{]} }%
\CSLRightInline{{``Rust.''} Rust Foundation. Accessed: Dec. 28, 2023.
{[}Online{]}. Available: \url{https://github.com/rust-lang/rust/}}

\bibitem[\citeproctext]{ref-svp}
\CSLLeftMargin{{[}19{]} }%
\CSLRightInline{J. Dupák, {``Contribution to the {R}ust front-end for
the {GCC} compiler,''} research report, Czech Technical University in
Prague, 2023. Accessed: Jan. 05, 2023. {[}Online{]}. Available:
\url{https://jakubdupak.com/dev/academic/dupakjak-svp-report.pdf}}

\bibitem[\citeproctext]{ref-polonius3}
\CSLLeftMargin{{[}20{]} }%
\CSLRightInline{N. Matsakis, {``Polonius revisited, part 2.''} Sep. 29,
2023. Accessed: Dec. 30, 2023. {[}Online{]}. Available:
\url{https://smallcultfollowing.com/babysteps/blog/2023/09/29/polonius-part-2/}}

\bibitem[\citeproctext]{ref-rustonomicon}
\CSLLeftMargin{{[}21{]} }%
\CSLRightInline{A. Beingessner \emph{et al.}, \emph{The {R}ustonomicon}.
Rust Foundation, 2023. Accessed: Dec. 15, 2023. {[}Online{]}. Available:
\url{https://doc.rust-lang.org/nomicon/}}

\end{CSLReferences}

\chapter{Rustc Intermediate Representations
Examples}\label{rustc-intermediate-representations-examples}

\begin{quote}
\textbf{Compilation commands:}

\texttt{\$\ rustc\ -Z\ unpretty=ast-tree}

\texttt{\$\ rustc\ -Z\ unpretty=hir-tree}

\texttt{\$\ rustc\ -Z\ unpretty=mir\ -Z\ identify-regions}
\end{quote}

\section{Rust Source Code}\label{rust-source-code}

\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{struct}\NormalTok{ Foo(}\DataTypeTok{i32}\NormalTok{)}\OperatorTok{;}

    \KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{        Foo(x)}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\clearpage

\section{Abstract Syntax Tree (AST)}\label{abstract-syntax-tree-ast}

\begin{verbatim}

Fn {
    defaultness: Final,
    generics: Generics {
        params: [],
        where_clause: WhereClause {
            has_where_token: false,
            predicates: [],
            span: simple.rs:3:22: 3:22 (#0),
        },
        span: simple.rs:3:7: 3:7 (#0),
    },
    sig: FnSig {
        header: FnHeader { unsafety: No, asyncness: No, constness: No },
        decl: FnDecl {
            inputs: [
                Param {
                    attrs: [],
                    ty: Ty {
                        id: NodeId(4294967040),
                        kind: Path(
                            None,
                            Path {
                                span: simple.rs:3:11: 3:14 (#0),
                                segments: [
                                    PathSegment {
                                        ident: i31#0,
                                        id: NodeId(4294967040),
                                        args: None,
                                    },
                                ],
                                tokens: None,
                            },
                        ),
                        span: simple.rs:3:11: 3:14 (#0),
                        tokens: None,
                    },
                    pat: Pat {
                        id: NodeId(4294967040),
                        kind: Ident(
                            BindingAnnotation(No, Not),
                            x#0,
                            None,
                        ),
                        span: simple.rs:3:8: 3:9 (#0),
                        tokens: None,
                    },
                    id: NodeId(4294967040),
                    span: simple.rs:3:8: 3:14 (#0),
                    is_placeholder: false,
                },
            ],
            output: Ty(
                Ty {
                    id: NodeId(4294967040),
                    kind: Path(
                        None,
                        Path {
                            span: simple.rs:3:19: 3:22 (#0),
                            segments: [
                                PathSegment {
                                    ident: Foo#0,
                                    id: NodeId(4294967040),
                                    args: None,
                                },
                            ],
                            tokens: None,
                        },
                    ),
                    span: simple.rs:3:19: 3:22 (#0),
                    tokens: None,
                },
            ),
        },
        span: simple.rs:3:1: 3:22 (#0),
    },
    body: Some(
        Block {
            stmts: [
                Stmt {
                    id: NodeId(4294967040),
                    kind: Expr(
                        Expr {
                            id: NodeId(4294967040),
                            kind: Call(
                                Expr {
                                    id: NodeId(4294967040),
                                    kind: Path(
                                        None,
                                        Path {
                                            span: simple.rs:4:5: 4:8 (#0),
                                            segments: [
                                                PathSegment {
                                                    ident: Foo#0,
                                                    id: NodeId(4294967040),
                                                    args: None,
                                                },
                                            ],
                                            tokens: None,
                                        },
                                    ),
                                    span: simple.rs:4:5: 4:8 (#0),
                                    attrs: [],
                                    tokens: None,
                                },
                                [
                                    Expr {
                                        id: NodeId(4294967040),
                                        kind: Path(
                                            None,
                                            Path {
                                                span: simple.rs:4:9: 4:10 (#0),
                                                segments: [
                                                    PathSegment {
                                                        ident: x#0,
                                                        id: NodeId(4294967040),
                                                        args: None,
                                                    },
                                                ],
                                                tokens: None,
                                            },
                                        ),
                                        span: simple.rs:4:9: 4:10 (#0),
                                        attrs: [],
                                        tokens: None,
                                    },
                                ],
                            ),
                            span: simple.rs:4:5: 4:11 (#0),
                            attrs: [],
                            tokens: None,
                        },
                    ),
                    span: simple.rs:4:5: 4:11 (#0),
                },
            ],
            id: NodeId(4294967040),
            rules: Default,
            span: simple.rs:3:23: 5:2 (#0),
            tokens: None,
            could_be_bare_literal: false,
        },
    ),
}
\end{verbatim}

\normalsize

\section{High-Level Intermediate Representation
(HIR)}\label{high-level-intermediate-representation-hir}

\small

\begin{verbatim}
Fn(
    FnSig {
        header: FnHeader {
            unsafety: Normal,
            constness: NotConst,
            asyncness: NotAsync,
            abi: Rust,
        },
        decl: FnDecl {
            inputs: [
                Ty {
                    hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).10),
                    kind: Path(
                        Resolved(
                            None,
                            Path {
                                span: simple.rs:3:11: 3:14 (#0),
                                res: PrimTy(
                                    Int(
                                        I32,
                                    ),
                                ),
                                segments: [
                                    PathSegment {
                                        ident: i32#0,
                                        hir_id: HirId(
                                            DefId(0:6 ~ simple[415f]::foo).11),
                                        res: PrimTy(
                                            Int(
                                                I32,
                                            ),
                                        ),
                                        args: None,
                                        infer_args: false,
                                    },
                                ],
                            },
                        ),
                    ),
                    span: simple.rs:3:11: 3:14 (#0),
                },
            ],
            output: Return(
                Ty {
                    hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).12),
                    kind: Path(
                        Resolved(
                            None,
                            Path {
                                span: simple.rs:3:19: 3:22 (#0),
                                res: Def(
                                    Struct,
                                    DefId(0:3 ~ simple[415f]::Foo),
                                ),
                                segments: [
                                    PathSegment {
                                        ident: Foo#0,
                                        hir_id: HirId(
                                            DefId(0:6 ~ simple[415f]::foo).13),
                                        res: Def(
                                            Struct,
                                            DefId(0:3 ~ simple[415f]::Foo),
                                        ),
                                        args: None,
                                        infer_args: false,
                                    },
                                ],
                            },
                        ),
                    ),
                    span: simple.rs:3:19: 3:22 (#0),
                },
            ),
            c_variadic: false,
            implicit_self: None,
            lifetime_elision_allowed: false,
        },
        span: simple.rs:3:1: 3:22 (#0),
    },
    Generics {
        params: [],
        predicates: [],
        has_where_clause_predicates: false,
        where_clause_span: simple.rs:3:22: 3:22 (#0),
        span: simple.rs:3:7: 3:7 (#0),
    },
    BodyId {
        hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).9),
    },
)

...

Expr {
    hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).3),
    kind: Call(
        Expr {
            hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).4),
            kind: Path(
                Resolved(
                    None,
                    Path {
                        span: simple.rs:4:5: 4:8 (#0),
                        res: Def(
                            Ctor(
                                Struct,
                                Fn,
                            ),
                            DefId(0:4 ~ simple[415f]::Foo::{constructor#0}),
                        ),
                        segments: [
                            PathSegment {
                                ident: Foo#0,
                                hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).5),
                                res: Def(
                                    Ctor(
                                        Struct,
                                        Fn,
                                    ),
                                    DefId(0:4 ~ simple[415f]::Foo::{constructor#0}),
                                ),
                                args: None,
                                infer_args: true,
                            },
                        ],
                    },
                ),
            ),
            span: simple.rs:4:5: 4:8 (#0),
        },
        [
            Expr {
                hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).6),
                kind: Path(
                    Resolved(
                        None,
                        Path {
                            span: simple.rs:4:9: 4:10 (#0),
                            res: Local(
                                HirId(DefId(0:6 ~ simple[415f]::foo).2),
                            ),
                            segments: [
                                PathSegment {
                                    ident: x#0,
                                    hir_id: HirId(
                                        DefId(0:6 ~ simple[415f]::foo).7),
                                    res: Local(
                                        HirId(
                                            DefId(0:6 ~ simple[415f]::foo).2),
                                    ),
                                    args: None,
                                    infer_args: true,
                                },
                            ],
                        },
                    ),
                ),
                span: simple.rs:4:9: 4:10 (#0),
            },
        ],
    ),
    span: simple.rs:4:5: 4:11 (#0),
}
\end{verbatim}

\normalsize

\section{Mid-Level Intermediate Representation
(MIR)}\label{mid-level-intermediate-representation-mir}

\begin{verbatim}
fn foo(_1: i32) -> Foo {
    debug x => _1;
    let mut _0: Foo;    

    bb0: {
        _0 = Foo(_1);
        return;
    }
}

fn Foo(_1: i32) -> Foo {
    let mut _0: Foo;    

    bb0: {
        _0 = Foo(move _1);
        return;
    }
}
\end{verbatim}

\chapter{Comparison of BIR and MIR}\label{comparison-of-bir-and-mir}

BIR and MIR dump of the following code are displayed parallel, BIR on
left pages and MIR on right pages. Note that assert macros in MIR were
simplified to fit onto the page.

\section{Compilation Commands}\label{compilation-commands}

\begin{quote}
\begin{verbatim}
$ crab1 -frust-incomplete-and-experimental-compiler-do-not-use \
        -frust-dump-bir -frust-borrowcheck
\end{verbatim}

\texttt{\$\ rustc\ -Zdump-mir=nll\ -Zidentify-regions}
\end{quote}

\section{Rust Source Code}\label{rust-source-code-1}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ fib(n}\OperatorTok{:} \DataTypeTok{u32}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \DataTypeTok{u32} \OperatorTok{\{}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ n }\OperatorTok{==} \DecValTok{1} \OperatorTok{\{}
        \DecValTok{1}
    \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
\NormalTok{        fib(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\NormalTok{ fib(n }\OperatorTok{{-}} \DecValTok{2}\NormalTok{)}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Parallel}[p]{}{}
\ParallelLText{

\section{BIR (Rustc GCC)}\label{bir-rustc-gcc}

\small

\begin{verbatim}
fn fib(_2: u32) -> u32 {
        let _1: u32;    []
        let _2: u32;    []
        let _3: bool;   []
        let _5: u32;    []
        let _6: bool;   []
        let _8: u32;    []
        let _9: bool;   []
        scope 2 {
            let _14: u32;   []
            let _15: u32;   []
            let _16: u32;   []
            let _19: u32;   []
            let _20: u32;   []
            let _21: u32;   []
        }

    bb0: {
    0    StorageLive(_3);
    1    StorageLive(_5);
    2    _5 = _2;
    3    StorageLive(_6);
    4    _6 = Operator(move _5, const u32);
    5    switchInt(move _6) -> [bb1, bb2];
    }

    bb1: {
    0    _3 = const bool;
    1    goto -> bb3;
    }

    bb2: {
    0    StorageLive(_8);
    1    _8 = _2;
    2    StorageLive(_9);
    3    _9 = Operator(move _8, const u32);
    4    _3 = move _9;
    5    goto -> bb3;
    }

    bb3: {
    0    switchInt(move _3) -> [bb4, bb5];
    }

    bb4: {
    0    _1 = const u32;
    1    goto -> bb8;
    }

    bb5: {
    0    StorageLive(_14);
    1    _14 = _2;
    2    StorageLive(_15);
    3    _15 = Operator(move _14, const u32);
    4    StorageLive(_16);
    5    _16 = Call(fib)(move _15) -> [bb6];
    }

    bb6: {
    0    StorageLive(_19);
    1    _19 = _2;
    2    StorageLive(_20);
    3    _20 = Operator(move _19, const u32);
    4    StorageLive(_21);
    5    _21 = Call(fib)(move _20) -> [bb7];
    }

    bb7: {
    0    _1 = Operator(move _16, move _21);
    1    StorageDead(_21);
    2    StorageDead(_20);
    3    StorageDead(_19);
    4    StorageDead(_16);
    5    StorageDead(_15);
    6    StorageDead(_14);
    7    goto -> bb8;
    }

    bb8: {
    0    StorageDead(_9);
    1    StorageDead(_8);
    2    StorageDead(_6);
    3    StorageDead(_5);
    4    StorageDead(_3);
    5    return;
    }
}
\end{verbatim}

}
\ParallelRText{

\section{MIR (rustc)}\label{mir-rustc}

\small

\begin{verbatim}
fn fib(_1: u32) -> u32 {
    debug n => _1;
    let mut _0: u32;    
    let mut _2: bool;   
    let mut _3: u32;    
    let mut _4: bool;   
    let mut _5: u32;    
    let mut _6: u32;    
    let mut _7: u32;    
    let mut _8: u32;    
    let mut _9: (u32, bool);    
    let mut _10: u32;   
    let mut _11: u32;   
    let mut _12: u32;   
    let mut _13: (u32, bool);   
    let mut _14: (u32, bool);   

    bb0: {
        StorageLive(_2);
        StorageLive(_3);
        _3 = _1;
        _2 = Eq(move _3, const 0_u32);
        switchInt(move _2) -> [0: bb2, otherwise: bb1];
    }

    bb1: {
        StorageDead(_3);
        goto -> bb3;
    }

    bb2: {
        StorageDead(_3);
        StorageLive(_4);
        StorageLive(_5);
        _5 = _1;
        _4 = Eq(move _5, const 1_u32);
        switchInt(move _4) -> [0: bb4, otherwise: bb3];
    }

    bb3: {
        StorageDead(_5);
        _0 = const 1_u32;
        goto -> bb10;
    }

    bb4: {
        StorageDead(_5);
        StorageLive(_6);
        StorageLive(_7);
        StorageLive(_8);
        _8 = _1;
        _9 = CheckedSub(_8, const 1_u32);
        assert(!move (_9.1: bool)) -> [success: bb5, unwind: bb11];
    }

    bb5: {
        _7 = move (_9.0: u32);
        StorageDead(_8);
        _6 = fib(move _7) -> [return: bb6, unwind: bb11];
    }

    bb6: {
        StorageDead(_7);
        StorageLive(_10);
        StorageLive(_11);
        StorageLive(_12);
       _12 = _1;
        _13 = CheckedSub(_12, const 2_u32);
        assert(!move (_13.1: bool)) -> [success: bb7, unwind: bb11];
    }

    bb7: {
        _11 = move (_13.0: u32);
        StorageDead(_12);
        _10 = fib(move _11) -> [return: bb8, unwind: bb11];
    }

    bb8: {
        StorageDead(_11);
        _14 = CheckedAdd(_6, _10);
        assert(!move (_14.1: bool)) -> [success: bb9, unwind: bb11];
    }

    bb9: {
        _0 = move (_14.0: u32);
        StorageDead(_10);
        StorageDead(_6);
        goto -> bb10;
    }

    bb10: {
        StorageDead(_4);
        StorageDead(_2);
        return;
    }

    bb11 (cleanup): {
        resume;
    }
}

}
\end{verbatim}

}
\end{Parallel}

\chapter{Examples of Errors Detected by the
Borrow-Checker}\label{sec:errors}

A faulty program from gccrs test suite together with a fixed alternative
(when applicable) is presented. Expected errors are marked using special
comments used by the DejaGnu compiler testing framework.

\section{Move Errors}\label{move-errors}

A simple test, where an instance of type A, which is not trivially
copiable (does not implement the compy trait) is moved twice.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found move errors in function test\_move" \}}
    \KeywordTok{struct}\NormalTok{ A }\OperatorTok{\{}
\NormalTok{        i}\OperatorTok{:} \DataTypeTok{i32}\OperatorTok{,}
    \OperatorTok{\}}
    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=}\NormalTok{ A }\OperatorTok{\{}\NormalTok{ i}\OperatorTok{:} \DecValTok{1} \OperatorTok{\};}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_fixed() }\OperatorTok{\{}
    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// a is now primitive and can be copied}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

More complex text test, where moves the occurence of the error depends
on runtime values. Error is raised bacause for some values, the
violation is possible

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_conditional(b1}\OperatorTok{:} \DataTypeTok{bool}\OperatorTok{,}\NormalTok{ b2}\OperatorTok{:}\DataTypeTok{bool}\NormalTok{) }\OperatorTok{\{}
     \CommentTok{// \{ dg{-}error "Found move errors in function test\_move" \}}
    \KeywordTok{struct}\NormalTok{ A }\OperatorTok{\{}
\NormalTok{        i}\OperatorTok{:} \DataTypeTok{i32}\OperatorTok{,}
    \OperatorTok{\}}

    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=}\NormalTok{ A }\OperatorTok{\{}\NormalTok{ i}\OperatorTok{:} \DecValTok{1} \OperatorTok{\};}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if}\NormalTok{ b1 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if}\NormalTok{ b2 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_fixed(b1}\OperatorTok{:} \DataTypeTok{bool}\OperatorTok{,}\NormalTok{ b2}\OperatorTok{:}\DataTypeTok{bool}\NormalTok{) }\OperatorTok{\{}

    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// a is now primitive and can be copied}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if}\NormalTok{ b1 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if}\NormalTok{ b2 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\section{Subset Errors}\label{subset-errors}

TODO

\section{Loan Error}\label{loan-error}

TODO

The following test were used when Polonius was first experimentally
integrated into rustc.

In this test \texttt{s} is moved while it is borrowed. The test checks
that facts are corectly propagated through the function call.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ foo}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{,} \OtherTok{\textquotesingle{}b}\OperatorTok{\textgreater{}}\NormalTok{(p}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}b} \OperatorTok{\&}\OtherTok{\textquotesingle{}a} \KeywordTok{mut} \DataTypeTok{usize}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \OperatorTok{\&}\OtherTok{\textquotesingle{}b}\OperatorTok{\&}\OtherTok{\textquotesingle{}a} \KeywordTok{mut} \DataTypeTok{usize} \OperatorTok{\{}
\NormalTok{    p}
\OperatorTok{\}}

\KeywordTok{fn}\NormalTok{ well\_formed\_function\_inputs() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found loan errors in function well\_formed...}
    \KeywordTok{let}\NormalTok{ s }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \DecValTok{1}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ r }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \OperatorTok{*}\NormalTok{s}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ foo(}\OperatorTok{\&}\NormalTok{r  )}\OperatorTok{;}
\NormalTok{    s}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
\NormalTok{    tmp}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

This test check that variable cannot be used while borrowed.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ use\_while\_mut() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found loan errors in function use\_while\_mut" \}}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ x }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ x}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ z }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
    \KeywordTok{let}\NormalTok{ w }\OperatorTok{=}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

This test is similar to the previous one but uses a reborrow of a
reference passed as an argument.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ use\_while\_mut\_fr(x}\OperatorTok{:} \OperatorTok{\&}\KeywordTok{mut} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \OperatorTok{\&}\KeywordTok{mut} \DataTypeTok{i32} \OperatorTok{\{} 
    \CommentTok{// \{ dg{-}error "Found loan errors in function use\_while\_mut\_fr" \}}
    \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \OperatorTok{*}\NormalTok{x}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ z }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
\NormalTok{    y}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\chapter{Glossary}\label{glossary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6667}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ABI & Application Binary Interface \\
3-AD & Three Address Code \\
API & Application Programming Interface \\
AST & Abstract Syntax Tree \\
BIR & (gccrs) Borrow-Checker Intermediate Representation \\
CFG & Control Flow Graph \\
CLI & Command Line Interface \\
GCC & GNU Compiler Collection \\
GENERIC & (GCC) The internal representation used by GCC as an interface
between the front-end and the middle-end of the compiler \\
GIMPLE & (GCC) The internal representation used by GCC in the middle-end
of the compiler \\
HIR & (rustc, gccrs) High-level Intermediate Representation \\
IR & Intermediate Representation \\
LLVM & Low Level Virtual Machine \\
MIR & (rustc) Mid-level Intermediate Representation \\
MIRI & (rustc) The Rust MIR interpreter \\
NLL & (rustc) Non-Lexical Lifetimes (a CFG-based borrow-checker) \\
Polonius & The name of the new borrow-checker algorithm and engine \\
RAII & Resource Acquisition Is Initialization (C++ idiom) \\
RFC & Request For Comments (formal process for proposing changes to
Rust) \\
SSA & Static Single Assignment \\
THIR & (rustc) Typed High-level Intermediate Representation \\
TyTy & (rustc, gccrs) Type Intermediate Representation (used after types
are parsed and resolved) \\
basic block & A sequence of instructions with a single entry point and a
single exit point \\
borrow & (Polonius) The act of taking a checked reference \\
fact & (Polonius) Information about the program, reduced to a relation
between enumerated program objects \\
gccrs & GCC Rust Front-end \\
interning & The process of replacing a value with a unique identifier \\
loan & (Polonius) The result of a borrow operation (taking a checked
reference). \\
origin & (Polonius) An inference variable that represents a set of
loans. May be used interchangeably with \emph{region}. \\
outlives & (Polonius) A relationship between two origins, where the
first region must live longer than the second region. Denoted as
\texttt{R1:\ R2} where \texttt{R1} outlives \texttt{R2}. That means that
the set of CFG points R1 represents must be a superset of the set of CFG
points R2 represents. \\
point & (Polonius) A point in the CFG \\
region & (Polonius/NLL) An inference variable that represents a set of
points in the CFG. May be used interchangeably with \emph{origin}. \\
rustc & The main Rust Compiler based on LLVM \\
usize & Unsigned integer type with the same size as a pointer in Rust \\
\end{longtable}

\end{document}
