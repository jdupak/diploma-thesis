% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  twoside,symmetric]{report}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[BoldFont=Technika-Regular,BoldItalicFont=Technika-Italic]{Latin
Modern Roman}
  \setsansfont[UprightFont = *-Light,,BoldFont = *-Regular,,ItalicFont =
*-LightItalic,,BoldItalicFont = *-Italic,]{Technika}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[a4paper,top=32mm,left=35.6mm,right=35.6mm,bottom=30mm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textbf{#1}}
\newcommand{\AnnotationTok}[1]{\textit{#1}}
\newcommand{\AttributeTok}[1]{#1}
\newcommand{\BaseNTok}[1]{#1}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textit{#1}}
\newcommand{\CommentVarTok}[1]{\textit{#1}}
\newcommand{\ConstantTok}[1]{#1}
\newcommand{\ControlFlowTok}[1]{\textbf{#1}}
\newcommand{\DataTypeTok}[1]{\underline{#1}}
\newcommand{\DecValTok}[1]{#1}
\newcommand{\DocumentationTok}[1]{\textit{#1}}
\newcommand{\ErrorTok}[1]{\textbf{#1}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{#1}
\newcommand{\FunctionTok}[1]{#1}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textit{#1}}
\newcommand{\KeywordTok}[1]{\textbf{#1}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{#1}
\newcommand{\OtherTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textbf{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{#1}
\newcommand{\SpecialStringTok}[1]{#1}
\newcommand{\StringTok}[1]{#1}
\newcommand{\VariableTok}[1]{#1}
\newcommand{\VerbatimStringTok}[1]{#1}
\newcommand{\WarningTok}[1]{\textit{#1}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\usepackage{svg}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{english}
\ifPDFTeX
\else
\babelfont{rm}[BoldFont=Technika-Regular,BoldItalicFont=Technika-Italic]{Latin
Modern Roman}
\fi
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\input{../template/style.tex}
\input{../template/front.tex}
\University{Czech Technical University in Prague}
\Faculty{Faculty of Electrical Engineering}
\Department{Department of Measurement}
\StudyProgram{Open Informatics}
\FieldOfStudy{Computer Engineering}
\Supervisor{Ing. Pavel Píša Ph.D.}
\Advisor{MSc. Arthur Cohen}
\makeatletter
\@ifpackageloaded{subfig}{}{\usepackage{subfig}}
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\captionsetup[subfloat]{margin=0.5em}
\AtBeginDocument{%
\renewcommand*\figurename{Figure}
\renewcommand*\tablename{Table}
}
\AtBeginDocument{%
\renewcommand*\listfigurename{List of Figures}
\renewcommand*\listtablename{List of Tables}
}
\newcounter{pandoccrossref@subfigures@footnote@counter}
\newenvironment{pandoccrossrefsubfigures}{%
\setcounter{pandoccrossref@subfigures@footnote@counter}{0}
\begin{figure}\centering%
\gdef\global@pandoccrossref@subfigures@footnotes{}%
\DeclareRobustCommand{\footnote}[1]{\footnotemark%
\stepcounter{pandoccrossref@subfigures@footnote@counter}%
\ifx\global@pandoccrossref@subfigures@footnotes\empty%
\gdef\global@pandoccrossref@subfigures@footnotes{{##1}}%
\else%
\g@addto@macro\global@pandoccrossref@subfigures@footnotes{, {##1}}%
\fi}}%
{\end{figure}%
\addtocounter{footnote}{-\value{pandoccrossref@subfigures@footnote@counter}}
\@for\f:=\global@pandoccrossref@subfigures@footnotes\do{\stepcounter{footnote}\footnotetext{\f}}%
\gdef\global@pandoccrossref@subfigures@footnotes{}}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
% Make links footnotes instead of hotlinks:
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
\hypersetup{
  pdftitle={Memory Safety Analysis in Rust GCC},
  pdfauthor={Jakub Dupák},
  pdflang={en},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Memory Safety Analysis in Rust GCC}
\author{Jakub Dupák}
\date{January 2024}

\begin{document}
\maketitle

\pagenumbering{roman}

\includepdf[pages=-]{Thesis_Assignment_Jakub_Dupák_Memory_safety_analysis_in_Rust_GCC.pdf}

\clearpage

\ack{I express my gratitude to Jeremy Bennett for providing me with the opportunity to work on this project. I would also like to thank Arthur Cohen and Philip Herron, the maintainers of the Rust GCC project, for their consultations and reviews, and Pavel Píša for my introduction to the professional open-source developer community. \\ Furthermore, I would like to acknowledge our entire study group, Max Hollmann, Matěj Kafka, Vojtěch Štěpančík and Jáchym Herynek, for endless technical discussions and mental support. \\ Finally, I would like to thank my family for their continuous support.}

\declaration

\abstract{This thesis presents the first attempt to implement a memory safety analysis, known as the borrow checker, within the Rust GCC compiler. It utilizes the Polonius engine, which was designed as the next-generation borrow checker for rustc. The text describes the design of this analysis, the necessary modifications of the compiler, and compares the internal representations between rustc and gccrs. This comparison highlights the challenges in adapting the rustc borrow checker design to gccrs. The thesis concludes with a discussion of the results and known limitations.}{compiler, Rust, borrow checker, static analysis, GCC, Polonius}{Tato práce představuje první pokus o realizaci analýzy paměťové bezpečnosti, nazývané borrow-checker, v překladači Rust GCC. Analýza využívá systém Polonius, který je vytvořen jako nová generace borrow-checkeru pro překladač rustc. Práce popisuje návrh analýzy, úprav překladače a porovnává vnitřní reprezentaci překladačů rustc a gccrs a poukazuje na problémy při adaptaci návrhu borrow-checkeru z překladače rustc na překladač gccrs. Práci uzavírá diskusí o výsledcích a známých omezeních.}{překladač, Rust, borrow checker, statická analýza, GCC, Polonius}

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\clearpage
\pagenumbering{arabic}

\chapter{Introduction}\label{sec:introduction}

Rust is a modern systems programming language that aims to provide
memory safety without runtime
overhead\citeproc{ref-Matsakis2014}{{[}1{]}}. To achieve this goal, a
Rust compiler has to perform a static analysis to ensure that the memory
safety rules are not violated. This analysis is commonly called the
\emph{borrow checker}. The borrow checker is a complex analysis that has
been evolving throughout the history of the Rust language and its
reference implementation compiler, \emph{rustc}. It evolved from a
simple lexical analysis to a control-flow sensitive analysis, gradually
providing a more precise validation. The experimental version of the
rustc compiler uses a new analysis engine and algorithm called
\emph{Polonius}. The algorithm changes some fundamental views on the
internal semantics of the analysis to allow more programs to be accepted
and provides better error reporting for rejected
programs\citeproc{ref-RustBelt}{{[}2{]}}. The
\href{https://rust-lang.github.io/compiler-team/working-groups/polonius/}{Polonius
Working Group} is planning to replace the current rustc borrow checker
with one based on Polonius in the Rust language edition
2024\citeproc{ref-poloniusupdate}{{[}3{]}}.

Rust GCC, also known as gccrs, is one of the emerging alternative Rust
compilers. Unlike mrustc and rustc\_codegen\_gcc, gccrs aims to build a
complete general-purpose Rust compiler independent of rustc. Gccrs aims
to offer a rustc-compatible, drop-in replacement, capitalizing on the
mature and diverse features of the GCC infrastructure. GCC (compared to
LLVM) offers more target platforms and different optimizations and
provides security plugins (originally designed for C) that could be used
to find errors in
\href{https://doc.rust-lang.org/reference/unsafety.html}{\emph{unsafe}}
Rust code\citeproc{ref-eurorust}{{[}4{]}}. The goal of this thesis was
to start the development of a Polonius-based borrow checker in gccrs.

The first chapter introduces the problem of borrow checking. It gives a
brief overview of the development of the borrow checker in the rustc
compiler, up to the Polonius project. The second chapter describes the
Polonius analysis engine and its API. The third chapter compares the
internal representations of rustc and gccrs to highlight the challenges
of adapting the rustc borrow checker design to gccrs. The next chapter
explains the design of the borrow checker implemented in gccrs as part
of this work. It maps the experiments that lead to the current design
and describes the new intermediate representation and its usage in the
analysis. Later sections of the chapter describe other modifications of
the rest of the compiler necessary to support borrow checking. The final
chapter elaborates on the implementation, its development, the current
state and the known missing features and limitations.

\chapter{The Problem of Borrow
Checking}\label{sec:the-problem-of-borrow-checking}

This section introduces the concept of borrow checking and traces its
development within the Rust programming language. It presents the simple
lexical approach, followed by an explanation of a more advanced
control-flow sensitive analysis and an introduction to the Polonius
analysis engine, the latest approach to borrow checking in Rust. Since
this work utilizes the Polonius engine, it is described in more detail
in the following chapter.

Typical programming language implementations manage memory with dynamic
storage duration in one of two ways\footnote{Dynamic storage duration
  means that it is unknown at compile time when storage can be safely
  reclaimed. In contrast, memory with static storage duration is
  reclaimed at the end of the program, and memory with automatic storage
  duration is bound to a function call.}. Languages like C employ manual
memory management, where programmers explicitly allocate and free
memory, a method prone to errors\citeproc{ref-nsa}{{[}5{]}}. In
contrast, higher-level languages such as Java and Python use automatic
memory management, where runtime garbage collectors handle memory
management tasks.

Addressing the pitfalls of manual memory management, languages like C++
and \href{https://ziglang.org/}{Zig} have introduced tools for more
implicit memory deallocation. In simple situations, these tools tie
memory deallocation to the destruction of objects, utilizing concepts
like \href{https://en.cppreference.com/w/cpp/language/raii}{RAII},
\href{https://en.cppreference.com/w/cpp/memory\#Smart_pointers}{smart-pointers},
and \href{https://ziglang.org/documentation/master/\#defer}{defer
statements}. Here, the key difference from stack allocation is that the
ownership can be dynamically transferred between objects. In more
complex situations, where multiple objects share memory and deallocation
is tied to the last object's destruction, these languages opt-in for
runtime solutions like
\href{https://en.wikipedia.org/wiki/Reference_counting}{reference
counting}.

Despite these improvements, two serious problems remain. First,
programmers can incorrectly establish and maintain ownership binds,
especially during dynamic ownership transfers between objects. This
issue can very often occur when interfacing systems with differing
memory management models\footnote{An interface between a C++ application
  with
  \href{https://www.cppreference.com/Cpp_STL_ReferenceManual.pdf}{STL-based}
  memory management and the \href{https://www.qt.io/}{Qt GUI framework},
  where all Qt API methods take raw pointers (as opposed to smart
  pointers). Some of those methods assume that the ownership is
  transferred, and some of them do not. These methods can only be
  differentiated using their documentation.}. Second, issue appears when
the ownership is not transferred, but a copy of the pointer is used
temporarily (this is called \emph{borrowing} in Rust). The assumption
that the owning object will exist for the whole time this copy is used
is often wrong. This kind of mistake is called a \emph{dangling
pointer}.\citeproc{ref-danglingpointer}{{[}6{]}}.

Rust's memory safety strategy builds upon the RAII approach, but it
introduces a built-in static analysis, known as the borrow checker, to
prevent the above-mentioned memory errors. To make the analysis
feasible, Rust allows only a conservative subset of memory-safe
operations. Furthermore, Rust adds additional limitations to ensure that
memory use is safe even during multithreaded execution. Because these
restrictions are very strict and would severely limit the language, Rust
allows certain restrictions to be bypassed in \emph{unsafe} code blocks,
placing the responsibility for maintaining safety invariants on the
programmer.

The key idea behind Rust's approach is the strict differentiation
between ownership transfers and borrowing, achieved through its type
system. An ownership transfer, called ``move'' in Rust (and C++), binds
owned unique resources to another object, detaching them from the
current object. Rust simplifies this operation to a mere bitwise copy by
restricting objects from storing a reference to itself. It also ensures
the original object cannot be used after the move operation.

For borrows, Rust uses static analysis to ensure that any borrowed
object is not deallocated during its use, requiring the borrowed object
to \emph{outlive} the borrow. This analysis is limited to individual
functions to ensure analysis feasibility. Programmers are required to
formally describe the relationships of borrows within function inputs
and outputs using so-called \emph{lifetimes}. Lifetimes are a special
kind of type parameter that can be used to describe a part of program
where concerned references must be valid. One can image a lifetime as an
inference variables, for which the compiler has to find a valid value (a
subset of the program). Lifetime annotations are related using
\emph{outlives} relationships, indicating that one reference's lifetime
is a subset of another.

Throughout Rust's borrow checking development, the interpretation of
\emph{a subset of the program} has evolved. Initially it was based on
expressions, then control flow graph (CFG) points, and later potentially
used borrows.

\begin{quote}
\textbf{Example}: Consider a vector-like structure storing references to
integers without owning them. We introduce a lifetime parameter
\texttt{\textquotesingle{}a} to represent the parts of the program where
the vector must be valid, substituted with a concrete lifetime at each
use site.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \DataTypeTok{Vec}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \OperatorTok{\{} \OperatorTok{...} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

The add method has a separate lifetime parameter
\texttt{\textquotesingle{}b} for the inserted reference. Each method
invocation substitutes \texttt{\textquotesingle{}b} with the concrete
lifetime of the reference. The compiler ensures
\texttt{\textquotesingle{}b} outlives \texttt{\textquotesingle{}a}
(imposed by the \texttt{\textquotesingle{}b:\ \textquotesingle{}a}
constraint), ensuring all references in the vector remain valid as long
as the vector exists.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \DataTypeTok{Vec}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \OperatorTok{\{}
  \KeywordTok{fn}\NormalTok{ add}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}b}\OperatorTok{\textgreater{}} \KeywordTok{where} \OtherTok{\textquotesingle{}b}\OperatorTok{:} \OtherTok{\textquotesingle{}a}\NormalTok{ (}\OperatorTok{\&}\KeywordTok{mut} \KeywordTok{self}\OperatorTok{,}\NormalTok{ x}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}b} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{\{} \OperatorTok{...} \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\section{The Evolution of Borrow Checking in Rustc}\label{sec:evolution}

This section describes how the analysis evolved, gradually rejecting
less memory-safe programs. Rustc started with lexical (scope-based
analysis), followed by the first non-lexical (CFG-based) analysis, which
is being extended by the Polonius project. This section strongly builds
upon RFC 2094\citeproc{ref-rfc2094nll}{{[}7{]}}, which introduced
non-lexical borrow checking to Rust. Examples from the RFC are presented
in this section.

The simplest variant of borrow checker is based on stack variable
scopes. A reference is valid from the point in the program (here in
terms of statements and expressions) where it is created until the end
of the current scope. This approach can be extended to handle some
common programming patterns as special cases. For example, when a
reference is created in function parameters, it is valid until the end
of the function call.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;} \CommentTok{// {-}{-}+ \textquotesingle{}scope}
\NormalTok{    capitalize(}\OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{])}\OperatorTok{;}          \CommentTok{//   |}
 \CommentTok{// \^{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{} \textquotesingle{}lifetime //   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

However, a very common modification might cause the program to be
rejected. Since the reference is not created in the list of function
arguments, but rather as a local variable, the special case does not
apply and the reference must be valid until the end of the scope of the
variable \texttt{slice}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ slice }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{]}\OperatorTok{;} \CommentTok{// \textless{}{-}+ \textquotesingle{}lifetime}
\NormalTok{    capitalize(slice)}\OperatorTok{;}         \CommentTok{//   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

There is no simple way to determine (from the syntactic structure) when
the lifetime of the reference should end to prove that his program is
safe. This code can be fixed by explicitly specifying where the lifetime
should end. However, this clutters the code and cannot be used for more
advanced cases.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
    \OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ slice }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{]}\OperatorTok{;} \CommentTok{// \textless{}{-}+ \textquotesingle{}lifetime}
\NormalTok{        capitalize(slice)}\OperatorTok{;}         \CommentTok{//   |}
    \OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\NormalTok{    data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

One of those more advanced cases occurs when lifetimes are not symmetric
in conditional branches. A typical case is where a condition checks the
presence of a value. In the positive branch, we have a reference to a
value which is a part of the \texttt{map}, but in the negative branch,
we do not. Therefore, it is safe to create a new reference in the
negative branch. By \emph{safe}, we mean that there will be only one
reference pointing to the \texttt{map} object at any time. A convenient
way to describe \emph{at any time} is to use the control flow graph
(CFG) of the program.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut}\NormalTok{ map }\OperatorTok{=} \OperatorTok{...;}
\KeywordTok{let}\NormalTok{ key }\OperatorTok{=} \OperatorTok{...;}
\ControlFlowTok{match}\NormalTok{ map}\OperatorTok{.}\NormalTok{get\_mut(}\OperatorTok{\&}\NormalTok{key) }\OperatorTok{\{} \CommentTok{// {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+ \textquotesingle{}lifetime}
    \ConstantTok{Some}\NormalTok{(value) }\OperatorTok{=\textgreater{}}\NormalTok{ process(value)}\OperatorTok{,}     \CommentTok{// |}
    \ConstantTok{None} \OperatorTok{=\textgreater{}} \OperatorTok{\{}                          \CommentTok{// |}
\NormalTok{        map}\OperatorTok{.}\NormalTok{insert(key}\OperatorTok{,} \PreprocessorTok{V::}\KeywordTok{default}\NormalTok{())}\OperatorTok{;} \CommentTok{// |}
        \CommentTok{//  \^{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{} ERROR.              // |}
    \OperatorTok{\}}                                  \CommentTok{// |}
\OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

For more examples, see RFC 2094\citeproc{ref-rfc2094nll}{{[}7{]}}.
However, the provided examples should be sufficient to demonstrate that
analyzing the program on a control flow graph (CFG) instead of the
syntactic structure (AST) enables the borrow checker to validate and
ensure the safety of complex programs that were previously rejected.

The above analysis thinks of lifetimes as regions (set of points in CFG)
where the reference is valid. The goal of the analysis is to find the
smallest regions so that the reference is not required to be valid
outside of those regions. The smaller the regions, the more references
can coexist at the same time, allowing more programs to be accepted.
This approach is called NLL (non-lexical lifetimes) in rustc.

The next generation of borrow checker in Rust is based on the Polonius
analysis engine. Polonius is an extension of NLL, which is capable of
proving more programs to be safe by using a different interpretation of
lifetimes.

Unlike NLL, Polonius can handle the last example. In this scenario the
problem is that everything that is tied to external lifetimes
(\texttt{\textquotesingle{}a}) has to be valid for the whole function.
Since \texttt{v} is returned, it has to outlive the lifetime
\texttt{\textquotesingle{}a}. However, the lifetime of \texttt{v} is
bound to the lifetime of the reference to the hashmap it is stored in.
It forces the \texttt{map} to be borrowed (transitively) for at least
the whole function. This includes the \texttt{map.insert} call, which
needs to borrow the hashmap itself, resulting in an error. However, we
can clearly see that no reference to \texttt{map} is available in the
\texttt{None} branch. Here Polonius can help.

Instead of starting with references and figuring out where they need to
be valid, Polonius goes in the other direction and tracks what
references need to be valid at each point in the program. As we have
determined in the example above, there is no preexisting reference to
the \texttt{map} in the \texttt{None} branch.

It is important to note that only internal computations inside the
compiler are changed by this. This change does not affect the language
semantics. It only removes some limitations of the compiler.

Another significant contribution of the Polonius project is the fact
that it replaces many handwritten checks with formal logical rules.
Also, because it knows which references are conflicting, it can be used
to provide better error messages.

\chapter{Polonius Engine}\label{sec:polonius-engine}

The Polonius engine was created by
\href{https://github.com/nikomatsakis}{Niko Matsakis} and extended by
\href{https://github.com/lqd/}{Rémy Rakic} and Albin
Stjerna\citeproc{ref-Stjerna2020}{{[}8{]}} as a next-generation
control-flow sensitive borrow checking analysis for rustc. It was
designed as an independent library that can be used both by the rustc
compiler and by different research projects, making it suitable for
usage in gccrs. Polonius interfaces with the compiler by passing around
a struct of vectors\footnote{A contiguous growable array type from the
  Rust standard library.
  (\url{https://doc.rust-lang.org/std/vec/struct.Vec.html})} of facts,
where each fact is represented by a tuple of integers\footnote{\texttt{usize}}
(or types convertible to integers). It is completely unaware of the
compiler internals.

In the previous chapter, we mentioned that Polonius differs from NLL in
its interpretation of lifetimes. Polonius uses the term ``Origin'' to
better describe the concept. An origin is a set of loans that can be
referenced using a variable at each CFG point. In other words, it tracks
where the references that are used could have originated.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ r}\OperatorTok{:} \OperatorTok{\&}\CharTok{\textquotesingle{}}\DecValTok{0} \DataTypeTok{i32} \OperatorTok{=} \ControlFlowTok{if}\NormalTok{ (cond) }\OperatorTok{\{}
    \OperatorTok{\&}\NormalTok{x }\CommentTok{/* Loan L0 */}
\OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
    \OperatorTok{\&}\NormalTok{y }\CommentTok{/* Loan L1 */}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} The origin of the reference \texttt{r} (denoted as
\texttt{\textquotesingle{}0}) is the set of loans \texttt{L0} and
\texttt{L1}. Note that this fact is initially unknown and that it is the
task of the analysis to compute it.
\end{quote}

Polonius begins by processing the input facts, computing transitive
closures of relationships and analyzing variable initializations and
deinitializations across the CFG. It then proceeds to identify move
errors, where the ownership of an object is erroneously transferred
multiple times. In the next step, it calculates the liveness of
variables and the ``outlives'' graph (transitive constraints of
lifetimes at each CFG point)\citeproc{ref-polonius2}{{[}9{]}}. All
origins that appear in the type of live variable are considered live.

The engine next determines \emph{active loans} based on two criteria:
the liveliness of any origin containing the loan (i.e., there is a
variable that might reference it) and the fact variable/place
referencing the loan was not reassigned.

The compiler has to specify all the points in the control flow graph
where a loan being alive would violate the memory safety rules. Polonius
then checks whether such a situation can happen, and if so, it reports
the facts involved in the violation. For example, if a mutable loan of a
variable is alive, then any read/write/borrow operation on the variable
invalidates the loan.

\begin{figure}
\centering
\includesvg[width=0.77\textwidth,height=\textheight]{polonius.svg}
\caption{Illustration of steps performed by Polonius to detect errors.
(Adapted from \citeproc{ref-Stjerna2020}{{[}8{]}}.)}
\end{figure}

\section{Polonius Facts}\label{sec:polonius-facts}

This section outlines the facts that Polonius utilizes, offering a
better idea of the work that the compiler needs to do. These facts are
categorized and briefly explained. For an exhaustive list, refer to the
\href{https://github.com/rust-lang/polonius/blob/master/polonius-engine/src/facts.rs}{Polonius
source code} and the Polonius Book\citeproc{ref-polonius}{{[}10{]}}.

\begin{itemize}
\tightlist
\item
  Atoms:

  \begin{itemize}
  \tightlist
  \item
    \texttt{Point} is a CFG point.
  \item
    \texttt{Variable} is a variable in the program.
  \item
    \texttt{Path} is a memory location in the program.
  \item
    \texttt{Origin} is a set of loans that can be referenced using a
    variable at each CFG point. It is the interpretation of lifetimes
    used by Polonius.
  \item
    \texttt{Loan} is a result of a borrow expression.
  \end{itemize}
\item
  Control Flow Graph:

  \begin{itemize}
  \tightlist
  \item
    \texttt{cfg\_edge:\ (Point,\ Point)} represent the edges in the
    control flow graph of the program.
  \end{itemize}
\item
  Variable Usage and Effects:

  \begin{itemize}
  \tightlist
  \item
    \texttt{var\_used\_at:\ (Variable,\ Point)} marks locations a
    variable is used in any way except for being dropped (destructed).
  \item
    \texttt{var\_defined\_at:\ (Variable,\ Point)} marks the beginning
    of a variable's scope or its reassignment. All facts related to
    given variable are reset at this point.
  \item
    \texttt{var\_dropped\_at:\ (Variable,\ Point)} indicates a point
    where a variable is dropped (its destructor is called).
  \item
    \texttt{use\_of\_var\_derefs\_origin:\ (Variable,\ Origin)} means
    that a variable type contains given origin.
  \item
    \texttt{drop\_of\_var\_derefs\_origin:\ (Variable,\ Origin)}
    reflects that the origin is used in the drop implementation.
  \end{itemize}
\item
  Path Usage and Effects: Paths correspond to indirect or partial access
  to a variable, such as field access or casting.

  \begin{itemize}
  \tightlist
  \item
    \texttt{path\_is\_var:\ (Path,\ Variable)} lists trivial paths that
    directly correspond to a variable.
  \item
    \texttt{child\_path:\ (Path,\ Path)} describes hierarchical
    relationships between paths, where one path is a subset or component
    of another.
  \item
    \texttt{path\_assigned\_at\_base:\ (Path,\ Point)} highlights where
    a specific path is assigned in the CFG.
  \item
    \texttt{path\_moved\_at\_base:\ (Path,\ Point)} marks the transfer
    of ownership of origins at a specific CFG point.
  \item
    \texttt{path\_accessed\_at\_base:\ (Path,\ Point)} indicates any
    memory access (read or write) to a path.
  \end{itemize}
\item
  Origin Relationships:

  \begin{itemize}
  \tightlist
  \item
    \texttt{known\_placeholder\_subset:\ (Origin,\ Origin)} constrains
    universal origins, representing loans from outside the function.
  \item
    \texttt{universal\_region:\ (Origin)} lists universal origins.
  \item
    \texttt{subset\_base:\ (Origin,\ Origin)} describes origin subset
    (outlives) relationships.
  \item
    \texttt{placeholder:\ (Origin,\ Loan)} associates a universal origin
    with a loan that happened outside the function.
  \end{itemize}
\item
  Loan Facts:

  \begin{itemize}
  \tightlist
  \item
    \texttt{loan\_issued\_at:\ (Origin,\ Loan,\ Point)} marks execution
    of a borrow expression.
  \item
    \texttt{loan\_killed\_at:\ (Loan,\ Point)} marks the end of a loan's
    validity.
  \item
    \texttt{loan\_invalidated\_at:\ (Point,\ Loan)} marks points where
    an active loan leads to an error.
  \end{itemize}
\end{itemize}

\chapter{Comparison of Internal
Representations}\label{sec:comparison-of-internal-representations}

Executing a borrow checker with an external analysis engine involves two
key steps. The first is collecting relevant program information,
referred to as \emph{facts}. The second step is evaluation of these
facts using the external engine. Before we can discuss the
\emph{collection} of facts, we need a clear understanding of how
programs are represented inside the compiler. We will use the term
\emph{internal representation} (IR) to refer to the representation of
the program inside the compiler. We will compare the IRs used by rustc
and gccrs to highlight the differences between the two compilers. This
will help us understand the challenges of adapting the borrow checker
design from rustc to gccrs. First, we will describe the IRs used by
rustc and then compare them with those used in gccrs.

\section{GCC and LLVM}\label{sec:gcc-and-llvm}

To understand the differences between each of the compilers, we must
first explore the differences between the compiler platforms on which
they are built (GCC and LLVM). We will only focus on the middle-end of
each platform, since the back-end does not directly influence the
front-end development.

LLVM is built around a three-address code (3-AD)\footnote{Three-address
  code represents a program as sequences of statements (known as
  \emph{basic blocks}), connected by control flow instructions to form a
  control flow graph (CFG).} representation known as the \emph{LLVM
intermediate representation} (LLVM IR)\citeproc{ref-llvm}{{[}11{]}}.
This IR serves as an interface between the front-ends and the LLVM
platform. Each front-end is responsible for transforming its custom AST
IR\footnote{The abstract syntax tree (AST) is a structure representing
  the program's syntax. It is the direct result of parsing. For
  instance, an expression \texttt{1\ +\ (2\ -\ 7)} would be represented
  as a \texttt{subtraction} node, with children representing \texttt{1}
  and the subexpression \texttt{(2\ -\ 7)}.} into the LLVM IR. The LLVM
IR is stable and strictly separated from the front-end; therefore, it
cannot be easily extended to include language-specific constructs.

\begin{figure}
\centering
\includesvg[width=0.9\textwidth,height=\textheight]{llvm-ir-cfg-example.svg}
\caption{LLVM IR CFG Example (generated by Compiler Explorer)}
\end{figure}

GCC, in contrast, uses a tree-based representation called
GENERIC\citeproc{ref-gccint}{{[}12, p. 175{]}} for interfacing with
front-ends. GENERIC was created as a generalized form of AST shared by
most front-ends. GCC provides a set of common tree nodes to describe all
the standard language constructs in the GENERIC IR. Front-ends may
define language-specific constructs and provide hooks for their
handling.\citeproc{ref-gccint}{{[}12, p. 212{]}} The GENERIC
representation is subsequently transformed into GIMPLE, which is
mostly\footnote{``GIMPLE that is not fully lowered is known as `High
  GIMPLE' and consists of the IL before the \texttt{pass\_lower\_cf}.
  High GIMPLE contains some container statements such as lexical scopes
  and nested expressions, while ``Low GIMPLE'' exposes all of the
  implicit jumps for control and exception expressions directly in the
  IL and EH region trees.''\citeproc{ref-gccint}{{[}12, p. 225{]}}} a
3-AD representation. This transformation involves decomposing
expressions into a series of statements and introducing temporary
variables. This transformation is done inside the compiler platform, not
in the front-end. This approach makes the front-ends smaller and shifts
more work into the shared part. The GIMPLE representation does not
contain information specific to each front-end (programming language).
However, it is possible to store language-specific information in GIMPLE
by adding entirely new statements.\citeproc{ref-gccint}{{[}12, p.
262{]}} This is possible because GIMPLE is not a stable interface.

The key takeaway from this section is that rustc has to transform the
tree-based representation into a 3-AD representation by itself. That
means that it can access the program's control flow graph (CFG). This is
not the case for gccrs. In GCC, the CFG is only available in the
\emph{Low GIMPLE} representation, deep inside the middle-end where the
IR is language independent.

\section{Rustc Representation}\label{sec:rustc-representation}

In the previous section, we have seen that rustc is responsible for
transforming the code from the raw text to the LLVM IR. Given the high
complexity of the Rust language, rustc uses multiple intermediate
representations (IRs) to simplify the process (see the diagram below).
The text is first tokenized and parsed into an abstract syntax tree
(AST), and then transformed into the high-level intermediate
representation (HIR). For transformation into a middle-level
intermediate representation (MIR), the HIR is first transformed into a
typed HIR (THIR). The MIR is then transformed into the LLVM IR.

\begin{figure}
\centering
\includesvg[width=0.75\textwidth,height=\textheight]{./pipeline.svg}
\caption{Comparison of compiler pipelines with a focus on internal
representations}
\end{figure}

AST is a tree-based representation of the program, closely following
each source code token. At this stage, rustc performs macro-expansion
and a partial name resolution (macros and imports)
\citeproc{ref-devguide}{{[}13{]}} \footnote{\url{https://rustc-dev-guide.rust-lang.org/macro-expansion.html}}
\footnote{\url{https://rustc-dev-uide.rust-lang.org/name-resolution.html}}.
As the AST is lowered to HIR, some complex language constructs are
desugared to simpler constructs. For example, various types of loops are
transformed into a single infinite loop construct (Rust \texttt{loop}
keyword), and many structures that can perform pattern matching
(\texttt{if\ let}, \texttt{while\ let}, \texttt{?} operator) are
transformed into the `match``
construct\citeproc{ref-reference}{{[}14{]}} \footnote{\url{https://doc.rust-lang.org/reference/expressions/if-expr.html\#if-let-expressions}}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Foo(i31)}\OperatorTok{;}

\KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:}\NormalTok{ i31) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{    Foo(x)}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} This simple code snippet will serve as our example
through this section.
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Fn \{}
\NormalTok{  generics: Generics \{ ... \},}
\NormalTok{  sig: FnSig \{}
\NormalTok{    header: FnHeader \{ ... \},}
\NormalTok{      decl: FnDecl \{}
\NormalTok{        inputs: [}
\NormalTok{          Param \{}
\NormalTok{            ty: Ty \{}
\NormalTok{              Path \{ segments: [ PathSegment \{ ident: i32\#0 \} ] \}}
\NormalTok{            \}}
\NormalTok{            pat: Pat \{ Ident(x\#0) \}}
\NormalTok{          \},}
\NormalTok{        ],}
\NormalTok{        output: Ty \{}
\NormalTok{            Path \{ segments: [ PathSegment \{ ident: Foo\#0 \} ]}
\NormalTok{        \}}
\NormalTok{      \},}
\NormalTok{  \},}
\NormalTok{  ... }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} This is a textual representation of a small and
simplified part of the abstract syntax tree (AST) of the example
program. The full version can be found in the
\hyperref[abstract-syntax-tree-ast]{appendix}.
\end{quote}

The HIR is rustc primary representation, and it is used for most
operations\citeproc{ref-devguide}{{[}13{]}}, HIR It combines a
simplified AST with additional tables for quick access to additional
information, such as expression and statement types. These tables are
used for analysis passes, including full name resolution and type
checking. Type checking includes verification type correctness,
inference, and resolving of implicit type-dependent
constructs\citeproc{ref-devguide}{{[}13{]}} \footnote{\url{https://rustc-dev-guide.rust-lang.org/type-checking.html}}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
 \AttributeTok{\#[}\NormalTok{prelude\_import}\AttributeTok{]}
 \KeywordTok{use} \PreprocessorTok{::std::prelude::rust\_2015::}\OperatorTok{*;}
 \AttributeTok{\#[}\NormalTok{macro\_use}\AttributeTok{]}
 \KeywordTok{extern} \KeywordTok{crate}\NormalTok{ std}\OperatorTok{;}
 \KeywordTok{struct}\NormalTok{ Foo(}\DataTypeTok{i32}\NormalTok{)}\OperatorTok{;}

 \KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}\NormalTok{ Foo(x) }\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} One of HIR dump formats: HIR structure still
corresponds to a valid Rust program, equivalent to the original one.
\texttt{rustc} provides a textual representation of HIR, which displays
such a program.
\end{quote}

The HIR representation can contain many placeholders and ``optional''
fields that are resolved during the HIR analysis. To simplify further
processing, parts of HIR that correspond to executable code (e.g., not
type definitions) are transformed into THIR (Typed High-Level
Intermediate Representation), where all the missing information must be
resolved. The reader can think about HIR and THIR in terms of the
\href{https://en.wikipedia.org/wiki/Builder_pattern}{builder pattern}.
HIR provides a flexible interface for modification, while THIR is the
final immutable representation of the program. This involves not only
the data stored in HIR helper tables, but also parts of the program that
are implied from the type system. This means that operator overloading,
automatic references, and automatic dereferences are all resolved into
explicit code at this stage.

The final \texttt{rustc} IR, which is lowered directly to the LLVM IR,
is the Mid-level Intermediate Representation (MIR). We will pay extra
attention to MIR because it is the primary representation used by the
borrow checker. MIR is a three-address code representation, similar to
LLVM IR but with Rust-specific constructs. It contains information about
types, including lifetimes. It differentiates pointers and references,
as well as mutable and immutable references. It is aware of panics and
stack unwinding. It contains additional information for borrow checker,
like storage live/dead annotations, which denote when a place (an
abstract representation of a memory location) is first used or last
used, and fake operations, which help with the analysis. For example, a
fake unwind operation inside infinite loops ensures an exit edge in the
CFG. Fake operations can be critical for algorithms that process the CFG
in reverse order.

MIR consists of sequences of statements (basic blocks) connected by
control flow instructions. This structure forms a control flow graph.
MIR statements operate on places (often called lvalue in other
languages) and rvalues. A place can represent either a local variable or
a value derived from the variable (e.g., a field, an index, or a cast).

Rustc also uses a special IR, called TyTy, to represent types.
Initially, types are represented in HIR on a syntactic level. Every
mention of a type in the program compiles into a distinct HIR node.
These HIR nodes are compiled into the TyTy representation during the HIR
analysis. Each type (all its occurrences in the program) is represented
by a single TyTy object instance. This is achieved by
\href{https://en.wikipedia.org/wiki/Interning_\%28computer_science\%29}{interning}.
Note that there can be multiple equivalent types of different
structures. Those are represented by different TyTy instances. Each
non-primitive type forms a tree (e.g., reference to a pair of an integer
and a character), where the inner nodes are shared between types due to
interning. Generic types, which are of particular interest to borrow
checking, are represented as a pair: an inner type and a list of generic
arguments. When generic type parameters are substituted for concrete
types, the concrete type is placed into the argument list. The inner
type is left unchanged. When the type substitution is complete, there is
a procedure that transforms the generic type into a concrete type.

Inside the HIR, after the type-checking analysis, TyTy types of nodes
can be looked up based on the node's ID in one of the helper tables
(namely, the type-check context). Each \texttt{THIR} node directly
contains a pointer to its type. In MIR, the type is stored inside each
place.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ foo(\_1}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{    debug x }\OperatorTok{=\textgreater{}}\NormalTok{ \_1}\OperatorTok{;}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ \_0}\OperatorTok{:}\NormalTok{ Foo}\OperatorTok{;}

\NormalTok{    bb0}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{        \_0 }\OperatorTok{=}\NormalTok{ Foo(\_1)}\OperatorTok{;}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} MIR dump For further details, see the chapter ``Source
Code Representation'' in \citeproc{ref-devguide}{{[}13{]}}.
\end{quote}

\section{Rust GCC Representation}\label{sec:rust-gcc-representation}

This section discusses intermediate representations in gccrs. Since
gccrs is a second implementation of the Rust compiler, it is heavily
inspired by rustc. Therefore, this section assumes familiarity with the
rustc intermediate representations, described in the previous section.
We will focus on similarities and differences between rustc and gccrs,
rather than describing the gccrs intermediate representation in full
detail.

The gccrs representation is strongly inspired by rustc. It diverges
mostly for two reasons: for simplicity, since gccrs is still in an early
stage of development, and due to the specifics of the GCC platform.
Gccrs uses its own variants of AST, HIR, and TyTy representations, but
does not use a THIR or MIR.

AST and HIR representations are similar to rustc, with fewer features
supported. The main difference is the structure of the representation.
Rustc takes advantage of algebraic data types, resulting in a very
fine-grained representation. On the other hand, gccrs is severely
limited by the capabilities of C++11 and is forced to use an
object-oriented approach.

There are no THIR and MIR or any equivalent in gccrs. MIR cannot be used
in GCC unless the whole gccrs code generation is rewritten to output
(low) GIMPLE instead of GENERIC, which would be much more complex than
the current approach. Given the limited development resources of gccrs,
this is not a viable option.\citeproc{ref-zulip}{{[}15{]}}

The TyTy-type representation is simplified in gccrs and provides no
uniqueness guarantees. There is a notable difference in the
representation of generic types. Instead of being built on top of the
types (by composition) like in rustc, types that support generic
parameters inherit from a common base class. That means that the type
definition is not shared between different generic types. The advantage
of this approach is that during the substitution of generic parameters,
the inner types are modified during each type substitution, simplifying
intermediate handling, like type inference.

\chapter{Rust GCC Borrow Checker
Design}\label{sec:rust-gcc-borrow-checker-design}

The Rust GCC borrow checker is designed to closely resemble the rustc
borrow checker, within the constraints of the Rust GCC. This approach
allows us to leverage existing knowledge of borrow checking in Rust. The
analysis operates in two phases. First, it gathers relevant information,
called \emph{facts}, about the program, stored as tuples of numbers.
Each number represents a CFG node, variable, path/place, or loan (a
borrow expression). Then, the borrow checker submits these facts to the
analysis engine, which computes the analysis results. The compiler
receives the facts related to memory safety violations and translates
them into error messages. A significant aspect of the Rust GCC borrow
checker is its reuse of the analysis engine from rustc. To integrate the
Polonius engine, developed in Rust, into the gccrs compiler, which is
C++-based, we utilize the C ABI and a thin Rust wrapper.

This chapter details the design process of the gccrs borrow checker, the
decisions made during this process, and the final design. It places
special emphasis on the newly developed borrow checker intermediate
representation (BIR) and its application in analysis. Additionally, the
chapter covers other compiler modifications necessary to support borrow
checking and concludes with a brief overview of the error reporting
design.

\section{Analysis of the Fact Collection
Problem}\label{sec:analysis-of-the-fact-collection-problem}

This section discusses the options for fact collection in gccrs explored
during the initial design phase. Due to the differences between internal
representations of rustc and gccrs, it was impossible to copy the rustc
approach exactly. The considered alternatives included direct use of
HIR, implementing MIR in gccrs, or creating a new IR specifically for
borrow checking, with various placement possibilities within the
compilation pipeline.

The analysis has been control-flow sensitive since NLL's introduction in
rustc (see sec.~\ref{sec:evolution}), requiring us to match the required
facts, which are specific to Rust semantics, with control-flow graph
nodes. We need to distinguish between pointers (in unsafe Rust) and
references. Pointers are not subject to borrow checking, but references
are. Furthermore, we need to distinguish between mutable and immutable
references, since they have different rules, which is essential for
borrow checking\footnote{The critical rule of borrow checking is that
  for a single borrowed variable, there can only be a single mutable
  borrow or only immutable borrows valid at each point of the CFG.}.
Each type must carry information about its lifetimes and their variances
(described later in this chapter). We need to store the explicit
lifetime parameters from explicit user type annotation.

The only IR in GCC that contains CFG information is GIMPLE; however,
under normal circumstances, GIMPLE is language agnostic. It is possible
to annotate GIMPLE statements with language-specific information using
special statements that would have to be generated from special
information that would need to be added to GENERIC. The statements would
need to be preserved by the middle-end passes until the pass building
the CFG (which includes 11 passes), after which facts could be
collected. After that, the facts would need to be discarded to avoid
complicating the tens of subsequent
passes\footnote{See file \texttt{gcc/passes.def} in the GCC source code.}\citeproc{ref-gccint}{{[}12,
p. 141{]}}, and RTL generation. This approach was discussed with senior
GCC developers and quickly rejected as it would require a large amount
of work and leak front-end-specific information into the middle-end,
making it more complex. No attempt was made to experiment with this
approach.

It was clear that we needed to build a CFG. Luckily, working with a
particular control flow graph created by the compiler is unnecessary.
Any CFG that is consistent with Rust semantics is sufficient. In
particular, adding any edges and merging nodes in the CFG is
conservative with regard to the borrow checking analysis. In many cases,
it does not change the result at all.

Initially, we tried to collect information from the HIR directly and
compute an approximate CFG on the fly. That worked nicely for simple
language constructs that are local, but it gets very complicated for
more complex constructs like patterns and loops with \texttt{break} and
\texttt{continue} statements. Since no representation is generated,
there is no easy way to verify the process, not even by manual checking.
Furthermore, it was not clear how to handle panics and stack unwinding
in this model.

An option to ease such problems was to radically desugared the HIR to
only basic constructs. An advantage of this approach is that it would
leverage the code already existing in the code generator, making code
generation easier. Also, the code generator already performs some of
those transformations locally (not applying them back to HIR, but using
them directly for GENERIC generation), so those could be reused. The
problem that quickly arose was that the HIR visitor system was not
designed for HIR-to-HIR transformations, where new nodes would be
created. Many such transformations, such as explicit handling of
automatic referencing and dereferencing, would require information about
the type of each node, which would, in return, require name resolution
results. Therefore, that transformation would have to happen after all
analysis passes on the HIR are completed. However, all information
stored alongside HIR would need to be updated for each newly created
node. The code generator partly avoids this problem by querying the
GENERIC API for the information it needs about the code already
compiled. This fact would complicate the use of existing transformations
on the HIR-to-HIR level. Rustc avoids this problem by doing such
transformations on the HIR-THIR boundary and not modifying the HIR
itself. Since this modification would be complicated and would only be a
preparation for borrow checking, it was decided not to proceed in this
direction at that time. However, we found that some transformation can
be performed on the AST-HIR boundary. This approach can be done mostly
independently (only code handling the removed nodes is also removed, but
no additions or modifications are needed). It was agreed that such
transformations are useful and should be implemented regardless of the
path taken by the borrow checker. Those transformations include mainly
loops and pattern-matching structures. These transformations are even
documented in the rust reference\citeproc{ref-reference}{{[}14{]}}.

\begin{quote}
At the time of writing, desugaring of the for loop was implemented by
Philip Herron. More desugaring work is in progress or is planned.
However, I have focused on the borrow checking itself. For the time
being, I have ignored the complex constructs, assuming that they will be
eventually desugared into constructs that the borrow checker would
already be able to handle.
\end{quote}

To ensure that all possible approaches were considered, we discussed the
possibility of implementing MIR in gccrs. This approach has some
advantages and many problems. Should the MIR be implemented in a
completely compatible way, it would be possible to use tools like MIRI
with gccrs. The borrow checking would be very similar to rustc borrow
checking, and parts of rustc code might even be reused. Gccrs would also
be more ready for Rust-specific optimizations within the front-end. The
final advantage is that the current test suite would cover the process
of lowering the HIR to MIR, as all transformations would affect the code
generation. The main problem with this approach is that it would require
a large portion of gccrs to be reimplemented, delaying the project by a
considerable amount of time. Should such an approach be taken, any
effort on borrow checking would be delayed until the MIR is implemented.
The maintainers\citeproc{ref-zulip}{{[}15{]}} decided that such an
approach is not feasible and that gccrs will not use MIR in any
foreseeable future.

After Arthur Cohen suggested keeping things simpler, I decided to
experiment with a different, minimalistic approach: building a radically
simplified MIR-like IR that keeps only the bare minimum of information
needed for borrow checking. Given the unexpected productivity of this
approach, it was decided to continue. This IR, later called the borrow
checker IR (BIR), focuses only on the flow of data, and ignores the
actual data transformations. The main disadvantage of this approach is
that it creates a dead branch of the compilation pipeline that is not
used for code generation, and therefore it is not covered by the
existing test suite. To overcome this difficulty, the BIR and its
textual representation (dump) are designed to be as similar to rustc MIR
as possible. This feature allows us to check the generated BIR against
the MIR generated by rustc, at least for simple programs. The use of BIR
is the final approach used in this work. Details of the BIR design are
described in the next section.

\begin{figure}
\centering
\includesvg[width=0.35\textwidth,height=\textheight]{./bir.svg}
\caption{Placement of the borrow checker IR in the compilation pipeline}
\end{figure}

\section{The Borrow Checking
Process}\label{sec:the-borrow-checking-process}

Before the borrow checking itself can be performed, specific information
about types needs to be collected when the HIR is type-checked and TyTy
types are created. The TyTy needs to resolve and store information about
lifetimes and their corresponding constraints. At this point, lifetimes
are resolved from string names, and their bounding clauses are found.
There are different kinds of lifetimes in the Rust language. Inside
types, the lifetimes are bound to the lifetime parameters of generic
types. In function pointers, lifetimes can be universally quantified
(meaning that the function must be memory-safe for every possible
lifetime). In function definitions, lifetimes may be omitted (elided) if
all references share the same lifetime. In function bodies, lifetimes
can be bound to the lifetime parameters of the function, or they can be
omitted, in which case they are inferred \footnote{At least Rust
  semantics thinks about it that way. In reality, the compiler only
  checks that there exists some lifetime that could be used in that
  position by collecting constraints that would apply to such a
  lifetime.}. The type-checked HIR is then transformed into the borrow
checker IR (BIR). The BIR is then processed to extract facts for
Polonius. At this phase, some errors that are easy to detect can be
emitted. Subsequently, the collected facts are passed to Polonius, which
then computes the results of the analysis. The results are then passed
back to the compiler, which translates them into error messages.

\section{Representation of Lifetimes in
TyTy}\label{sec:representation-of-lifetimes-in-tyty}

\begin{quote}
In this work, the term lifetime refers to the syntactic object in HIR
and AST. In the source code, it corresponds to either explicit
universal\footnote{There are two kinds of lifetimes in Rust semantics:
  universal and existential. Universal lifetimes correspond to code that
  occurs outside the function. It is called universal because the
  concerned borrow checking rules use the universal quantifier. That
  means that the function has to be valid \emph{for all} possible
  outside code that satisfies the specified (or implied) constraints.
  Existential lifetimes correspond to the code that happens inside the
  function. The existential quantifier is used in the rules regarding
  existential lifetimes. That means that the code has to be valid
  \emph{for some} set of \emph{loans} (or CFG points).} lifetime
annotation (\texttt{\textquotesingle{}a}), elided universal lifetime
annotation\href{https://doc.rust-lang.org/reference/lifetime-elision.html}{\citeproc{ref-reference}{{[}14{]}}},
and local/existential lifetimes, which are always inferred. In contrast,
\emph{region}/\emph{origin} is used to refer to the semantic object. The
object is, in fact, an inference variable, and its value is computed by
the borrow checker. The term \emph{region} is used by NLL to refer to a
set of CFG points. Polonius introduced the term \emph{origin} to refer
to a set of \emph{loans}. In both this text and the implementation, the
terms are used interchangeably.
\end{quote}

In order to analyze more complex lifetimes than just simple references,
it was necessary to add a representation of lifetime parameters to the
type system and unify it with the representation of lifetimes in the
rest of the compiler. The first step is to resolve the lifetimes and
bind them to their binding clauses. Gccrs recognizes four kinds of
regions. In a function body, explicit lifetime annotations result in
\emph{named} lifetimes, while implicit annotations lead to
\emph{anonymous} lifetimes. Within generic data types, lifetimes
resolved to lifetime parameters are called ``early-bound.'' For function
pointers and traits, lifetimes can be universally quantified using the
\texttt{for} clause\footnote{\texttt{for\textless{}\textquotesingle{}a\textgreater{}\ fn(\&\textquotesingle{}a\ i32)\ -\textgreater{}\ \&\textquotesingle{}a\ i32}}.
These lifetimes are not resolved when the definition is analyzed, but
only when this type is used. Hence, the name is ``late-bound''
lifetimes. In addition, there is a representation for unresolved
lifetimes. It is used, for example, when a generic type is defined, but
the generic arguments have not been provided yet. Any occurrence of an
unresolved lifetime after type checking is to be treated as a compiler
bug.

Inside TyTy, lifetimes are represented in the following ways. Named
lifetimes are enumerated. Anonymous lifetimes are assumed to be always
distinct (but they are represented by an identical object at this
stage). Early bound lifetimes are represented by the relative position
of the lifetime parameter to which they are bound. In generic types, the
lifetime arguments are stored together with the type arguments, which
ensures their automatic propagation. An issue arising from this
automatic propagation is the updating of the bindings of early bound
lifetimes. This means that by a simple inspection of the body of the
generic type, one would not be able to resolve the lifetimes. A trick
solves this problem. Each type in TyTy is identified by a unique ID.
When generic arguments are substituted, a clone of the type with a fresh
ID is created. What we would like to achieve is to have the same state
as in rustc: the original body and an up-to-date list of generic
arguments. This can be achieved by storing the ID of the original type
in addition to the current ID. When necessary, the original ID can be
used to look up the initial type.\footnote{This was once revealed to me
  in a dream.} The analysis can then traverse the original type, and
when a type placeholder is encountered, the appropriate argument is
looked up in the current type.

\section{Borrow Checker IR Design}\label{sec:borrow-checker-ir-design}

The Borrow Checker Intermediate Representation (BIR) is a three-address
code representation, designed to closely resemble a subset of rustc
Mid-level Intermediate Representation (MIR). Like MIR, it represents the
body of a single function (or function-like item, such as a closure), as
borrow checking is performed on each function separately. It abstracts
specific operations into a few key operations that focus on data flow.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ fib(\_2}\OperatorTok{:} \DataTypeTok{u32}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \DataTypeTok{u32} \OperatorTok{\{}
\NormalTok{    bb0}\OperatorTok{:} \OperatorTok{\{}
    \DecValTok{0}\NormalTok{    StorageLive(\_3)}\OperatorTok{;}
    \DecValTok{1}\NormalTok{    StorageLive(\_5)}\OperatorTok{;}
    \DecValTok{2}\NormalTok{    \_5 }\OperatorTok{=}\NormalTok{ \_2}\OperatorTok{;}
    \DecValTok{3}\NormalTok{    StorageLive(\_6)}\OperatorTok{;}
    \DecValTok{4}\NormalTok{    \_6 }\OperatorTok{=}\NormalTok{ Operator(}\KeywordTok{move}\NormalTok{ \_5}\OperatorTok{,} \KeywordTok{const} \DataTypeTok{u32}\NormalTok{)}\OperatorTok{;}
    \DecValTok{5}\NormalTok{    switchInt(}\KeywordTok{move}\NormalTok{ \_6) }\OperatorTok{{-}\textgreater{}}\NormalTok{ [bb1}\OperatorTok{,}\NormalTok{ bb2]}\OperatorTok{;}
    \OperatorTok{\}}

   \CommentTok{// ... (omitted for brevity) }

\NormalTok{    bb5}\OperatorTok{:} \OperatorTok{\{}
    \DecValTok{0}\NormalTok{    StorageLive(\_14)}\OperatorTok{;}
    \DecValTok{1}\NormalTok{    \_14 }\OperatorTok{=}\NormalTok{ \_2}\OperatorTok{;}
    \DecValTok{2}\NormalTok{    StorageLive(\_15)}\OperatorTok{;}
    \DecValTok{3}\NormalTok{    \_15 }\OperatorTok{=}\NormalTok{ Operator(}\KeywordTok{move}\NormalTok{ \_14}\OperatorTok{,} \KeywordTok{const} \DataTypeTok{u32}\NormalTok{)}\OperatorTok{;}
    \DecValTok{4}\NormalTok{    StorageLive(\_16)}\OperatorTok{;}
    \DecValTok{5}\NormalTok{    \_16 }\OperatorTok{=}\NormalTok{ Call(fib)(}\KeywordTok{move}\NormalTok{ \_15) }\OperatorTok{{-}\textgreater{}}\NormalTok{ [bb6]}\OperatorTok{;}
    \OperatorTok{\}}

    \CommentTok{// ... (omitted for brevity)}

\NormalTok{    bb8}\OperatorTok{:} \OperatorTok{\{}
    \DecValTok{0}\NormalTok{    StorageDead(\_9)}\OperatorTok{;}
    \CommentTok{// ... (omitted for brevity) }
    \DecValTok{4}\NormalTok{    StorageDead(\_3)}\OperatorTok{;}
    \DecValTok{5}    \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} The following example shows a shortened BIR dump of a
simple Rust program computing the nth Fibonacci number. The complete
source code and full dump are available in appendix
\ref{sec:comparison-of-bir-and-mir}.
\end{quote}

The BIR of a single function is composed of basic metadata about the
function (such as arguments, return type, or explicit lifetimes), a list
of basic blocks, and a list of places.

A basic block is identified by its index in the function's basic block
list. It contains a list of BIR statements and a list of successor basic
block indices in the CFG. BIR statements are of three categories: An
assignment of an expression to a local (place), a control flow operation
(switch, return), or a special statement (not executable), which carries
additional information for the borrow checker (explicit type
annotations, information about variable scope, etc.). BIR statements
correspond to the MIR \texttt{StatementKind} enum.

Expressions represent the executable parts of the rust code. Many
different Rust constructs are represented by a single expression. Only
data (and lifetime) flow needs to be tracked. Some expressions are
differentiated only to allow for a better debugging experience. BIR
expressions correspond to the MIR \texttt{RValue} enum.

Expressions and statements operate on places. A place is an abstract
representation of a memory location. It is either a variable, a field,
an index, or a dereference of another place. For simplicity, constants
are also represented as places. Since exact values are not important for
borrow checking and constants are, from principle, immutable with static
storage duration, a single place can represent all constants of a single
type. Rustc MIR cannot afford this simplification, and keeps constants
separate. The \texttt{Operand} enum is a common interface for places and
constants. However, since operations use constants and lvalues in the
same way, MIR introduces a special layer of lvalues.

Places are identified by the index in the place database. The database
stores a list of places and their properties. The properties include an
identifier, used to always resolve the same variable (field, index,
etc.) to the same place, move and copy flags, type, a list of fresh
regions (lifetimes), and a relationship to other places (e.g., a field
of a struct). Temporaries are treated just like variables but are
differentiated in the place database because of place lookup. The place
database also keeps track of scopes and existing loans. The place
database structure is based on rustc
\href{https://rustc-dev-guide.rust-lang.org/borrow_check/moves_and_initialization/move_paths.html}{\texttt{MovePathData}}.
It combines the handling of places done by both MIR and borrow checker
separately in rustc.

It is important to highlight that different fields are assigned to
different places; however, all indices are assigned to the same place
(both in gccrs and rustc). This fact has a strong impact on the strength
and complexity of the analysis, because the number of fields is static
and typically small, the size of arrays is unbound and depends on
runtime information.

\begin{quote}
\textbf{Structure of the BIR Function}

\begin{itemize}
\tightlist
\item
  basic block list

  \begin{itemize}
  \tightlist
  \item
    basic block
  \item
    \texttt{Statement}

    \begin{itemize}
    \tightlist
    \item
      \texttt{Assignment}

      \begin{itemize}
      \tightlist
      \item
        \texttt{InitializerExpr}
      \item
        \texttt{Operator\textless{}ARITY\textgreater{}}
      \item
        \texttt{BorrowExpr}
      \item
        \texttt{AssignmentExpr} (copy)
      \item
        \texttt{CallExpr}
      \end{itemize}
    \item
      \texttt{Switch}
    \item
      \texttt{Goto}
    \item
      \texttt{Return}
    \item
      \texttt{StorageLive} (start of variable scope)
    \item
      \texttt{StorageDead} (end of variable scope)
    \item
      \texttt{UserTypeAsscription} (explicit type annotation)
    \end{itemize}
  \end{itemize}
\item
  place database
\item
  arguments
\item
  return type
\item
  universal lifetimes
\item
  universal lifetime constraints
\end{itemize}
\end{quote}

\section{BIR Building}\label{sec:bir-building}

BIR construction involves visiting the High-Level Intermediate
Representation (HIR) tree of the function. There are specialized
visitors for expressions, statements, and patterns, as well as a
top-level visitor for handling function headers. Whenever a new place is
created in the compilation database, a corresponding list of fresh
regions\footnote{In this text, we use the term lifetime for the
  syntactic object in the code and region for the semantic object in the
  analysis. It is called a region because it represents a set of points
  in the control flow graph (CFG). At this point, the set is not yet
  known. It is the main task of the borrow checker analysis engine to
  compute the set of points for each region.} is generated. Counting the
number of lifetimes to be generated involves traversing the type
structure. For generic types, the inner structure is ignored and only
the lifetime and type parameters are considered. Note that the type
parameters can be also generic, creating a structure known as
\href{https://rustc-dev-guide.rust-lang.org/what-does-early-late-bound-mean.html\#early-and-late-bound-parameter-definitions}{higher-kinded}.
All types are independently queried for each node from the HIR, instead
of being derived within the BIR.

\begin{quote}
Example: For a BIR code that reads a field from a variable, the type is
not computed from the variable. Rather, it is queried from the HIR for
both the variable and the field.
\end{quote}

BIR building itself is fairly straightforward. However, some extra
handling was added to produce a code that is more similar to
\texttt{rustc}'s MIR. For example, instead of eagerly assigning computed
expressions to temporaries, it is checked whether the caller did not
provide a destination place. This transformation removes some of the
\texttt{\_10\ =\ \_11} statements from the BIR dump. The BIR dump also
renumbers all places to produce a closer match with the BIR dump. This
can cause some confusion during debugging because Polonius is receiving
the original place numbers. When debugging using the Polonius debug
output, the dump can be switched to show the original place numbers.

\begin{quote}
This handling was especially important when testing the initial BIR
builder, since it makes the dump more similar to the MIR dump and,
therefore, easier for manual comparison.
\end{quote}

\section{BIR Fact Collection and
Checking}\label{sec:bir-fact-collection-and-checking}

The BIR fact collection process extracts Polonius facts from the BIR and
conducts additional checks. Polonius is responsible for verifying
lifetime (region) constraints, ensuring each place is moved at most
once, and checking that illegal accesses are not made to borrow memory
locations. The collection process involves two phases: gathering static
facts from the place database and universal region constraints, and
traversing the BIR along the CFG to collect dynamic facts.

The fact collection is performed in two phases. First, static facts are
collected from the place database. These include universal region
constraints (constraints corresponding to lifetime parameters of the
function) collected during BIR construction and facts collected from the
place database. Polonius needs to know which places correspond to
variables and which form paths (see the definition below). Furthermore,
it needs to sanitize fresh regions of places that are related (e.g., a
field and a parent variable) by adding appropriate constraints between
them. The relations of the regions depend on the variance of the region
within the type. (See Variance Analysis below.)

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Path }\OperatorTok{=}\NormalTok{ Variable}
     \OperatorTok{|}\NormalTok{ Path }\StringTok{"."}\NormalTok{ Field }\CommentTok{// field access}
     \OperatorTok{|}\NormalTok{ Path }\StringTok{"["} \StringTok{"]"}   \CommentTok{// index}
     \OperatorTok{|} \StringTok{"*"}\NormalTok{ Path}
\end{Highlighting}
\end{Shaded}

Formal definition of paths from the Polonius
book\citeproc{ref-polonius}{{[}10{]}}.
\end{quote}

In the second phase, the BIR is traversed along the CFG, and dynamic
facts are collected. For each statement, two CFG nodes are added. Two
nodes are necessary to model the semantic aspects where the statement's
effect is immediate or follows the execution of the statement. For each
statement and (if present) its expression, Polonius facts are collected.
These include generic facts related to read and write operations, as
well as facts specific to borrows and function calls. For the function,
we need to instantiate fresh regions for the function's lifetime
parameters, which need to be correctly bound together.

\subsection{Subtyping and Variance}\label{sec:subtyping-and-variance}

In the basic interpretation of Rust language semantics (one used by
programmers to reason about their code, not the one used by the
compiler), lifetimes are part of the type and are always present.
Lifetimes not explicitly mentioned are inferred in the same way as type
parts (e.g., \texttt{let\ a\ =\ (\_,\ i32)\ =\ (true,\ 5);} infers the
type to \texttt{(bool,\ i32)}). In Rust, explicit lifetime annotations
in a function correspond to borrows that occurred \emph{outside} the
function, implying that these lifetimes span the entire function body.
Annotations for lifetimes that cover only part of the function body
would be redundant, as borrows within a function are precisely analyzed
by the borrow checker. Explicit annotations are used only to represent
constraints from code outside the function's scope.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{let} \KeywordTok{mut}\NormalTok{ x}\OperatorTok{;}
 \ControlFlowTok{if}\NormalTok{ (b) }\OperatorTok{\{}
\NormalTok{     x }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;} \CommentTok{// a: \&\textquotesingle{}a T}
 \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
\NormalTok{     x }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;} \CommentTok{// b: \&\textquotesingle{}b T}
 \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} The type of \texttt{x} must be inferred to be a
subtype of both \texttt{\&\textquotesingle{}a\ T} and
\texttt{\&\textquotesingle{}b\ T}, ensuring safe use with all potential
loans (here \texttt{a} or \texttt{b}).
\end{quote}

In Rust, unlike object-oriented languages like Java or C++, the only
subtyping relationship, apart from identity, arises from
lifetimes\footnote{During type inference computation, there can also be
  subtyping relations with general kinds of types (like ), which is
  mostly used for literals without a type annotation, where we know it
  is ``some kind'' of integer, but we do not yet know which one.}. Two
regions (representing lifetimes) can either be unrelated, subsets of
each other in terms of loans or CFG points
(\texttt{\textquotesingle{}a:\ \textquotesingle{}b}), or equal
(resulting from \texttt{\textquotesingle{}a:\ \textquotesingle{}b} and
\texttt{\textquotesingle{}b:\ \textquotesingle{}a}). The dependency of
subtyping on the inner parameter is called variance.

\begin{quote}
\textbf{Definition} \citeproc{ref-reference}{{[}14{]}}

\texttt{F\textless{}T\textgreater{}} is covariant over \texttt{T} if
\texttt{T} being a subtype of \texttt{U} implies that
\texttt{F\textless{}T\textgreater{}} is a subtype of
\texttt{F\textless{}U\textgreater{}} (subtyping ``passes through'')

\texttt{F\textless{}T\textgreater{}} is contravariant over \texttt{T} if
\texttt{T} being a subtype of \texttt{U} implies that
\texttt{F\textless{}U\textgreater{}} is a subtype of F

\texttt{F\textless{}T\textgreater{}} is invariant over \texttt{T}
otherwise (no subtyping relation can be derived)
\end{quote}

Consider an example specific to lifetimes in Rust. With a simple
reference type \texttt{\&\textquotesingle{}a\ T}, the lifetime parameter
\texttt{\textquotesingle{}a} is covariant. This implies that a reference
\texttt{\&\textquotesingle{}a\ T} can be safely coerced into
\texttt{\&\textquotesingle{}b\ T} if \texttt{\textquotesingle{}a} is a
subtype of \texttt{\textquotesingle{}b}. In practical terms, if it's
safe to dereference a reference at any point during the period
\texttt{\textquotesingle{}a}, it remains safe throughout the shorter
period \texttt{\textquotesingle{}b}, given \texttt{\textquotesingle{}b}
is a subset of \texttt{\textquotesingle{}a} \footnote{A subset of CFG
  nodes.}.

The situation is different when we pass a reference to a function as an
argument. In that case, the lifetime parameter is contravariant. For
function parameters, we need to ensure that the parameter lives as long
as the function needs it to. For instance, a function pointer with the
type
\texttt{fn\ foo\textless{}\textquotesingle{}a\textgreater{}(x:\ \&\textquotesingle{}a\ T)}
can be coerced into
\texttt{fn\ foo\textless{}\textquotesingle{}b\textgreater{}(x:\ \&\textquotesingle{}b\ T)}
if \texttt{\textquotesingle{}b:\ \textquotesingle{}a}. Such a
transformation is safe as it narrows the range of acceptable argument
values for the parameter \texttt{x}.

To visualize this concept, consider the following code snippet, where
\texttt{\textquotesingle{}a} denotes a region safe for referencing the
storage of \texttt{x}, and \texttt{\textquotesingle{}b} denotes a
similar region for \texttt{y}. A function that operates correctly with a
reference of lifetime \texttt{\textquotesingle{}b} is also guaranteed to
work correctly with a reference of lifetime
\texttt{\textquotesingle{}a}, since \texttt{\textquotesingle{}a}
contains \texttt{\textquotesingle{}b}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{let}\NormalTok{ x }\OperatorTok{=} \DecValTok{5}\OperatorTok{;}        \CommentTok{// region \textquotesingle{}a}
 \OperatorTok{\{}                 \CommentTok{//}
     \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \DecValTok{7}\OperatorTok{;}    \CommentTok{//            // region \textquotesingle{}b        }
 \OperatorTok{\}}                 \CommentTok{//}
\end{Highlighting}
\end{Shaded}
\end{quote}

The return type of the function is effectively an assignment to a local
variable (just across function boundaries) and therefore is covariant.

The situation becomes interesting when the two rules are combined. Let
us have a function
\texttt{fn\ foo\textless{}\textquotesingle{}a\textgreater{}(x:\ \&\textquotesingle{}a\ T)\ -\textgreater{}\ \&\textquotesingle{}a\ T}.
The return type requires the function to be covariant over
\texttt{\textquotesingle{}a}, while the parameter requires it to be
contravariant. This is called \emph{invariance}.

For non-generic types, variance is directly derived from the type
definition. However, variance in generic types is more complex and
subject to different approaches.

\subsection{Variance of Generic
Types}\label{sec:variance-of-generic-types}

Generic type variance can be derived from either the type's usage or its
definition\citeproc{ref-Altidor2011}{{[}16{]}}. Rustc employs
definition-site variance for generic types, meaning variance is computed
from the type's definition, rather than its usage in functions. The
situation becomes complicated when a generic type is used within another
type, possibly in a recursive manner. In such cases, variance requires
computation via a fixed-point algorithm, referred to as ``variance
analysis''.

\subsubsection{Variance Analysis}\label{sec:variance-analysis}

Both rustc and gccrs implement variance analysis based on section 4 of
the paper \citeproc{ref-Altidor2011}{{[}16{]}}. The notation from the
paper is followed in the documentation of both compilers, as well as in
this text. While the paper primarily focuses on the variance of complex
types, like in the case of Java, it introduces an effective formal
calculus, which is also applicable to higher-kinded lifetimes.

For a thorough understanding of the exact rules, the paper and the
source code are the best resources. Here, we provide only a basic
overview. The analysis employs an iterative fixed-point computation,
where variables form a semi-lattice with an additional binary operation.
Each variable corresponds to a single lifetime or type parameter and is
initially set as bivariant.

The visitor algorithm traverses each type, taking the current variance
of the visited expression as input. Every type member is in a covariant
position. Conversely, each function parameter member is in a
contravariant position, while the return type is in a covariant
position. The position of a generic argument is determined by the
variance of the generic parameter (represented as a variable in this
computation). The variance of the current node within the type is
computed by a \texttt{transform} function, which considers both the
parent node's variance and the current node's positional variance. When
a lifetime or type parameter is encountered, then, if the current
variance expression is constant, the variable is updated to the new
variance using the join operation with the current value. For
expressions containing at least one variable, the expression is added to
a list of constraints and the fixed-point computation is used.

\begin{quote}
\textbf{Example of Algorithm Execution}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{struct}\NormalTok{ Foo}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{,} \OtherTok{\textquotesingle{}b}\OperatorTok{,}\NormalTok{ T}\OperatorTok{\textgreater{}} \OperatorTok{\{}
\NormalTok{     x}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}a}\NormalTok{ T}\OperatorTok{,}
\NormalTok{     y}\OperatorTok{:}\NormalTok{ Bar}\OperatorTok{\textless{}}\NormalTok{T}\OperatorTok{\textgreater{},}
 \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \texttt{Foo} has three generic parameters, resulting in 3 variables:
  \texttt{f0=o}, \texttt{f1=o}, \texttt{f2=o}.
\item
  \texttt{x} is first processed in the covariant position.

  \begin{itemize}
  \tightlist
  \item
    \texttt{\&\textquotesingle{}a\ T} being in the covariant position
    updates the variables to \texttt{f0=+} and \texttt{f2=+}.
  \end{itemize}
\item
  \texttt{y} is next, also in the covariant position.

  \begin{itemize}
  \tightlist
  \item
    \texttt{Bar\textless{}T\textgreater{}} being in the covariant
    position.

    \begin{itemize}
    \tightlist
    \item
      \texttt{T} inside a generic argument leads to
      \texttt{transform(+,\ b0)} for its position.
    \item
      A new constant \texttt{f2\ =\ join(f2,\ transform(+,\ b0))} is
      added.
    \end{itemize}
  \end{itemize}
\item
  After processing all types and assuming \texttt{Bar} is an external
  type with variances \texttt{{[}-{]}}, a fixed-point computation
  begins.

  \begin{itemize}
  \tightlist
  \item
    Iteration 1:

    \begin{itemize}
    \tightlist
    \item
      Starting values: \texttt{f0=+}, \texttt{f1=o}, \texttt{f2=+}.
    \item
      Processing constraint
      \texttt{f2\ =\ join(f2,\ transform(+,\ b0))}.
    \item
      \texttt{transform(+,\ b0)} with \texttt{b0=-} gives \texttt{-}.
    \item
      \texttt{join(+,\ -)} results in \texttt{*}.
    \item
      Update of \texttt{f2} requires another iteration.
    \end{itemize}
  \item
    Iteration 2:

    \begin{itemize}
    \tightlist
    \item
      Current values: \texttt{f0=+}, \texttt{f1=o}, \texttt{f2=*}.
    \item
      Processing same constraint.
    \item
      \texttt{transform(+,\ b0)} still yields \texttt{-}.
    \item
      \texttt{join(*,\ -)} remains \texttt{*}.
    \item
      No update to \texttt{f2}, computation concludes.
    \end{itemize}
  \end{itemize}
\item
  Final variances: \texttt{f0=+}, \texttt{f1=o}, \texttt{f2=*}:

  \begin{itemize}
  \tightlist
  \item
    \texttt{f0} is evident.
  \item
    \texttt{f1} remains bivariant, as it is unmentioned in the type.
  \item
    \texttt{f2} is invariant due to its usage in both covariant and
    contravariant positions.
  \end{itemize}
\end{itemize}
\end{quote}

After processing all types in the crate, constraints are resolved using
the fixed-point computation. Note that current crates might use generic
types from other crates, necessitating the export/load of variance for
public types.

\section{Error Reporting}\label{sec:error-reporting}

As each function is analyzed separately, the compiler can easily report
which functions violate the rules. Currently, only the kind of violation
is communicated from the Polonius engine to the compiler. More detailed
reporting is an area for future work.

There are three possible approaches for implementing more detailed
reporting:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Returning All Violations:} This method involves passing all
  violations back to the compiler as a return value of the Polonius FFI
  invocation. It offers a clear separation of roles between the compiler
  and the analysis engine. However, implementing this correctly could be
  challenging due to memory ownership concerns at the FFI boundary.
  Polonius would need to allocate dynamically sized memory for the
  result and provide an API for its release.
\item
  \emph{Callback Function for Error Reporting:} Another option is to
  provide the Polonius engine with a callback function to report each
  found error. But, as Polonius only possesses information in terms of
  the enumerated nodes of the control flow graph, a pointer to an
  instance of the borrow checker would also need to be passed. This
  pointer would be used in conjunction with the callback to map nodes
  back to the actual code. However, this approach compromises the
  separation of roles, where Polonius and Polonius FFI act solely as
  external computation engines.
\item
  \emph{Compiler-Side Allocation via Callback Functions:} A compromise
  between these two methods would be to supply Polonius with callback
  functions that relay violations to the compiler one at a time, keeping
  memory allocation on the compiler side.
\end{enumerate}

Additionally, the borrow checker does not currently store information to
trace the nodes back to their source code locations. This limitation is
purely technical and can be addressed straightforwardly with localized
changes. Given the experimental nature of this work, the focus has been
on analysis over detailed error reporting.

The final stage in developing the borrow checker would involve
implementing heuristics to infer the reasons for errors and suggest
potential fixes.

\chapter{Implementation}\label{sec:implementation}

After the initial experiments described in
sec.~\ref{sec:analysis-of-the-fact-collection-problem}, the project was
implemented in the following phases: First, an initial version of the
borrow checker IR (BIR), lowering from HIR to BIR (the BIR builder), and
a textual BIR dump were implemented. Second, the first version of the
BIR fact collection and the Polonius FFI were added. At this stage, the
first simple error detections were tested. Next, the implementation was
extended to handle more complex data types, especially generics.
Finally, the BIR fact collection was extended to handle the new
information and emit all available facts.

The initial version of the borrow checker included only the minimal
information that the borrow checker was expected to need. The builder
was able to lower most operator and initializer expressions, borrow
expressions, function calls, and simple control flow operations
(\texttt{if}, \texttt{if/else}, \texttt{while}, \texttt{loop},
\texttt{return}). The compiler was
\href{https://github.com/Rust-GCC/gccrs/pull/2689}{extended} to handle
\href{https://doc.rust-lang.org/reference/expressions/loop-expr.html\#labelled-block-expressions}{labeled
blocks} to lower (and test) \texttt{break} and \texttt{continue}
expressions. Note that in the Rust language, \texttt{break} and
\texttt{continue} can use label identifiers to exit nested loops or
return a value from any labeled block\citeproc{ref-reference}{{[}14{]}}.

The BIR dump was designed to be as similar to MIR as possible for manual
verification. However, rustc performs many transformations on MIR, and
there are various versions of the dump available. Originally, the MIR
dump from the online \href{https://godbolt.org/}{Compiler Explorer} was
used, but this version is optimized and cleaned up. It proved
complicated to align with this dump, requiring additional BIR
transformations. This led to the decision to change the reference MIR
dump. MIR after each MIR pass can be exported from rustc using the
\texttt{-Zdump-mir=*} flag. Additionally, the \texttt{-Zunpretty=mir}
option is available. The logical choice was to use the MIR version for
borrow checking (\texttt{-Zdump-mir=nll}), which is less optimized and
contains additional borrow checking information. Most BIR
transformations were removed after this change ot the reference MIR
dump.

This initial BIR version and related infrastructure were submitted to
Rust GCC in \href{https://github.com/Rust-GCC/gccrs/pull/2702}{pull
request 2702}, adding 3,779 lines of new code, including a document
titled ``BIR Design Notes'' to assist new developers with the borrow
checker implementation. It is located in
\href{https://github.com/Rust-GCC/gccrs/blob/df5b6a371dba385e4bb03ebd638cd473c4cc38eb/gcc/rust/checks/errors/borrowck/bir-design-notes.md}{\texttt{gcc/rust/checks/errors/borrowck/bir-design-notes.md}}.

In the second phase, the fact collection and an interface to the
Polonius engine were implemented. Initially, only lifetimes of simple
references were handled (at most one lifetime per type). Fact collection
processed all places in the place database and traversed the BIR control
flow graphs. The interface to Polonius consists of a C ABI in gccrs and
a C ABI (generated by
\href{https://github.com/rust-lang/rust-bindgen}{rust-bindgen} and
manually cleaned up and extended) in a small static Rust library (FFI
Polonius). The FFI Polonius library's role is to invoke the Polonius
engine. A discussion about integrating this interface into the GCC build
system began in \href{https://github.com/Rust-GCC/gccrs/pull/2716}{pull
request draft 2716}. This integration is complex, requiring compilation
of Rustc code beyond gccrs's current capabilities. For development
purposes, the Cargo build system (rustc) is invoked from the GCC
Makefile. While not ideal for production due to no cross-compilation
handling, this solution is optimal for development. It was decided to
keep the build integration downstream for the time being. The most
viable solution for upstreaming is to release the Polonius FFI as a
dynamic library, with the building process outside GCC. The final
decision on this will be made when the borrow checker is ready for
public release. Therefore, this phase was not submitted to Rust GCC,
with newer independent commits rebased below the FFI commit and
submitted separately. At this stage, the borrow checker successfully
detected
\href{https://doc.rust-lang.org/error_codes/E0382.html}{repeated moves},
basic subset errors (i.e., insufficient constraints between inputs and
outputs of functions), and
\href{https://doc.rust-lang.org/error_codes/E0507.html}{moves behind a
reference}. Error output was implemented using only the FFI Polonius
debug output at this stage (see the example).

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{[}\DecValTok{34}\OperatorTok{/}\DecValTok{35}\NormalTok{] Checking function test\_move}
\NormalTok{Polonius analysis completed}\OperatorTok{.}\NormalTok{ Results}\OperatorTok{:}
\NormalTok{Errors}\OperatorTok{:} \OperatorTok{\{\}}
\NormalTok{Subset error}\OperatorTok{:} \OperatorTok{\{\}}
\NormalTok{Move error}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{   GccrsAtom(}
       \DecValTok{11}\OperatorTok{,}
\NormalTok{   )}\OperatorTok{:}\NormalTok{ [}
\NormalTok{       GccrsAtom(}
           \DecValTok{2}\OperatorTok{,}
\NormalTok{       )}\OperatorTok{,}
\NormalTok{   ]}\OperatorTok{,}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} FFI Polonius debug output for a simple program with a
move error. The output reports that at a CFG point encoded as the number
11, a path number 2 was moved illegally.
\end{quote}

In the third (and final) phase, the entire borrow checker, the TyTy IR,
and the type checker were extended to support complex types containing
multiple regions (lifetimes). Variance analysis and helper region tools
were implemented. The BIR builder and fact collection were expanded to
handle the new information and emit all available facts. Correctly
collecting facts is challenging due to limited documentation of the
facts and their relationship with Rust code. The current implementation
relies on the Polonius Book\citeproc{ref-polonius}{{[}10{]}}, the
Polonius source code\citeproc{ref-poloniusSource}{{[}17{]}}, the rustc
source code\citeproc{ref-rustcSource}{{[}18{]}}, and experiments using
rustc and the Polonius CLI. Some facts might be missing or incorrectly
collected.

The borrow checker could identify most errors that violate access rules
(number of loans of a given type allowed, loan/access conflicts),
move/initialization errors, and subset errors. To demonstrate its
functionality, a small test suite was created based on tests from the
Polonius project, supplemented with custom ones. Ideally, the borrow
checker would be tested against rustc test suite, but gccrs is currently
unable to compile most of these tests as they rely on the Rust standard
library. Examples from the gccrs borrow checker test suite are available
in the appendix.

This phase is pending final cleanup and submission in the branch
\href{https://github.com/jdupak/gccrs/tree/borrowck-stage2}{borrowck-stage2}.
It includes 5146 additions and 720 deletions and is expected to be
submitted to Rust GCC soon.

\section{Limitations}\label{sec:limitations}

The main bottleneck in the current implementation is the BIR builder.
After covering a subset of Rust sufficient for testing error detection
capabilities, the focus shifted to other aspects of the borrow checker
to implement all necessary parts, even if in a limited fashion. Below is
a list of known limitations of the current implementation.

\subsection{BIR and BIR Builder}\label{sec:bir-and-bir-builder}

\begin{itemize}
\tightlist
\item
  Currently, only nongeneric functions are supported (not closures or
  \href{https://doc.rust-lang.org/nightly/reference/items/associated-items.html\#associated-functions-and-methods}{associated
  functions and methods}). Other function-like items require special
  top-level handling, though their body handling is identical. Generic
  functions must be monomorphised before checking.
\item
  Method calls are not handled due to required implicit coercion of the
  \texttt{self} argument.
\item
  The \texttt{?} operator and \texttt{while\ let} are not addressed.
  They will be removed at the \texttt{AST-\textgreater{}HIR} boundary.
\item
  Handling for \texttt{if\ let} and \texttt{match} expressions is
  missing, particularly for pattern detection (variant selection).
  Pattern destructuring is mostly implemented for \texttt{let}
  expressions and function parameters. The
  \href{https://doc.rust-lang.org/reference/patterns.html\#or-patterns}{\texttt{or}
  pattern} is unsupported, as is pattern declaration without an initial
  value, except for
  \href{https://doc.rust-lang.org/reference/patterns.html\#identifier-patterns}{identifier
  patterns}.
\item
  \href{https://doc.rust-lang.org/reference/types/enum.html}{Enums} are
  not supported.
\item
  Unsafe blocks are not handled.
\item
  Asynchronous code is completely unsupported in the compiler.
\item
  Unwind paths (drops) are not created, as drops are not supported by
  the compiler.
\item
  \href{https://rustc-dev-guide.rust-lang.org/borrow_check/two_phase_borrows.html}{Two-phase
  borrowing} is not implemented. While not essential for correctness, it
  reduces false positives.
\item
  Location information is not stored, which is necessary for practical
  error reporting.
\item
  Copy trait probing is not performed. The \texttt{Copy} trait is
  derived only for primitive types and tuples of primitive types.
\item
  Not all fake operations (e.g., \texttt{fake\_unwind}) are represented
  or emitted.
\item
  Advanced projections like \texttt{cast} might require more complex
  handling.
\end{itemize}

\subsection{Parsing, AST, HIR, TyTy}\label{sec:parsing-ast-hir-tyty}

\begin{itemize}
\tightlist
\item
  \href{https://doc.rust-lang.org/nightly/reference/lifetime-elision.html\#lifetime-elision}{Lifetime
  elision} is not handled.
\item
  Variance analysis does not import or export variance information via
  metadata export and currently only considers one crate.
\item
  Region propagation in the type checker requires further testing,
  particularly in cases involving traits.
\item
  \href{https://doc.rust-lang.org/reference/trait-bounds.html\#higher-ranked-trait-bounds}{Late-bound
  lifetime} instantiation is unaddressed.
\end{itemize}

\subsection{Fact Collection}\label{sec:fact-collection}

\begin{itemize}
\tightlist
\item
  Implicit constraints between a reference and its base type
  (\texttt{\&\textquotesingle{}a\ T\ =\textgreater{}\ T:\ \textquotesingle{}a})
  are not collected.
\item
  The collection of the \texttt{loan\_killed\_at} fact is simplified.
\item
  Drop and unwind-related handling is not implemented due to incomplete
  support elsewhere in the borrow checker.
\item
  \href{https://rustc-dev-guide.rust-lang.org/borrow_check/two_phase_borrows.html}{Two-phase
  borrowing} is unaddressed. Refer to
  sec.~\ref{sec:bir-and-bir-builder}.
\item
  The reasons for loan invalidation are not stored, which is necessary
  for practical error reporting.
\item
  Rustc prioritizes subset facts for displaying more relevant errors.
  This is not implemented in gccrs.
\end{itemize}

\subsection{Polonius FFI and Error
Reporting}\label{sec:polonius-ffi-and-error-reporting}

\begin{itemize}
\tightlist
\item
  The current integration with the build system is not viable for
  production. Refer to the beginning of this
  \hyperref[implementation]{chapter} for details.
\item
  Only information about the presence and category of violations is
  passed back to the borrow checker; details about the violations
  themselves are not.
\item
  Errors are reported only at the function level (and using debug
  output), which can be problematic for automated testing if tests fail
  or succeed for incorrect reasons.
\end{itemize}

\section{Building, Usage, and
Debugging}\label{sec:building-usage-and-debugging}

This section provides references and basic information on how to build
gccrs and use the borrow checker, along with tips for debugging.

The latest source code is available in the author's
\href{https://github.com/jdupak/gccrs/}{fork} on the branch
\href{https://github.com/jdupak/gccrs/tree/borrowck-stage2}{\texttt{borrowck-stage2}}.

Detailed instructions for building gccrs are in the \texttt{README.md}
file in the project's root directory. For tips on a better development
experience (e.g., faster builds), refer to \citeproc{ref-svp}{{[}19{]}}.

The compiler binary is named \texttt{crab1}, and it is located in the
\texttt{gcc} directory within the chosen build directory after building.
Since gccrs is still experimental, the flag
\texttt{-frust-incomplete-and-experimental-compiler-do-not-use} is
required to use the compiler. To enable the borrow checker, add the
\texttt{-frust-borrowcheck} flag. Any detected borrow checker errors
will be reported as standard compilation errors.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{$ crab1 {-}frust{-}incomplete{-}and{-}experimental{-}compiler{-}do{-}not{-}use \textbackslash{}}
\NormalTok{      {-}frust{-}borrowcheck some\_rust\_code.rs}

\NormalTok{../../gcc/testsuite/rust/borrowck/borrowck{-}assign{-}comp.rs:5:1:}
\NormalTok{error: Found loan errors in function a}
\NormalTok{5 | fn a() \{ // \{ dg{-}error "Found loan errors in function a" \}}
\NormalTok{| \^{}\textasciitilde{} }
\end{Highlighting}
\end{Shaded}
\end{quote}

For a deeper inspection of the borrow checker, a debug build of the
compiler is necessary. The \texttt{-frust-debug} flag enables debug
logs, including the borrow checker activity. Unfortunately, GCC's debug
logging lacks category filtering. The reader may find the variance
analysis log, the borrow checker log (BIR build and fact collector), and
Polonius debug output particularly interesting. This flag also activates
the BIR dump (saved to
\texttt{./bir\_dump/\textless{}crate\_name?\textgreater{}/\textless{}function\_name?\textgreater{}.bir.dump})
and \emph{facts} dump (saved to
\texttt{nll\_facts\_gccrs/\textless{}function\_name\textgreater{}.facts}).

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{crab1: note: Variance analysis solving started:}
\NormalTok{crab1: note: Variance analysis results:}
\NormalTok{crab1: note:  Point\textless{}\textgreater{}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{../../}\NormalTok{gcc}\OperatorTok{/}\NormalTok{testsuite}\OperatorTok{/}\NormalTok{rust}\OperatorTok{/}\NormalTok{borrowck}\OperatorTok{/}\NormalTok{borrowck}\OperatorTok{{-}}\NormalTok{assign}\OperatorTok{{-}}\NormalTok{comp}\OperatorTok{.}\NormalTok{rs}\OperatorTok{:}\DecValTok{5}\OperatorTok{:}\DecValTok{1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:} 
\NormalTok{ Checking function a}

    \DecValTok{5} \OperatorTok{|} \KeywordTok{fn}\NormalTok{ a() }\OperatorTok{\{} \CommentTok{// \{ dg{-}error "Found loan errors in function a" \}}
      \OperatorTok{|} \OperatorTok{\^{}\textasciitilde{}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:} \PreprocessorTok{BIR::Builder::}\NormalTok{build function}\OperatorTok{=\{}\NormalTok{a}\OperatorTok{\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  ctx}\OperatorTok{.}\NormalTok{fn\_free\_region}\OperatorTok{=\{\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  handle\_lifetime\_param\_constraints}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{ visit\_statemensts}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize constraints of Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_4 }\OperatorTok{=}\NormalTok{ BorrowExpr(\_1)}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{      push\_subset}\OperatorTok{:} \CharTok{\textquotesingle{}}\ErrorTok{?2: }\CharTok{\textquotesingle{}}\OperatorTok{?}\DecValTok{1}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_5 }\OperatorTok{=}\NormalTok{ Assignment(\_6) at }\DecValTok{0}\OperatorTok{:}\DecValTok{5}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_9 }\OperatorTok{=}\NormalTok{ Assignment(\_8) at }\DecValTok{0}\OperatorTok{:}\DecValTok{7}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  \_0 }\OperatorTok{=}\NormalTok{ Assignment(\_10) at }\DecValTok{0}\OperatorTok{:}\DecValTok{11}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize field }\OperatorTok{.}\DecValTok{0}\NormalTok{ of Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize deref of }\OperatorTok{\&}\NormalTok{ Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\NormalTok{crab1}\OperatorTok{:}\NormalTok{ note}\OperatorTok{:}\NormalTok{  Sanitize field }\OperatorTok{.}\DecValTok{0}\NormalTok{ of Point}\OperatorTok{\{}\NormalTok{Point }\OperatorTok{\{}\NormalTok{x}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{,}\NormalTok{ y}\OperatorTok{:}\DataTypeTok{isize}\OperatorTok{\}\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

To obtain similar output from rustc, use the flags
\texttt{-Znll-facts\ -Zdump-mir=nll\ -Zidentify-regions}. With a debug
build of rustc, you can also enable the borrow checker debug log using
the environment variable \texttt{RUSTC\_LOG=rustc\_borrowck}. Building
rustc is described in the
\href{https://rustc-dev-guide.rust-lang.org/building/how-to-build-and-run.html}{Rustc
Developer Guide}.

For more advanced debugging and inspection, gdb/lldb can be used as
usual. A common issue with LLDB is its difficulty in correctly
identifying virtual classes. To address this, a simple LLDB formatter
for resolving TyTy classes based on internal identifiers is available in
\href{https://gist.github.com/jdupak/68af0f0ad91f3e6eba2c478dc4f662dd}{this
gist}. This script can be used as a template and can be adapted to other
classes suffering from this problem.

\chapter{Conclusion}\label{sec:conclusion}

This project aimed to implement a prototype of a Polonius-based borrow
checker for Rustc GCC to explore the feasibility of this approach and
establish a code infrastructure for further development. The development
was conducted in a \href{https://github.com/jdupak/gccrs/}{personal
fork} of Rust GCC, and stabilized parts are being integrated into the
main \href{https://github.com/Rust-GCC/gccrs}{Rustc GCC GitHub
repository}. All accepted changes are scheduled to be integrated into
the \href{https://gcc.gnu.org/git/}{central GCC repository} by the
maintainers of Rust GCC with the help of the author.

This text described the problem of borrow checking, mapped the situation
in rustc and gccrs, and presented the design of the solution, as well as
the experiments that led to it. The prototype version of the implemented
borrow checker can detect most common errors in simple Rust code. These
include violations of access rules (number of allowed loans of a given
type, loan/access conflicts), move/initialization errors, and subset
errors. Examples of detected errors can be found in the appendix.

The last chapter provides an overview of the prototype's limitations.
These limitations are not fundamental and should be resolvable with
simple extensions and implementation of missing cases in the existing
code. Future work should address these limitations to provide a
production-ready solution.

Given the complex nature of borrow checking, a comprehensive, fully
functional solution is likely to take months, if not years, of future
work. This project provides a significant stepping stone toward a
production-ready solution, offering extensive infrastructure for further
development and solutions to most of the challenging problems identified
in the analysis.

I believe that the Rust programming language will play a significant
role in systems programming, and I would like to continue working on
this project, on other problems in Rustc GCC, or on the rustc compiler
itself. There appears to be considerable interest in the industry as
well. Bradley Spengler, President of Open Source Security, Inc., one of
the two main sponsors of Rust GCC, has expressed interest in financially
supporting my continued work on Rust GCC.

\appendix

\chapter{References}\label{sec:references}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{0}
\bibitem[\citeproctext]{ref-Matsakis2014}
\CSLLeftMargin{{[}1{]} }%
\CSLRightInline{N. D. Matsakis and F. S. Klock, {``The rust language,''}
in \emph{Proceedings of the 2014 ACM SIGAda annual conference on high
integrity language technology}, Oct. 2014. doi:
\href{https://doi.org/10.1145/2663171.2663188}{10.1145/2663171.2663188}.}

\bibitem[\citeproctext]{ref-RustBelt}
\CSLLeftMargin{{[}2{]} }%
\CSLRightInline{N. Matsakis, {``Polonius: Either borrower or lender be,
but responsibly.''} Rust Belt Rust Conference, Jan. 2020. Accessed: Jan.
04, 2024. {[}Online{]}. Available:
\url{https://www.youtube.com/watch?v=_agDeiWek8w}}

\bibitem[\citeproctext]{ref-poloniusupdate}
\CSLLeftMargin{{[}3{]} }%
\CSLRightInline{R. Rakic and N. Matsakis, {``Polonius update.''} Oct.
2023. Accessed: Jan. 04, 2024. {[}Online{]}. Available:
\url{https://blog.rust-lang.org/inside-rust/2023/10/06/polonius-update.html}}

\bibitem[\citeproctext]{ref-eurorust}
\CSLLeftMargin{{[}4{]} }%
\CSLRightInline{A. Cohen, {``The road to compiling the standard library
with gccrs.''} EuroRust, 2023. Accessed: Jan. 05, 2024. {[}Online{]}.
Available: \url{https://www.youtube.com/watch?v=WgqGahDl-sY}}

\bibitem[\citeproctext]{ref-nsa}
\CSLLeftMargin{{[}5{]} }%
\CSLRightInline{\emph{{{``Software Memory Safety''}} {C}ybersecurity
{I}nformation {S}heet}. The National Security Agency, 2022. Accessed:
Dec. 29, 2023. {[}Online{]}. Available:
\url{https://media.defense.gov/2022/nov/10/2003112742/-1/-1/0/csi_software_memory_safety.pdf}}

\bibitem[\citeproctext]{ref-danglingpointer}
\CSLLeftMargin{{[}6{]} }%
\CSLRightInline{Mitre, {``CWE-416: Use after free.''} Accessed: Dec. 20,
2023. {[}Online{]}. Available:
\url{https://cwe.mitre.org/data/definitions/416.html}}

\bibitem[\citeproctext]{ref-rfc2094nll}
\CSLLeftMargin{{[}7{]} }%
\CSLRightInline{N. Matsakis, {``2094-nll,''} in \emph{The {R}ust {RFC}
{B}ook}, Rust Foundation, 2017. Accessed: Dec. 18, 2023. {[}Online{]}.
Available: \url{https://rust-lang.github.io/rfcs/2094-nll.html}}

\bibitem[\citeproctext]{ref-Stjerna2020}
\CSLLeftMargin{{[}8{]} }%
\CSLRightInline{A. Stjerna, {``{M}odelling {R}ust's {R}eference
{O}wnership {A}nalysis {D}eclaratively in {D}atalog,''} Master's thesis,
Uppsala University, 2020. Accessed: Dec. 28, 2023. {[}Online{]}.
Available:
\url{https://www.diva-portal.org/smash/get/diva2:1684081/fulltext01.pdf}}

\bibitem[\citeproctext]{ref-polonius2}
\CSLLeftMargin{{[}9{]} }%
\CSLRightInline{N. Matsakis, {``Polonius revisited, part 1.''} Sep. 22,
2023. Accessed: Dec. 17, 2023. {[}Online{]}. Available:
\url{https://smallcultfollowing.com/babysteps/blog/2023/09/22/polonius-part-1/}}

\bibitem[\citeproctext]{ref-polonius}
\CSLLeftMargin{{[}10{]} }%
\CSLRightInline{N. Matsakis, R. Rakic, \emph{et al.}, {``{T}he
{P}olonius {B}ook.''} Rust Foundation, 2021.}

\bibitem[\citeproctext]{ref-llvm}
\CSLLeftMargin{{[}11{]} }%
\CSLRightInline{\emph{Reference}. LLVM Project, 2023. Accessed: Dec. 15,
2023. {[}Online{]}. Available:
\url{https://llvm.org/docs/Reference.html}}

\bibitem[\citeproctext]{ref-gccint}
\CSLLeftMargin{{[}12{]} }%
\CSLRightInline{R. M. Stallman and the GCC Developer Community,
\emph{{GNU} {C}ompiler {C}ollection {I}nternals}, 14th ed. Free Software
Foundation, 2023. Accessed: Dec. 18, 2023. {[}Online{]}. Available:
\url{https://gcc.gnu.org/onlinedocs/gccint/}}

\bibitem[\citeproctext]{ref-devguide}
\CSLLeftMargin{{[}13{]} }%
\CSLRightInline{\emph{{R}ust {C}ompiler {D}evelopment {G}uide}. Rust
Foundation, 2023. Accessed: Dec. 18, 2023. {[}Online{]}. Available:
\url{https://rustc-dev-guide.rust-lang.org/index.html}}

\bibitem[\citeproctext]{ref-reference}
\CSLLeftMargin{{[}14{]} }%
\CSLRightInline{Rustc developers, \emph{Reference}. Rust Foundation,
2023. Accessed: Dec. 07, 2023. {[}Online{]}. Available:
\url{https://doc.rust-lang.org/reference/}}

\bibitem[\citeproctext]{ref-zulip}
\CSLLeftMargin{{[}15{]} }%
\CSLRightInline{{``{\#}{c}ompiler-development \textgreater{}
{B}orrowchecking vs ({H})IR - GCC rust - zulip.''} Sep. 05, 2023.
Accessed: Dec. 05, 2023. {[}Online{]}. Available:
\url{https://gcc-rust.zulipchat.com/\#narrow/stream/281658-compiler-development/topic/Borrowchecking.20vs.20.28H.29IR}}

\bibitem[\citeproctext]{ref-Altidor2011}
\CSLLeftMargin{{[}16{]} }%
\CSLRightInline{J. Altidor, S. S. Huang, and Y. Smaragdakis, {``Taming
the wildcards: Combining definition- and use-site variance,''} \emph{ACM
SIGPLAN Notices}, vol. 46, no. 6, pp. 602--613, Jun. 2011, doi:
\href{https://doi.org/10.1145/1993316.1993569}{10.1145/1993316.1993569}.}

\bibitem[\citeproctext]{ref-poloniusSource}
\CSLLeftMargin{{[}17{]} }%
\CSLRightInline{{``Polonius.''} Rust Foundation. Accessed: Dec. 29,
2023. {[}Online{]}. Available:
\url{https://github.com/rust-lang/polonius/}}

\bibitem[\citeproctext]{ref-rustcSource}
\CSLLeftMargin{{[}18{]} }%
\CSLRightInline{{``Rust.''} Rust Foundation. Accessed: Dec. 28, 2023.
{[}Online{]}. Available: \url{https://github.com/rust-lang/rust/}}

\bibitem[\citeproctext]{ref-svp}
\CSLLeftMargin{{[}19{]} }%
\CSLRightInline{J. Dupák, {``Contribution to the {R}ust front-end for
the {GCC} compiler,''} research report, Czech Technical University in
Prague, 2023. Accessed: Jan. 05, 2023. {[}Online{]}. Available:
\url{https://jakubdupak.com/dev/academic/dupakjak-svp-report.pdf}}

\bibitem[\citeproctext]{ref-polonius3}
\CSLLeftMargin{{[}20{]} }%
\CSLRightInline{N. Matsakis, {``Polonius revisited, part 2.''} Sep. 29,
2023. Accessed: Dec. 30, 2023. {[}Online{]}. Available:
\url{https://smallcultfollowing.com/babysteps/blog/2023/09/29/polonius-part-2/}}

\bibitem[\citeproctext]{ref-rustonomicon}
\CSLLeftMargin{{[}21{]} }%
\CSLRightInline{A. Beingessner \emph{et al.}, \emph{The {R}ustonomicon}.
Rust Foundation, 2023. Accessed: Dec. 15, 2023. {[}Online{]}. Available:
\url{https://doc.rust-lang.org/nomicon/}}

\end{CSLReferences}

\chapter{Rustc Intermediate Representations
Examples}\label{sec:rustc-intermediate-representations-examples}

\begin{quote}
\textbf{Compilation commands:}

\texttt{\$\ rustc\ -Z\ unpretty=ast-tree}

\texttt{\$\ rustc\ -Z\ unpretty=hir-tree}

\texttt{\$\ rustc\ -Z\ unpretty=mir\ -Z\ identify-regions}
\end{quote}

\section{Rust Source Code}\label{sec:rust-source-code}

\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{struct}\NormalTok{ Foo(}\DataTypeTok{i32}\NormalTok{)}\OperatorTok{;}

    \KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{        Foo(x)}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\clearpage

\section{Abstract Syntax Tree (AST)}\label{sec:abstract-syntax-tree-ast}

\begin{verbatim}

Fn {
    defaultness: Final,
    generics: Generics {
        params: [],
        where_clause: WhereClause {
            has_where_token: false,
            predicates: [],
            span: simple.rs:3:22: 3:22 (#0),
        },
        span: simple.rs:3:7: 3:7 (#0),
    },
    sig: FnSig {
        header: FnHeader { unsafety: No, asyncness: No, constness: No },
        decl: FnDecl {
            inputs: [
                Param {
                    attrs: [],
                    ty: Ty {
                        id: NodeId(4294967040),
                        kind: Path(
                            None,
                            Path {
                                span: simple.rs:3:11: 3:14 (#0),
                                segments: [
                                    PathSegment {
                                        ident: i31#0,
                                        id: NodeId(4294967040),
                                        args: None,
                                    },
                                ],
                                tokens: None,
                            },
                        ),
                        span: simple.rs:3:11: 3:14 (#0),
                        tokens: None,
                    },
                    pat: Pat {
                        id: NodeId(4294967040),
                        kind: Ident(
                            BindingAnnotation(No, Not),
                            x#0,
                            None,
                        ),
                        span: simple.rs:3:8: 3:9 (#0),
                        tokens: None,
                    },
                    id: NodeId(4294967040),
                    span: simple.rs:3:8: 3:14 (#0),
                    is_placeholder: false,
                },
            ],
            output: Ty(
                Ty {
                    id: NodeId(4294967040),
                    kind: Path(
                        None,
                        Path {
                            span: simple.rs:3:19: 3:22 (#0),
                            segments: [
                                PathSegment {
                                    ident: Foo#0,
                                    id: NodeId(4294967040),
                                    args: None,
                                },
                            ],
                            tokens: None,
                        },
                    ),
                    span: simple.rs:3:19: 3:22 (#0),
                    tokens: None,
                },
            ),
        },
        span: simple.rs:3:1: 3:22 (#0),
    },
    body: Some(
        Block {
            stmts: [
                Stmt {
                    id: NodeId(4294967040),
                    kind: Expr(
                        Expr {
                            id: NodeId(4294967040),
                            kind: Call(
                                Expr {
                                    id: NodeId(4294967040),
                                    kind: Path(
                                        None,
                                        Path {
                                            span: simple.rs:4:5: 4:8 (#0),
                                            segments: [
                                                PathSegment {
                                                    ident: Foo#0,
                                                    id: NodeId(4294967040),
                                                    args: None,
                                                },
                                            ],
                                            tokens: None,
                                        },
                                    ),
                                    span: simple.rs:4:5: 4:8 (#0),
                                    attrs: [],
                                    tokens: None,
                                },
                                [
                                    Expr {
                                        id: NodeId(4294967040),
                                        kind: Path(
                                            None,
                                            Path {
                                                span: simple.rs:4:9: 4:10 (#0),
                                                segments: [
                                                    PathSegment {
                                                        ident: x#0,
                                                        id: NodeId(4294967040),
                                                        args: None,
                                                    },
                                                ],
                                                tokens: None,
                                            },
                                        ),
                                        span: simple.rs:4:9: 4:10 (#0),
                                        attrs: [],
                                        tokens: None,
                                    },
                                ],
                            ),
                            span: simple.rs:4:5: 4:11 (#0),
                            attrs: [],
                            tokens: None,
                        },
                    ),
                    span: simple.rs:4:5: 4:11 (#0),
                },
            ],
            id: NodeId(4294967040),
            rules: Default,
            span: simple.rs:3:23: 5:2 (#0),
            tokens: None,
            could_be_bare_literal: false,
        },
    ),
}
\end{verbatim}

\normalsize

\section{High-Level Intermediate Representation
(HIR)}\label{sec:high-level-intermediate-representation-hir}

\small

\begin{verbatim}
Fn(
    FnSig {
        header: FnHeader {
            unsafety: Normal,
            constness: NotConst,
            asyncness: NotAsync,
            abi: Rust,
        },
        decl: FnDecl {
            inputs: [
                Ty {
                    hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).10),
                    kind: Path(
                        Resolved(
                            None,
                            Path {
                                span: simple.rs:3:11: 3:14 (#0),
                                res: PrimTy(
                                    Int(
                                        I32,
                                    ),
                                ),
                                segments: [
                                    PathSegment {
                                        ident: i32#0,
                                        hir_id: HirId(
                                            DefId(0:6 ~ simple[415f]::foo).11),
                                        res: PrimTy(
                                            Int(
                                                I32,
                                            ),
                                        ),
                                        args: None,
                                        infer_args: false,
                                    },
                                ],
                            },
                        ),
                    ),
                    span: simple.rs:3:11: 3:14 (#0),
                },
            ],
            output: Return(
                Ty {
                    hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).12),
                    kind: Path(
                        Resolved(
                            None,
                            Path {
                                span: simple.rs:3:19: 3:22 (#0),
                                res: Def(
                                    Struct,
                                    DefId(0:3 ~ simple[415f]::Foo),
                                ),
                                segments: [
                                    PathSegment {
                                        ident: Foo#0,
                                        hir_id: HirId(
                                            DefId(0:6 ~ simple[415f]::foo).13),
                                        res: Def(
                                            Struct,
                                            DefId(0:3 ~ simple[415f]::Foo),
                                        ),
                                        args: None,
                                        infer_args: false,
                                    },
                                ],
                            },
                        ),
                    ),
                    span: simple.rs:3:19: 3:22 (#0),
                },
            ),
            c_variadic: false,
            implicit_self: None,
            lifetime_elision_allowed: false,
        },
        span: simple.rs:3:1: 3:22 (#0),
    },
    Generics {
        params: [],
        predicates: [],
        has_where_clause_predicates: false,
        where_clause_span: simple.rs:3:22: 3:22 (#0),
        span: simple.rs:3:7: 3:7 (#0),
    },
    BodyId {
        hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).9),
    },
)

...

Expr {
    hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).3),
    kind: Call(
        Expr {
            hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).4),
            kind: Path(
                Resolved(
                    None,
                    Path {
                        span: simple.rs:4:5: 4:8 (#0),
                        res: Def(
                            Ctor(
                                Struct,
                                Fn,
                            ),
                            DefId(0:4 ~ simple[415f]::Foo::{constructor#0}),
                        ),
                        segments: [
                            PathSegment {
                                ident: Foo#0,
                                hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).5),
                                res: Def(
                                    Ctor(
                                        Struct,
                                        Fn,
                                    ),
                                    DefId(0:4 ~ simple[415f]::Foo::{constructor#0}),
                                ),
                                args: None,
                                infer_args: true,
                            },
                        ],
                    },
                ),
            ),
            span: simple.rs:4:5: 4:8 (#0),
        },
        [
            Expr {
                hir_id: HirId(DefId(0:6 ~ simple[415f]::foo).6),
                kind: Path(
                    Resolved(
                        None,
                        Path {
                            span: simple.rs:4:9: 4:10 (#0),
                            res: Local(
                                HirId(DefId(0:6 ~ simple[415f]::foo).2),
                            ),
                            segments: [
                                PathSegment {
                                    ident: x#0,
                                    hir_id: HirId(
                                        DefId(0:6 ~ simple[415f]::foo).7),
                                    res: Local(
                                        HirId(
                                            DefId(0:6 ~ simple[415f]::foo).2),
                                    ),
                                    args: None,
                                    infer_args: true,
                                },
                            ],
                        },
                    ),
                ),
                span: simple.rs:4:9: 4:10 (#0),
            },
        ],
    ),
    span: simple.rs:4:5: 4:11 (#0),
}
\end{verbatim}

\normalsize

\section{Mid-Level Intermediate Representation
(MIR)}\label{sec:mid-level-intermediate-representation-mir}

\begin{verbatim}
fn foo(_1: i32) -> Foo {
    debug x => _1;
    let mut _0: Foo;    

    bb0: {
        _0 = Foo(_1);
        return;
    }
}

fn Foo(_1: i32) -> Foo {
    let mut _0: Foo;    

    bb0: {
        _0 = Foo(move _1);
        return;
    }
}
\end{verbatim}

\chapter{Comparison of BIR and MIR}\label{sec:comparison-of-bir-and-mir}

BIR and MIR dump of the following code are displayed parallel, BIR on
left pages and MIR on right pages. Note that assert macros in MIR were
simplified to fit onto the page.

\section{Compilation Commands}\label{sec:compilation-commands}

\begin{quote}
\begin{verbatim}
$ crab1 -frust-incomplete-and-experimental-compiler-do-not-use \
        -frust-dump-bir -frust-borrowcheck
\end{verbatim}

\texttt{\$\ rustc\ -Zdump-mir=nll\ -Zidentify-regions}
\end{quote}

\section{Rust Source Code}\label{sec:rust-source-code-1}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ fib(n}\OperatorTok{:} \DataTypeTok{u32}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \DataTypeTok{u32} \OperatorTok{\{}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ n }\OperatorTok{==} \DecValTok{1} \OperatorTok{\{}
        \DecValTok{1}
    \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
\NormalTok{        fib(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\NormalTok{ fib(n }\OperatorTok{{-}} \DecValTok{2}\NormalTok{)}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Parallel}[p]{}{}
\ParallelLText{

\section{BIR (Rustc GCC)}\label{sec:bir-rustc-gcc}

\small

\begin{verbatim}
fn fib(_2: u32) -> u32 {
        let _1: u32;    []
        let _2: u32;    []
        let _3: bool;   []
        let _5: u32;    []
        let _6: bool;   []
        let _8: u32;    []
        let _9: bool;   []
        scope 2 {
            let _14: u32;   []
            let _15: u32;   []
            let _16: u32;   []
            let _19: u32;   []
            let _20: u32;   []
            let _21: u32;   []
        }

    bb0: {
    0    StorageLive(_3);
    1    StorageLive(_5);
    2    _5 = _2;
    3    StorageLive(_6);
    4    _6 = Operator(move _5, const u32);
    5    switchInt(move _6) -> [bb1, bb2];
    }

    bb1: {
    0    _3 = const bool;
    1    goto -> bb3;
    }

    bb2: {
    0    StorageLive(_8);
    1    _8 = _2;
    2    StorageLive(_9);
    3    _9 = Operator(move _8, const u32);
    4    _3 = move _9;
    5    goto -> bb3;
    }

    bb3: {
    0    switchInt(move _3) -> [bb4, bb5];
    }

    bb4: {
    0    _1 = const u32;
    1    goto -> bb8;
    }

    bb5: {
    0    StorageLive(_14);
    1    _14 = _2;
    2    StorageLive(_15);
    3    _15 = Operator(move _14, const u32);
    4    StorageLive(_16);
    5    _16 = Call(fib)(move _15) -> [bb6];
    }

    bb6: {
    0    StorageLive(_19);
    1    _19 = _2;
    2    StorageLive(_20);
    3    _20 = Operator(move _19, const u32);
    4    StorageLive(_21);
    5    _21 = Call(fib)(move _20) -> [bb7];
    }

    bb7: {
    0    _1 = Operator(move _16, move _21);
    1    StorageDead(_21);
    2    StorageDead(_20);
    3    StorageDead(_19);
    4    StorageDead(_16);
    5    StorageDead(_15);
    6    StorageDead(_14);
    7    goto -> bb8;
    }

    bb8: {
    0    StorageDead(_9);
    1    StorageDead(_8);
    2    StorageDead(_6);
    3    StorageDead(_5);
    4    StorageDead(_3);
    5    return;
    }
}
\end{verbatim}

}
\ParallelRText{

\section{MIR (rustc)}\label{sec:mir-rustc}

\small

\begin{verbatim}
fn fib(_1: u32) -> u32 {
    debug n => _1;
    let mut _0: u32;    
    let mut _2: bool;   
    let mut _3: u32;    
    let mut _4: bool;   
    let mut _5: u32;    
    let mut _6: u32;    
    let mut _7: u32;    
    let mut _8: u32;    
    let mut _9: (u32, bool);    
    let mut _10: u32;   
    let mut _11: u32;   
    let mut _12: u32;   
    let mut _13: (u32, bool);   
    let mut _14: (u32, bool);   

    bb0: {
        StorageLive(_2);
        StorageLive(_3);
        _3 = _1;
        _2 = Eq(move _3, const 0_u32);
        switchInt(move _2) -> [0: bb2, otherwise: bb1];
    }

    bb1: {
        StorageDead(_3);
        goto -> bb3;
    }

    bb2: {
        StorageDead(_3);
        StorageLive(_4);
        StorageLive(_5);
        _5 = _1;
        _4 = Eq(move _5, const 1_u32);
        switchInt(move _4) -> [0: bb4, otherwise: bb3];
    }

    bb3: {
        StorageDead(_5);
        _0 = const 1_u32;
        goto -> bb10;
    }

    bb4: {
        StorageDead(_5);
        StorageLive(_6);
        StorageLive(_7);
        StorageLive(_8);
        _8 = _1;
        _9 = CheckedSub(_8, const 1_u32);
        assert(!move (_9.1: bool)) -> [success: bb5, unwind: bb11];
    }

    bb5: {
        _7 = move (_9.0: u32);
        StorageDead(_8);
        _6 = fib(move _7) -> [return: bb6, unwind: bb11];
    }

    bb6: {
        StorageDead(_7);
        StorageLive(_10);
        StorageLive(_11);
        StorageLive(_12);
       _12 = _1;
        _13 = CheckedSub(_12, const 2_u32);
        assert(!move (_13.1: bool)) -> [success: bb7, unwind: bb11];
    }

    bb7: {
        _11 = move (_13.0: u32);
        StorageDead(_12);
        _10 = fib(move _11) -> [return: bb8, unwind: bb11];
    }

    bb8: {
        StorageDead(_11);
        _14 = CheckedAdd(_6, _10);
        assert(!move (_14.1: bool)) -> [success: bb9, unwind: bb11];
    }

    bb9: {
        _0 = move (_14.0: u32);
        StorageDead(_10);
        StorageDead(_6);
        goto -> bb10;
    }

    bb10: {
        StorageDead(_4);
        StorageDead(_2);
        return;
    }

    bb11 (cleanup): {
        resume;
    }
}

}
\end{verbatim}

}
\end{Parallel}

\chapter{Examples of Errors Detected by the
Borrow-Checker}\label{sec:errors}

A faulty program from gccrs test suite together with a fixed alternative
(when applicable) is presented. Expected errors are marked using special
comments used by the DejaGnu compiler testing framework.

\section{Move Errors}\label{sec:move-errors}

A simple test, where an instance of type A, which is not trivially
copiable (does not implement the compy trait) is moved twice.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found move errors in function test\_move" \}}
    \KeywordTok{struct}\NormalTok{ A }\OperatorTok{\{}
\NormalTok{        i}\OperatorTok{:} \DataTypeTok{i32}\OperatorTok{,}
    \OperatorTok{\}}
    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=}\NormalTok{ A }\OperatorTok{\{}\NormalTok{ i}\OperatorTok{:} \DecValTok{1} \OperatorTok{\};}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_fixed() }\OperatorTok{\{}
    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// a is now primitive and can be copied}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

More complex text test, where moves the occurence of the error depends
on runtime values. Error is raised bacause for some values, the
violation is possible

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_conditional(b1}\OperatorTok{:} \DataTypeTok{bool}\OperatorTok{,}\NormalTok{ b2}\OperatorTok{:}\DataTypeTok{bool}\NormalTok{) }\OperatorTok{\{}
     \CommentTok{// \{ dg{-}error "Found move errors in function test\_move" \}}
    \KeywordTok{struct}\NormalTok{ A }\OperatorTok{\{}
\NormalTok{        i}\OperatorTok{:} \DataTypeTok{i32}\OperatorTok{,}
    \OperatorTok{\}}

    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=}\NormalTok{ A }\OperatorTok{\{}\NormalTok{ i}\OperatorTok{:} \DecValTok{1} \OperatorTok{\};}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if}\NormalTok{ b1 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if}\NormalTok{ b2 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_fixed(b1}\OperatorTok{:} \DataTypeTok{bool}\OperatorTok{,}\NormalTok{ b2}\OperatorTok{:}\DataTypeTok{bool}\NormalTok{) }\OperatorTok{\{}

    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// a is now primitive and can be copied}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if}\NormalTok{ b1 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if}\NormalTok{ b2 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\section{Subset Errors}\label{sec:subset-errors}

TODO

\section{Loan Error}\label{sec:loan-error}

TODO

The following test were used when Polonius was first experimentally
integrated into rustc.

In this test \texttt{s} is moved while it is borrowed. The test checks
that facts are corectly propagated through the function call.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ foo}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{,} \OtherTok{\textquotesingle{}b}\OperatorTok{\textgreater{}}\NormalTok{(p}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}b} \OperatorTok{\&}\OtherTok{\textquotesingle{}a} \KeywordTok{mut} \DataTypeTok{usize}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \OperatorTok{\&}\OtherTok{\textquotesingle{}b}\OperatorTok{\&}\OtherTok{\textquotesingle{}a} \KeywordTok{mut} \DataTypeTok{usize} \OperatorTok{\{}
\NormalTok{    p}
\OperatorTok{\}}

\KeywordTok{fn}\NormalTok{ well\_formed\_function\_inputs() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found loan errors in function well\_formed...}
    \KeywordTok{let}\NormalTok{ s }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \DecValTok{1}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ r }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \OperatorTok{*}\NormalTok{s}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ foo(}\OperatorTok{\&}\NormalTok{r  )}\OperatorTok{;}
\NormalTok{    s}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
\NormalTok{    tmp}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

This test check that variable cannot be used while borrowed.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ use\_while\_mut() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found loan errors in function use\_while\_mut" \}}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ x }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ x}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ z }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
    \KeywordTok{let}\NormalTok{ w }\OperatorTok{=}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

This test is similar to the previous one but uses a reborrow of a
reference passed as an argument.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ use\_while\_mut\_fr(x}\OperatorTok{:} \OperatorTok{\&}\KeywordTok{mut} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \OperatorTok{\&}\KeywordTok{mut} \DataTypeTok{i32} \OperatorTok{\{} 
    \CommentTok{// \{ dg{-}error "Found loan errors in function use\_while\_mut\_fr" \}}
    \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \OperatorTok{*}\NormalTok{x}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ z }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
\NormalTok{    y}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\chapter{Glossary}\label{sec:glossary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6667}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ABI & Application Binary Interface \\
3-AD & Three Address Code \\
API & Application Programming Interface \\
AST & Abstract Syntax Tree \\
BIR & (gccrs) Borrow-Checker Intermediate Representation \\
CFG & Control Flow Graph \\
CLI & Command Line Interface \\
GCC & GNU Compiler Collection \\
GENERIC & (GCC) The internal representation used by GCC as an interface
between the front-end and the middle-end of the compiler \\
GIMPLE & (GCC) The internal representation used by GCC in the middle-end
of the compiler \\
HIR & (rustc, gccrs) High-level Intermediate Representation \\
IR & Intermediate Representation \\
LLVM & Low Level Virtual Machine \\
MIR & (rustc) Mid-level Intermediate Representation \\
MIRI & (rustc) The Rust MIR interpreter \\
NLL & (rustc) Non-Lexical Lifetimes (a CFG-based borrow-checker) \\
Polonius & The name of the new borrow-checker algorithm and engine \\
RAII & Resource Acquisition Is Initialization (C++ idiom) \\
RFC & Request For Comments (formal process for proposing changes to
Rust) \\
SSA & Static Single Assignment \\
THIR & (rustc) Typed High-level Intermediate Representation \\
TyTy & (rustc, gccrs) Type Intermediate Representation (used after types
are parsed and resolved) \\
basic block & A sequence of instructions with a single entry point and a
single exit point \\
borrow & (Polonius) The act of taking a checked reference \\
fact & (Polonius) Information about the program, reduced to a relation
between enumerated program objects \\
gccrs & GCC Rust Front-end \\
interning & The process of replacing a value with a unique identifier \\
loan & (Polonius) The result of a borrow operation (taking a checked
reference). \\
origin & (Polonius) An inference variable that represents a set of
loans. May be used interchangeably with \emph{region}. \\
outlives & (Polonius) A relationship between two origins, where the
first region must live longer than the second region. Denoted as
\texttt{R1:\ R2} where \texttt{R1} outlives \texttt{R2}. That means that
the set of CFG points R1 represents must be a superset of the set of CFG
points R2 represents. \\
point & (Polonius) A point in the CFG \\
region & (Polonius/NLL) An inference variable that represents a set of
points in the CFG. May be used interchangeably with \emph{origin}. \\
rustc & The main Rust Compiler based on LLVM \\
usize & Unsigned integer type with the same size as a pointer in Rust \\
\end{longtable}

\end{document}
