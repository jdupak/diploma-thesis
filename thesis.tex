% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
]{report}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[BoldFont=Technika-Regular,BoldItalicFont=Technika-Italic]{Latin
Modern Roman}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[a4paper,top=32mm,left=35.6mm,right=35.6mm,bottom=30mm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textbf{#1}}
\newcommand{\AnnotationTok}[1]{\textit{#1}}
\newcommand{\AttributeTok}[1]{#1}
\newcommand{\BaseNTok}[1]{#1}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textit{#1}}
\newcommand{\CommentVarTok}[1]{\textit{#1}}
\newcommand{\ConstantTok}[1]{#1}
\newcommand{\ControlFlowTok}[1]{\textbf{#1}}
\newcommand{\DataTypeTok}[1]{\underline{#1}}
\newcommand{\DecValTok}[1]{#1}
\newcommand{\DocumentationTok}[1]{\textit{#1}}
\newcommand{\ErrorTok}[1]{\textbf{#1}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{#1}
\newcommand{\FunctionTok}[1]{#1}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textit{#1}}
\newcommand{\KeywordTok}[1]{\textbf{#1}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{#1}
\newcommand{\OtherTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textbf{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{#1}
\newcommand{\SpecialStringTok}[1]{#1}
\newcommand{\StringTok}[1]{#1}
\newcommand{\VariableTok}[1]{#1}
\newcommand{\VerbatimStringTok}[1]{#1}
\newcommand{\WarningTok}[1]{\textit{#1}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\usepackage{svg}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{pdfpages}
\usepackage{titlesec}
\usepackage[most]{tcolorbox}
\newtcolorbox{myquote}{colframe=white!75!white}
\renewenvironment{quote}{\begin{myquote}}{\end{myquote}}
\titleformat{\chapter}[display]{\normalfont\LARGE\bfseries}{\chaptertitlename\ \thechapter}{-5pt}{\huge}
\titlespacing*{\chapter}{0pt}{20pt}{20pt}
\let\oldShaded\Shaded
\renewenvironment{Shaded}{\begin{adjustwidth}{2em}{2em}\oldShaded}{\end{adjustwidth}\end{Shaded}}
\makeatletter
\@ifpackageloaded{subfig}{}{\usepackage{subfig}}
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\captionsetup[subfloat]{margin=0.5em}
\AtBeginDocument{%
\renewcommand*\figurename{Figure}
\renewcommand*\tablename{Table}
}
\AtBeginDocument{%
\renewcommand*\listfigurename{List of Figures}
\renewcommand*\listtablename{List of Tables}
}
\newcounter{pandoccrossref@subfigures@footnote@counter}
\newenvironment{pandoccrossrefsubfigures}{%
\setcounter{pandoccrossref@subfigures@footnote@counter}{0}
\begin{figure}\centering%
\gdef\global@pandoccrossref@subfigures@footnotes{}%
\DeclareRobustCommand{\footnote}[1]{\footnotemark%
\stepcounter{pandoccrossref@subfigures@footnote@counter}%
\ifx\global@pandoccrossref@subfigures@footnotes\empty%
\gdef\global@pandoccrossref@subfigures@footnotes{{##1}}%
\else%
\g@addto@macro\global@pandoccrossref@subfigures@footnotes{, {##1}}%
\fi}}%
{\end{figure}%
\addtocounter{footnote}{-\value{pandoccrossref@subfigures@footnote@counter}}
\@for\f:=\global@pandoccrossref@subfigures@footnotes\do{\stepcounter{footnote}\footnotetext{\f}}%
\gdef\global@pandoccrossref@subfigures@footnotes{}}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
% Make links footnotes instead of hotlinks:
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
\hypersetup{
  pdftitle={Memory Safety Analysis in Rust GCC},
  pdfauthor={Jakub Dupak},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Memory Safety Analysis in Rust GCC}
\author{Jakub Dupak}
\date{}

\begin{document}
\maketitle
\begin{abstract}
TODO
\end{abstract}

\includepdf[pages=-]{Thesis_Assignment_Jakub_Dup√°k_Memory_safety_analysis_in_Rust_GCC.pdf}

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\chapter{Introduction}\label{introduction}

The first chapter introduces the problem of borrow-checking and gives a
brief overview of the borrow-checker development in the rustc compiler,
up to the Polonius project, which is utilized by this work. The second
chapter describes the Polonius analysis engine and its API. The third
chapter compares the internal representations of rustc and gccrs to
highlight the challenges of adapting the rustc borrow-checker design to
gccrs. The next chapter explains the design of the borrow-checker
implemented in gccrs as part of this work. It maps the experiments
leading to the current design and describes the new intermediate
representation and its usage in the analysis. Later sections of the
chapter describe other modifications of the rest of the compiler
necessary to support borrow-checking. The final chapter elaborates on
the results, the current state of the implementations, and known missing
features and limitations. Since this work had an experimental nature, it
focused on exploring most aspects of the problem rather than on the
completeness of the solution. Therefore, the final chapter should lead
to future work, extending this experimental work into a production-ready
solution.

\chapter{The Problem of
Borrow-Checking}\label{the-problem-of-borrow-checking}

This section introduces borrow-checking and briefly describes its
development in Rust. First, simple lexical borrow-checking is described.
Then, the more complex control-flow sensitive borrow-checking is
introduced. Finally, the Polonius analysis engine is described. Since
this work utilizes the Polonius engine, it is described in more detail
in the following chapter.

Typical programming language implementations fall into two categories
based on how they manage memory with dynamic storage
duration\footnote{Dynamic storage duration means that it is unknown at
  compile time when storage can be safely reclaimed. In contrast, memory
  with static duration is reclaimed at the end of the program, and
  memory with automatic storage duration is bound to a function call.}.
Languages like C use manual memory management, where the programmer is
responsible for allocating and freeing memory explicitly. Higher-level
languages like Java or Python use automatic memory management, where a
\href{https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)}{garbage
collector} manages the memory in runtime. Since the C approach is
considerably error-prone{[}@nsa{]}, later languages like C++ and
\href{https://ziglang.org/}{Zig} provide tools to make the deallocation
of memory more implicit. For simple cases, they tie the deallocation to
the destruction of other objects
(\href{https://en.cppreference.com/w/cpp/language/raii}{RAII},
\href{https://en.cppreference.com/w/cpp/memory\#Smart_pointers}{smart-pointers},
\href{https://ziglang.org/documentation/master/\#defer}{defer
statements}). What differentiates it from the stack allocation is that
the relationship (called ownership) can be transferred dynamically
between objects. For more complex cases, when there is no single object
to which we can tie the deallocation (that means there are multiple
objects, and the deallocation has to be linked to the destruction of the
last one), they opt-in for a runtime solution
(\href{https://en.wikipedia.org/wiki/Reference_counting}{reference
counting}). Those approaches improve the situation considerably.
However, there are two problems remaining. First, those ownership bounds
can be created incorrectly by the programmer, mainly in cases where the
ownership of the memory is transferred between objects. The situation is
even worse when two systems with different memory management models are
interfaced\footnote{An interface between a C++ application with
  \href{https://www.cppreference.com/Cpp_STL_ReferenceManual.pdf}{STL-based}
  memory management and the \href{https://www.qt.io/}{Qt GUI framework},
  where all Qt API methods take raw pointers (as opposed to smart
  pointers.). Some of those methods assume that the ownership is
  transferred, and some of them do not. Those methods can only be
  differentiated using their documentation.}. Second, when the ownership
is not transferred, but a copy of the pointer is used temporarily (this
is called ``borrowing'' in Rust), assuming that the owning object will
exist for the whole time this copy is used. Such an assumption is often
wrong, and this kind of mistake is often called a ``dangling
pointer.''{[}@danglingpointer{]}

The Rust language builds on the RAII approach; however, it adds a
built-in static analysis called the borrow-checker to make sure that the
mistakes mentioned above cannot happen. To make such analysis feasible,
Rust only allows a conservative subset of memory-safe operations.
Furthermore, Rust adds further limitations to ensure that memory use is
safe even during multithreaded execution. Because these restrictions are
very strict, and they would severely limit the language, Rust provides a
feature to lift some of those restrictions in clearly denoted ``unsafe''
areas. The responsibility for maintaining the safety invariants in
``unsafe'' code falls on the programmer.

The key idea behind Rust memory safety is to strictly (using the type
system) differentiate the two problematic cases: ownership transfers and
borrows. Ownership transfer ties all owned unique resources to another
object, detaching them from the current object. This operation is called
``move'' in Rust (and C++). Unlike C++, Rust does not allow objects to
store a reference to themselves, simplifying the ownership transfer
semantics to just a bitwise copy. Rust static analysis also ensures that
the old object is not used after it has been ``moved from.''

Borrow is a temporary usage of an object without ownership transfer. A
typical example is a method call. For borrows, Rust uses static analysis
to ensure that the borrowed object cannot be deallocated while in use
(in Rust terms, the borrowed object has to \emph{outlive} the borrow).
However, since a whole program analysis would be very expensive, Rust
performs the analysis only inside of a single function. It requires the
programmer to formally describe the invariants of lifetimes (subsets of
the program where each reference has to be valid) on a function
boundary. The invariants are checked inside the function and assumed
outside of the function, resulting in a safe program. The invariants are
described using so-called lifetime annotations. The programmer can think
about a lifetime annotation as an inference variable. The domain of the
variable represents a subset of the program (set of lines, expressions
control, or control flow graph nodes). The task of the borrow-checker is
to resolve each inference variable to an actual subset of the program
where the borrow is valid. This subset might not be unique. The
existence of such a subset is sufficient to prove that the program is
safe.

The annotations are related to each other by ``outlives'' relations,
requiring one reference lifetime to be a subset of another lifetime.
These constraints are used to describe the relationship of the inputs
and outputs of a function, providing a simplified, conservative
description of all the relevant code outside of the function.

\begin{quote}
\textbf{Example}: We have a vector-like structure (a dynamic array), and
we want to store references to integers as elements. We need to make
sure that as long as the vector exists, all references stored in it are
valid. However, we do not want the vector to own the integers. First, we
introduce a lifetime parameter \texttt{\textquotesingle{}a}, which
represents all the regions where the vector itself is alive. This
parameter will be substituted at a particular use site with a concrete
lifetime.

\begin{Shaded}
\begin{Highlighting}[]

    \KeywordTok{struct} \DataTypeTok{Vec}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \OperatorTok{\{} \OperatorTok{...} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then, for the add method, we introduce a lifetime parameter
\texttt{\textquotesingle{}b}, which restricts the inserted reference.
This parameter is substituted with a concrete lifetime of each reference
when the method is invoked. Finally, we will require that the method can
only be used with lifetimes, for which we can guarantee that
\texttt{\textquotesingle{}b} is a subset of \texttt{\textquotesingle{}a}
(in terms of parts of the program). We do that by adding the
\texttt{\textquotesingle{}a:\ \textquotesingle{}b} constraint.
\texttt{\textquotesingle{}a:\ \textquotesingle{}b} usually reads as
``\texttt{\textquotesingle{}a} outlives '\texttt{b},'' and it means that
``'a lasts at least as long as 'b, so a reference
\texttt{\&\textquotesingle{}a\ i32} is valid whenever
\texttt{\&\textquotesingle{}b\ i32} is
valid.''\href{https://doc.rust-lang.org/reference/trait-bounds.html\#lifetime-bounds}{{[}@reference{]}}

\begin{Shaded}
\begin{Highlighting}[]

    \KeywordTok{impl}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \DataTypeTok{Vec}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{\textgreater{}} \OperatorTok{\{}
        \KeywordTok{fn}\NormalTok{ add}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}b}\OperatorTok{\textgreater{}} \KeywordTok{where} \OtherTok{\textquotesingle{}a}\OperatorTok{:} \OtherTok{\textquotesingle{}b}\NormalTok{ (}\OperatorTok{\&}\KeywordTok{mut} \KeywordTok{self}\OperatorTok{,}\NormalTok{ x}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}b} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{\{} \OperatorTok{...} \OperatorTok{\}}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\section{The Evolution of Borrow-Checking in
rustc}\label{the-evolution-of-borrow-checking-in-rustc}

This section describes how the analysis evolved, gradually rejecting
less memory-safe programs. rustc started with lexical (scope-based
analysis), followed by the first non-lexical (CFG-based) analysis, which
is being extended by the Polonius project. This section strongly builds
upon RFC 2094{[}@rfc2094nll{]}, which introduced non-lexical
borrow-checking to Rust. Examples from that RFC are presented in this
section.

The simplest variant of borrow-checker is based on stack variable
scopes. A reference is valid from the point in the program (here in
terms of statements and expression) where it is created until the end of
the current scope. This approach can be extended to handle some common
programming patterns as special cases. For example, when a reference is
created in function parameters, it is valid until the end of the
function call.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \OperatorTok{\{}
        \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;} \CommentTok{// {-}{-}+ \textquotesingle{}scope}
\NormalTok{        capitalize(}\OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{])}\OperatorTok{;}          \CommentTok{//   |}
    \CommentTok{//  \^{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{} \textquotesingle{}lifetime //   |}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;}                     \CommentTok{//   |}
    \OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

However, a very common modification might cause the program to be
rejected. Since the reference is not created in the list of function
arguments but rather as a local variable, the special case does not
apply, and the reference has to be valid until the end of the scope for
the variable \texttt{slice}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \OperatorTok{\{}
        \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
        \KeywordTok{let}\NormalTok{ slice }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{]}\OperatorTok{;} \CommentTok{// \textless{}{-}+ \textquotesingle{}lifetime}
\NormalTok{        capitalize(slice)}\OperatorTok{;}         \CommentTok{//   |}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// ERROR!  //   |}
    \OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

Now, there is no simple way to say when the lifetime of the reference
should end to prove that his program is safe from its syntactic
structure. The code above can be fixed by explicitly specifying where
the lifetime should end. However, this clutters the code, and it cannot
be used for more advanced cases.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \OperatorTok{\{}
        \KeywordTok{let} \KeywordTok{mut}\NormalTok{ data }\OperatorTok{=} \PreprocessorTok{vec!}\NormalTok{[}\CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{,} \CharTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
        \OperatorTok{\{}
            \KeywordTok{let}\NormalTok{ slice }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ data[}\OperatorTok{..}\NormalTok{]}\OperatorTok{;} \CommentTok{// \textless{}{-}+ \textquotesingle{}lifetime}
\NormalTok{            capitalize(slice)}\OperatorTok{;}         \CommentTok{//   |}
        \OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
\NormalTok{        data}\OperatorTok{.}\NormalTok{push(}\CharTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{// OK}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

One of those more advanced cases happens when lifetimes are not
symmetric in conditional branches. A typical case is when a condition
checks the presence of a value. In the positive branch, we are holding a
reference to the value, but in the negative branch, we are not.
Therefore, it is safe to create a new reference in the negative branch.
By ``safe,'' we mean that there will only be one reference pointing to
the \texttt{map} object at any time. A convenient way to describe ``at
any time'' is using the control from graph (CFG) representation of the
program.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ map }\OperatorTok{=} \OperatorTok{...;}
    \KeywordTok{let}\NormalTok{ key }\OperatorTok{=} \OperatorTok{...;}
    \ControlFlowTok{match}\NormalTok{ map}\OperatorTok{.}\NormalTok{get\_mut(}\OperatorTok{\&}\NormalTok{key) }\OperatorTok{\{} \CommentTok{// {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+ \textquotesingle{}lifetime}
        \ConstantTok{Some}\NormalTok{(value) }\OperatorTok{=\textgreater{}}\NormalTok{ process(value)}\OperatorTok{,}     \CommentTok{// |}
        \ConstantTok{None} \OperatorTok{=\textgreater{}} \OperatorTok{\{}                          \CommentTok{// |}
\NormalTok{            map}\OperatorTok{.}\NormalTok{insert(key}\OperatorTok{,} \PreprocessorTok{V::}\KeywordTok{default}\NormalTok{())}\OperatorTok{;} \CommentTok{// |}
            \CommentTok{//  \^{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{} ERROR.              // |}
        \OperatorTok{\}}                                  \CommentTok{// |}
    \OperatorTok{\}} \CommentTok{// \textless{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\end{Highlighting}
\end{Shaded}
\end{quote}

For more examples, see the RFC 2094{[}@rfc2094nll{]}. However, the
provided examples should be sufficient to demonstrate that analyzing the
program on a control flow graph (CFG) instead of the syntactic structure
(AST) enables the borrow-checker to validate and ensure the safety of
complex programs that were previously rejected.

The above analysis thinks about lifetimes as regions (set of points in
CFG) where the reference is valid. The goal of the analysis is to find
the smallest regions such that the reference is not required to be valid
outside of those regions. The smaller the regions, the more references
can coexist at the same time, allowing more programs to be accepted.

The next generation of borrow-checking in Rust is based on the Polonius
analysis engine. Polonius is an extension of NLL (non-lexical
lifetimes), which is capable of proving move programs to be safe by
using a different interpretation of lifetimes.

NLL cannot handle the following code, but Polonius can handle it. The
problem here is that everything that is tied to external lifetimes
(\texttt{\textquotesingle{}a}) has to be valid for the whole function.
Since \texttt{v} is returned, it has to outlive the lifetime
\texttt{\textquotesingle{}a}. However, the lifetime of \texttt{v} is
bound to the lifetime of the reference to the hashmap it is stored in.
It forces the \texttt{map} to be borrowed (transitively) for at least
the whole function. That includes the \texttt{map.insert} call, which
needs to borrow the hashmap itself, resulting in an error. However, we
can clearly see that no reference to \texttt{map} is available in the
\texttt{None} branch. This is where Polonius can help.

Instead of starting with references and figuring out where they need to
be valid, Polonius goes in the other direction and tracks what
references need to be valid at each point in the program. As we have
determined in the example above, there is no preexisting reference to
the \texttt{map} in the \texttt{None} branch.

It is important to note that only internal computations inside the
compiler are changed by this. This change does not affect the language
semantics. It only lifts some limitations of the compiler.

Another significant contribution of the Polonius project is the fact
that it replaces many handwritten checks with formal logical rules.
Also, because it knows which references are conflicting, it can be used
to provide better error messages.

\chapter{Polonius Engine}\label{polonius-engine}

The Polonius engine was created by
\href{https://github.com/nikomatsakis}{Niko Matsakis} and extended by
\href{https://github.com/lqd/}{R√©my Rakic} and Albin
Stjerna{[}@Stjerna2020{]} as a next-generation control-flow sensitive
borrow-checking analysis for rustc. It was designed as an independent
library that can be used both by the rustc compiler and different
research projects, which makes it suitable for usage in gccrs. Polonius
interfaces with the compiler by passing around a struct of
vectors\footnote{A contiguous growable array type from the Rust standard
  library. (\url{https://doc.rust-lang.org/std/vec/struct.Vec.html})} of
facts, where each fact is represented by a tuple of integers\footnote{\texttt{usize}}
(or types convertible to integers). It is completely unaware of the
compiler internals.

In the previous chapter, we have mentioned that Polonius differs from
NLL in its interpretation of lifetimes. Polonius uses the term
``Origin'' to better describe the concept. An origin is a set of loans
that can be referenced using a variable at each CFG point. In other
words, it tracks ``where the references that are used could have
originated.''

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
   \KeywordTok{let}\NormalTok{ r}\OperatorTok{:} \OperatorTok{\&}\CharTok{\textquotesingle{}}\DecValTok{0} \DataTypeTok{i32} \OperatorTok{=} \ControlFlowTok{if}\NormalTok{ (cond) }\OperatorTok{\{}
           \OperatorTok{\&}\NormalTok{x }\CommentTok{/* Loan L0 */}
       \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
           \OperatorTok{\&}\NormalTok{y }\CommentTok{/* Loan L1 */}
       \OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} \emph{The origin of the reference \texttt{r} (denoted
as \texttt{\textquotesingle{}0}) is the set of loans \texttt{L0} and
\texttt{L1}. Note that this fact is initially unknown, and it is the
task of the analysis to compute it.}
\end{quote}

The engine first preprocesses the input facts. It computes transitive
closures of relations and analyzes all the initialization and
deinitializations that happen over the CFG. Then, it checks for move
errors, i.e., when ownership of some object is transferred more than
once. In the next step, the liveness of variables and the ``outlives''
graph (transitive constraints of lifetimes at each CFG point) are
computed{[}@polonius2{]}. All origins that appear in the type of live
variable are considered live.

Then Polonius needs to figure out \emph{active loans}. A loan is active
at a CFG point if two conditions hold. Any origin that contains the loan
is live (i.e., there is a variable that might reference it), and the
variable/place referencing the loan was not reassigned. (When a
reference variable is reassigned, it points to something else.)

The compiler has to specify all the points in the control flow graph
where a loan being alive would violate the memory safety rules. Polonius
then checks whether such a situation can happen. If it can, it reports
the facts involved in the violation. For example, if a mutable loan of a
variable is alive, then any read/write/borrow operation on the variable
invalidates the loan.

\begin{figure}
\centering
\includesvg{polonius.svg}
\caption{Steps performed by Polonius to find error. The starting nodes
correspond to \emph{facts} supplied to Polonius by the compiler. Inner
nodes represent intermediate results produced by the analysis. Errors
(at the bottom) are ultimately returned to the compiler. (The graphic
was adapted from {[}@Stjerna2020{]}.)}
\end{figure}

\section{Polonius Facts}\label{polonius-facts}

This section provides a list of facts taken by Polonius to give the
reader a better idea of the work that needs to be done by the compiler.
The facts are grouped into categories and briefly described. The full
list of facts can be found in the
\href{https://github.com/rust-lang/polonius/blob/master/polonius-engine/src/facts.rs}{Polonius
source code} and the Polonius Book{[}@polonius{]}.

\begin{itemize}
\tightlist
\item
  Control flow graphs edges (\texttt{cfg\_edge:\ (Point,\ Point)}).
\item
  Facts regarding variable usage and its effects.

  \begin{itemize}
  \tightlist
  \item
    \texttt{var\_used\_at:\ (Variable,\ Point)} - Any usage of variable
    except for a drop (destructor).
  \item
    \texttt{var\_defined\_at:\ (Variable,\ Point)} - Start of scope or
    reassignment. This reassignment treatment makes the variable act
    similarly to an
    \href{https://en.wikipedia.org/wiki/Static_single-assignment_form}{SSA
    variable}.
  \item
    \texttt{var\_dropped\_at:\ (Variable,\ Point)} - Drop (destructor
    call) of the variable.
  \item
    \texttt{use\_of\_var\_derefs\_origin:\ (Variable,\ Origin)} - The
    type of the variable contains the origin.
  \item
    \texttt{drop\_of\_var\_derefs\_origin:\ (Variable,\ Origin)} - When
    the drop implementation used the origin.
  \end{itemize}
\item
  Facts regarding paths and their usages. Paths represent indirect or
  partial access to a variable (e.g., field access or cast).

  \begin{itemize}
  \tightlist
  \item
    \texttt{path\_is\_var:\ (Path,\ Variable)} - Lists ``trivial'' paths
    that are just a variable.
  \item
    \texttt{child\_path:\ (Path,\ Path)} - Describes hierarchical
    (non-transitive) relationships between paths. For example, a field
    path is a child path of the variable path it is accessed from.
  \item
    \texttt{path\_assigned\_at\_base:\ (Path,\ Point)} - Path is
    assigned at the CFG point. ``base'' means that this fact is emitted
    only for the exact path used, not all its parent paths.
  \item
    \texttt{path\_moved\_at\_base:\ (Path,\ Point)} - Ownership of
    origins is transferred at the CFG point.
  \item
    \texttt{path\_accessed\_at\_base:\ (Path,\ Point)} - Any memory
    access to the path (read or write).
  \end{itemize}
\item
  Facts about relationships (subset relation) of origins.

  \begin{itemize}
  \tightlist
  \item
    \texttt{known\_placeholder\_subset:\ (Origin,\ Origin)} -
    Constraints on universal origins (those representing loans that
    happened outside the function).
  \item
    \texttt{universal\_region:\ (Origin)} - List of universal origins.
    (See the previous point.)
  \item
    \texttt{subset\_base:\ (Origin,\ Origin)} - Any relationship between
    origins required by the subtyping rules.
  \item
    \texttt{placeholder:\ (Origin,\ Loan)} - Associates an origin with a
    loan.
  \end{itemize}
\item
  Facts about loans.

  \begin{itemize}
  \tightlist
  \item
    \texttt{loan\_issued\_at:\ (Loan,\ Point)} - Result of borrow
    expression.
  \item
    \texttt{loan\_killed\_at:\ (Loan,\ Point)} - Loan is no longer live
    after this point.
  \item
    \texttt{loan\_invalidated\_at:\ (Loan,\ Point)} - If the loan is
    live at this point, it is an error.
  \end{itemize}
\end{itemize}

\chapter{Comparison of Internal
Representations}\label{comparison-of-internal-representations}

The execution of a borrow-checker with an external analysis engine
consists of two steps. First, we need to collect the relevant
information about the program. We will call that information
\emph{facts}\footnote{This follows the terminology used by
  Polonius{[}@polonius{]}.}. Second, we need to send those facts to the
external engine and process them. Before we can discuss the
\emph{collection} of facts itself, we need to understand how programs
are represented inside the compiler. We will use the term \emph{internal
representation} (IR) to refer to the representation of the program
inside the compiler. We will compare the IRs used by rustc and gccrs to
highlight the differences between the two compilers. This will help us
understand the challenges of adapting the borrow-checker design from
rustc to gccrs. First, we will describe the IRs used by rustc, and then
we will compare them with those used in gccrs.

\section{GCC and LLVM}\label{gcc-and-llvm}

To understand the differences between each of the compilers, we must
first explore the differences between the compiler platforms they are
built on (GCC and LLVM). We will only focus on the middle-end of each
platform since the back-end does not influence the front-end directly.

The core of LLVM is a three-address code (3-AD)\footnote{Three-address
  code represents the program as sequences of statements (we call such
  sequence a \emph{basic block}), connected by control flow
  instructions, forming a control flow graph (CFG).} representation,
called the LLVM intermediate representation (LLVM IR) {[}@llvm,
llvm-ir{]}. This IR is the interface between front-ends and the compiler
platform (the middle-end and the back-end). Each front-end is
responsible for transforming its custom AST IR\footnote{Abstract syntax
  tree (AST) is a data structure used to represent the structure of the
  program. It is the direct product of program parsing. For example, an
  expression \texttt{1\ +\ (2\ -\ 7)} would be represented as a node
  \texttt{subtraction}, with the left child being the number one and the
  right child being the AST for the subexpression \texttt{(2\ -\ 7)}.}
into the LLVM IR. The LLVM IR is stable and strictly separated from the
front-end, hence it cannot be easily extended to include
language-specific constructs.

\begin{figure}
\centering
\includesvg[width=0.9\textwidth,height=\textheight]{llvm-ir-cfg-example.svg}
\caption{LLVM IR CFG Example (generated by Compiler Explorer)}
\end{figure}

GCC, on the other hand, interfaces with the front-ends using a
tree-based representation called GENERIC{[}@gccint, p.~175{]}. GENERIC
was created as a generalized form of AST shared by most front-ends. GCC
provides a set of common tree nodes to describe all the standard
language constructs in the GENERIC IR. Front-ends may define
language-specific constructs and provide hooks for their
handling.{[}@gccint, p.~212{]} This representation is then transformed
into the GIMPLE representation, which is mostly\footnote{``GIMPLE that
  is not fully lowered is known as ``High GIMPLE'' and consists of the
  IL before the \texttt{pass\_lower\_cf}. High GIMPLE contains some
  container statements like lexical scopes and nested expressions, while
  ``Low GIMPLE'' exposes all of the implicit jumps for control and
  exception expressions directly in the IL and EH region
  trees.''{[}@gccint, p.~225{]}} a 3-AD representation. It does so by
breaking down expressions into a sequence of statements and introducing
temporary variables. This transformation is done inside the compiler
platform, not in the front-end. This approach makes the front-ends
smaller and shifts more work into the shared part. The GIMPLE
representation does not contain information specific to each front-end
(programming language). However, it is possible to store
language-specific information in GIMPLE by adding entirely new
statements.{[}@gccint, p.~262{]} This is possible because GIMPLE is not
a stable interface.

The key takeaway from this section is that rustc has to transform the
tree-based representation into a 3-AD representation by itself. That
means it can access the program's control flow graph (CFG). This is not
the case for gccrs. In GCC, the CFG is only available in the \emph{Low
GIMPLE} representation, deep inside the middle-end, where the
representation is language independent.

\section{Rustc's Representation}\label{rustcs-representation}

In the previous section, we have seen that rustc is responsible for
transforming the code from the raw text to the LLVM IR. Given the high
complexity of the Rust language, rustc uses multiple intermediate
representations (IRs) to simplify the process (see the diagram below).
The text is first tokenized and parsed into an abstract syntax tree
(AST) and then transformed into the high-level intermediate
representation (HIR). For transformation into a middle-level
intermediate representation (MIR), the HIR is first transformed into a
typed HIR (THIR). The MIR is then transformed into the LLVM IR.

\begin{figure}
\centering
\includesvg[width=0.75\textwidth,height=\textheight]{./pipeline.svg}
\caption{Comparison of compiler pipelines with a focus on internal
representations}
\end{figure}

AST is a tree-based representation of the program, closely following
each source code token. At this stage, rustc performs macro-expansion
and a partial name resolution (macros and imports) {[}@devguide
\footnote{\url{https://rustc-dev-guide.rust-lang.org/macro-expansion.html}}
\footnote{\url{https://rustc-dev-uide.rust-lang.org/name-resolution.html}}{]}.
As the AST is lowered to HIR, some complex language constructs are
desugared to simpler constructs. For example, various kinds of loops are
transformed into a single infinite loop construct (Rust \texttt{loop}
keyword), and many structures that can perform pattern matching
(\texttt{if\ let}, \texttt{while\ let}, \texttt{?} operator) are
transformed into the `match`` construct{[}@reference \footnote{\href{https://doc.rust-lang.\%20org/reference/expressions/if-expr.html\#if-let-expressions}{https://doc.rust-lang.org/reference/expressions/if-expr.html\#if-let-expressions}}{]}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
   \KeywordTok{struct}\NormalTok{ Foo(i31)}\OperatorTok{;}

   \KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:}\NormalTok{ i31) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{       Foo(x)}
   \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} This very simple code will be used as an example
throughout this section.
\end{quote}

\begin{quote}
\begin{verbatim}
   Fn {
     generics: Generics { ... },
     sig: FnSig {
       header: FnHeader { ... },
         decl: FnDecl {
           inputs: [
             Param {
               ty: Ty {
                 Path { segments: [ PathSegment { ident: i32#0 } ] }
               }
               pat: Pat { Ident(x#0) }
             },
           ],
           output: Ty {
               Path { segments: [ PathSegment { ident: Foo#0 } ]
           }
         },
     },
     body: Block {
       stmts: [ Stmt { Expr {
         Call(
           Expr {
             Path { segments: [ PathSegment { ident: Foo#0 } ] }
           }
           params: [
             Expr {
               Path { segments: [ PathSegment { ident: x#0 } ] }
             }
           ]
         )
       ]
     }
   }
\end{verbatim}

\textbf{Example:} This is a textual representation of a small and
simplified part of the abstract syntax tree (AST) of the example
program. The full version can be found in the
\hyperref[appendix-a-ast-dump-example]{Appendix A}.
\end{quote}

HIR is the primary representation used for most rustc
operations{[}@devguide, HIR{]}. It combines a simplified version of the
AST with additional tables and maps for quick access to extra
information. Those tables contain, for example, information about the
types of expressions and statements. These tables are used for analysis
passes, e.g., the full (late) name resolution and type checking. The
type-checking process includes checking the type correctness of the
program, type inference, and resolution of type-dependent implicit
language constructs.{[}@devguide \footnote{\url{https://rustc-dev-guide.rust-lang.org/type-checking.html}}{]}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \AttributeTok{\#[}\NormalTok{prelude\_import}\AttributeTok{]}
    \KeywordTok{use} \PreprocessorTok{::std::prelude::rust\_2015::}\OperatorTok{*;}
    \AttributeTok{\#[}\NormalTok{macro\_use}\AttributeTok{]}
    \KeywordTok{extern} \KeywordTok{crate}\NormalTok{ std}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Foo(}\DataTypeTok{i32}\NormalTok{)}\OperatorTok{;}

    \KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}\NormalTok{ Foo(x) }\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} One of HIR dump formats: HIR structure still
corresponds to a valid Rust program, equivalent to the original one.
\texttt{rustc} provides a textual representation of HIR, which displays
such a program.
\end{quote}

The HIR representation can contain many placeholders and ``optional''
fields that are resolved during the HIR analysis. To simplify further
processing, parts of HIR that correspond to executable code (e.g., not
type definitions) are transformed into THIR (Typed High-Level
Intermediate Representation), where all the missing information must be
resolved. The reader can think about HIR and THIR in terms of the
\href{https://en.wikipedia.org/wiki/Builder_pattern}{builder pattern}.
HIR provides a flexible interface for modification, while THIR is the
final immutable representation of the program. This involves not only
the data stored in HIR helper tables but also parts of the program that
are implied from the type system. That means that operator overloading,
automatic references, and automatic dereferences are all resolved into
explicit code at this stage.

The final \texttt{rustc} IR, which is lowered directly to the LLVM IR,
is the Mid-level Intermediate Representation (MIR). We will pay extra
attention to MIR because it is the primary representation used by the
borrow-checker. MIR is a three-address code representation, similar to
LLVM IR but with Rust-specific constructs. It contains information about
types, including lifetimes. It differentiates pointers and references,
as well as mutable and immutable references. It is aware of panics and
stack unwinding. It contains additional information for borrow-checker,
like storage live/dead annotations, which denote when a place (an
abstract representation of a memory location) is first used or last
used, and fake operations, which help with the analysis. For example, a
fake unwind operation inside infinite loops ensures an exit edge in the
CFG. Fake operations can be critical for algorithms that process the CFG
in reverse order.

MIR consists of sequences of statements (basic blocks) connected by
control flow instructions. This structure forms a control flow graph.
MIR statements operate on places (often called lvalue in other
languages) and rvalues. A place can represent either a local variable or
a value derived from the variable (e.g., a field, an index, cast).

Rustc also uses a special IR, called the TyTy, to represent types.
Initially, types are represented in HIR on a syntactic level. Every
mention of a type in the program compiles into a distinct HIR node.
These HIR nodes are compiled into the TyTy representation during the
analysis of HIR. Each type (all of its occurrences in the program) is
represented by a single TyTy object instance. This is achieved by
\href{https://en.wikipedia.org/wiki/Interning_\%28computer_science\%29}{interning}.
Note that there can be multiple equivalent types of different
structures. Those are represented by different TyTy instances. Each
non-primitive type forms a tree (e.g., reference to a pair of an integer
and a character), where the inner nodes are shared between types due to
interning. Generic types, which are of particular interest to
borrow-checking, are represented as a pair: an inner type and a list of
generic arguments. When generic type parameters are substituted for
concrete types, the concrete type is placed into the argument list. The
inner type is left unchanged. When the type substitution is complete,
there is a procedure that transforms the generic type into a concrete
type.

Inside the HIR, after the type-checking analysis, TyTy types of nodes
can be looked up based on the node's ID in one of the helper tables
(namely, the type-check context). Each \texttt{THIR} node directly
contains a pointer to its type. In MIR, the type is stored inside each
place.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{fn}\NormalTok{ foo(\_1}\OperatorTok{:} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{        debug x }\OperatorTok{=\textgreater{}}\NormalTok{ \_1}\OperatorTok{;}
        \KeywordTok{let} \KeywordTok{mut}\NormalTok{ \_0}\OperatorTok{:}\NormalTok{ Foo}\OperatorTok{;}  

\NormalTok{        bb0}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{            \_0 }\OperatorTok{=}\NormalTok{ Foo(\_1)}\OperatorTok{;}
            \ControlFlowTok{return}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} MIR dump For further details, see the chapter ``Source
Code Representation'' in {[}@devguide{]}.
\end{quote}

\section{Rust GCC representation}\label{rust-gcc-representation}

\begin{quote}
This section discusses intermediate representations in gccrs. Since
gccrs is a second implementation of the Rust compiler, it is heavily
inspired by rustc. Therefore, this section assumes familiarity with
rustc's intermediate representations, described in the previous section.
We will focus on similarities and differences between rustc and gccrs,
rather than describing the gccrs intermediate representation in full
detail.
\end{quote}

The gccrs representation is strongly inspired by rustc. It diverges
mostly for two reasons: for simplicity, since gccrs is still in an early
stage of development, and due to the specifics of the GCC platform.
Gccrs uses its own variants of AST, HIR, and TyTy representations but
does not use a THIR or MIR.

AST and HIR representations are similar to rustc, with fewer features
supported. The main difference is the structure of the representation.
Rustc takes advantage of algebraic data types, resulting in very
fine-grained representation. On the other hand, gccrs is severely
limited by the capabilities of C++11 and is forced to use an
object-oriented approach.

There is no THIR and MIR or any equivalent in gccrs. MIR cannot be used
in GCC unless the whole gccrs code generation is rewritten to output
(low) GIMPLE instead of GENERIC, which would be way more complex than
the current approach. Given the limited development resources of gccrs,
this is not a viable option.{[}@zulip{]}

TyTy type representation is simplified in gccrs and provides no
uniqueness guarantees. There is a notable difference in the
representation of generic types. Instead of being built on top of the
types (by composition) like in rustc, types that support generic
parameters inherit from a common base class. That means the type
definition is not shared between different generic types. The advantage
of this approach is that during the substitution of generic parameters,
the inner types are modified during each type substitution, simplifying
intermediate handling, like type inference.

\chapter{Rust GCC Borrow-checker
Design}\label{rust-gcc-borrow-checker-design}

The Rust GCC borrow-checker is designed to be as similar to the rustc
borrow-checker as possible within the constraints of the Rust GCC. This
allows us to leverage existing knowledge about borrow-checking in Rust.
The analysis works in two phases. First, it collects relevant
information (called facts) about the program, which are stored as tuples
of numbers. Each number represents a CFG node, variable, path/place, or
loan (a borrow expression). Then, the borrow-checker passes the facts to
the analysis engine, which computes the results of the analysis. The
compiler receives back the facts involved in memory safety violations
and translates them into error messages. The main decision of the Rust
GCC borrow-checker is to reuse the analysis engine from rustc. To
connect the Polonius engine written in Rust to the gccrs compiler
written in C++, we use the C ABI and a thin Rust wrapper.

This chapter describes the process of designing the gccrs
borrow-checker, the decisions made during the process, and the final
design. Special emphasis is placed on a new borrow-checker intermediate
representation (BIR) and its usage in the analysis. The chapter also
describes other modifications of the compiler necessary to support
borrow-checking. The final section briefly describes the design of error
reporting.

\section{Analysis of the Fact Collection
Problem}\label{analysis-of-the-fact-collection-problem}

This section described options for fact collection in gccrs that were
considered and experimented with during the initial design phase. Due to
the differences between internal representations of rustc and gccrs, it
was impossible to copy the rustc approach exactly. Considered options
were to use HIR directly, to implement MIR in gccrs, or to design a new
IR for borrow-checking with multiple options to place it inside the
compilation pipeline.

The analysis has been control-flow sensitive since NLL's introduction in
rustc (see section
\hyperref[the-evolution-of-borrow-checking-in-rustc]{2.1}), requiring us
to match the required facts, which are specific to Rust semantics, with
control-flow graph nodes. We need to distinguish between pointers (in
unsafe Rust) and references. Pointers are not subject to
borrow-checking, but references are. Furthermore, we need to distinguish
between mutable and immutable references since they have different
rules, which is essential for borrow-checking\footnote{The critical rule
  of borrow-checking is that for a single borrowed variable, there can
  only be a single mutable borrow or only immutable borrows valid at
  each point of the CFG.}. Each type must carry information about its
lifetimes and their variances (described later in this chapter). We need
to store the explicit lifetime parameters from explicit user type
annotation.

The only IR in GCC that contains CFG information is GIMPLE; however,
under normal circumstances, GIMPLE is language agnostic. It is possible
to annotate GIMPLE statements with language-specific information using
special statements, which would have to be generated from special
information that would need to be added to GENERIC. The statements would
need to be preserved by the middle-end passes until the pass building
the CFG (that includes 11 passes), after which facts could be collected.
After that, the facts would need to be discarded to avoid complicating
the tens of following passes\footnote{See file \texttt{gcc/passes.def}
  in the GCC source code.}{[}@gccint, p.~141{]}, and RTL generation.
This approach was discussed with senior GCC developers and quickly
rejected as it would require a large amount of work and leak
front-end-specific information into the middle-end, making it more
complex. No attempt was made to experiment with this approach.

It was clear that we needed to build a CFG. Luckily, working with a
particular control flow graph created by the compiler is unnecessary.
Any CFG that is consistent with Rust semantics is sufficient. In
particular, adding any edges and merging nodes in the CFG is
conservative with regard to the borrow-checking analysis. In many cases,
it does not change the result at all.

Initially, we tried to collect information from the HIR directly and
compute an approximate CFG on the fly. That worked nicely for simple
language constructs that are local, but it gets very complicated for
more complex constructs like patterns and loops with \texttt{break} and
\texttt{continue} statements. Since no representation is generated,
there is no easy way to verify the process, not even by manual checking.
Furthermore, it was not clear how to handle panics and stack unwinding
in this model.

An option to ease such problems was to radically desugared the HIR to
only basic constructs. An advantage of this approach is that it would
leverage the code already existing in the code generator, making the
code generation easier. Also, the code generator already performs some
of those transformations locally (not applying them back to HIR, but
using them directly for GENERIC generation), so those could be reused.
The problem that quickly arose was that the HIR visitor system was not
designed for HIR-to-HIR transformations, where new nodes would be
created. Many such transformations, like explicit handling of automatic
referencing and dereferencing, would require information about the type
of each node, which would, in return, require name resolution results.
Therefore, that transformation would have to happen after all analysis
passes on HIR are completed. However, all information stored alongside
HIR would need to be updated for each newly created node. The code
generator partly avoids this problem by querying the GENERIC API for the
information it needs about the already compiled code. This fact would
complicate leveraging the existing transformations on the HIR to HIR
level. Rustc avoids this problem by doing such transformations on the
HIR-THIR boundary and not modifying the HIR itself. Since this
modification would be complicated and would only be a preparation for
borrow-checking, it was decided not to proceed in this direction at that
time. However, we found that some transformation can be done on the
AST-HIR boundary. This approach can be done mostly independently (only
code handling the removed nodes is also removed, but no additions or
modifications are needed). It was agreed that such transformations are
useful and should be implemented regardless of the path taken by the
borrow-checker. Those transformations include mainly loops and
pattern-matching structures. Those transformations are even documented
in the rust reference{[}@reference{]}.

\begin{quote}
At the time of writing this thesis, desugaring of the for loop was
implemented by Philip Herron. More desugaring work is in progress or
planned. However, I have focused on borrow-checking itself. For the time
being, I have ignored the complex constructs, assuming that they will be
eventually desugared to constructs that the borrow-checker would already
be able handle.
\end{quote}

To ensure all possible approaches were considered, we have discussed the
possibility of implementing MIR in gccrs. This approach has some
advantages and many problems. Should the MIR be implemented in a
completely compatible way, it would be possible to use tools like
\href{https://github.com/rust-lang/miri}{MIRI} with gccrs. The
borrow-checking would be very similar to rustc's borrow-checking, and
parts of rustc's code might even be reused. Gccrs would also be more
ready for Rust-specific optimizations within the front-end. The final
advantage is that the current test suite would cover the process of
lowering HIR to MIR, as all transformations would affect the code
generation. The main problem with this approach is that it would require
a large portion of gccrs to be reimplemented, delaying the project by a
considerable amount of time. Should such an approach be taken, any
effort on borrow-checking would be delayed until the MIR is implemented.
The maintainers{[}@zulip{]} decided that such an approach is not
feasible and that gccrs will not use MIR in any foreseeable future.

After Arthur Cohen suggested keeping things simpler, I decided to
experiment with a different, minimalistic approach---to build a
radically simplified MIR-like IR that keeps only the bare minimum of
information needed for borrow-checking. Given the unexpected
productivity of this approach, it was decided to go on with it. This IR,
later called the borrow-checker IR (BIR), only focuses on the flow of
data, and it ignores the actual data transformations. The main
disadvantage of this approach is that it creates a dead branch of the
compilation pipeline that is not used for code generation, and
therefore, it is not covered by the existing test suite. To overcome
this difficulty, the BIR and its textual representation (dump) are
designed to be as similar to rustc's MIR as possible. This feature
allows us to check the generated BIR against the MIR generated by rustc,
at least for simple programs. Using BIR is the final approach used in
this work. Details of the BIR design are described in the next section.

\begin{figure}
\centering
\includesvg[width=0.35\textwidth,height=\textheight]{./bir.svg}
\caption{Placement of the borrow-checker IR in the compilation pipeline}
\end{figure}

\section{The Borrow-Checking Process}\label{the-borrow-checking-process}

Before the borrow-checking itself can be performed, specific information
about types needs to be collected when HIR is type-checked and TyTy
types are created and processed. The TyTy needs to resolve and store
information about lifetimes and their constraints. At this point,
lifetimes are resolved from string names, and their bounding clauses are
found. There are different kinds of lifetimes in the Rust language.
Inside types, the lifetimes are bound to the lifetime parameters of
generic types. In function pointers, lifetimes can be universally
quantified (meaning that the function must be memory-safe for every
possible lifetime). In function definitions, lifetimes can be elided
when all references have the same lifetime. In function bodies,
lifetimes can be bound to the lifetime parameters of the function, or
they can be omitted, in which case they are inferred \footnote{At least
  Rust semantics thinks about it that way. In reality, the compiler only
  checks that there exists some lifetime that could be used in that
  position by collecting constraints that would apply to such a lifetime
  and passing them to the borrow-checker.}. The type-checked HIR is then
transformed into the borrow-checker IR (BIR). The BIR is then processed
to extract facts for Polonius. At this phase, some errors that are easy
to detect can be emitted. The collected facts are then passed to
Polonius, which computes the results of the analysis. The results are
then passed back to the compiler, which translates them into error
messages.

\section{Representation of Lifetimes in
TyTy}\label{representation-of-lifetimes-in-tyty}

\begin{quote}
The term \emph{lifetime} is used in this work to refer to the syntactic
object in HIR and AST. In the source code it corresponds to either
explicit universal\footnote{There are two kinds of lifetimes in Rust
  semantics: universal and existential. Universal lifetimes correspond
  to code that happens outside the function. It is called universal
  because the concerned borrow-checking rules use the universal
  quantifier. That means that the function has to be valid \emph{for
  all} possible outside code that satisfies the specified (or implied)
  constraints. Existential lifetimes correspond to code that happens
  inside the function. The existential quantifier is used in the rules
  regarding existential lifetimes. That means that the code has to be
  valid \emph{for some} set of \emph{loans} (or CFG points).} lifetime
annotation (\texttt{\textquotesingle{}a}), elided universal lifetime
annotation\href{https://doc.rust-lang.org/reference/lifetime-elision.html}{{[}@reference{]}},
and local/existential\footnote{There are two kinds of lifetimes in Rust
  semantics: universal and existential. Universal lifetimes correspond
  to code that happens outside the function. It is called universal
  because the concerned borrow-checking rules use the universal
  quantifier. That means that the function has to be valid \emph{for
  all} possible outside code that satisfies the specified (or implied)
  constraints. Existential lifetimes correspond to code that happens
  inside the function. The existential quantifier is used in the rules
  regarding existential lifetimes. That means that the code has to be
  valid \emph{for some} set of \emph{loans} (or CFG points).} lifetimes,
which are always inferred. In contrast, \emph{region}/\emph{origin} is
used to refer to the semantic object. The object is in fact an inference
variable, and its value is computed by the borrow-checker. The term
\emph{region} is used by NLL to referer to a set of CFG points. Polonius
introduced the term \emph{origin} to refer to a set of \emph{loans}. In
this text and the implementation, we use the two terms interchangeably.
\end{quote}

In order to analyze more complex lifetimes than just simple references,
it was necessary to add representation of lifetime parameters to the
type system and unify it with the representation of lifetimes in the
rest of the compiler. The first step is to resolve the lifetimes and
bind them to their bounding clauses. Gccrs recognizes four kinds of
regions. In a function body, explicit lifetimes annotations result in
``named'' lifetime and implicit lifetimes annotations result in
``anonymous'' lifetimes. Within generic data types lifetimes resolved to
lifetime parameters are called ``early-bound.'' For function pointers
and traits, lifetimes can be universally quantified using the
\texttt{for} clause\footnote{\texttt{for\textless{}\textquotesingle{}a\textgreater{}\ fn(\&\textquotesingle{}a\ i32)\ -\textgreater{}\ \&\textquotesingle{}a\ i32}}.
Those lifetimes are not resolved when the definition is analyzed but
only when this type is used. Hence, the name is ``late-bound''
lifetimes. In addition, there is a representation for unresolved
lifetimes. It is used, for example, when a generic type is defined, but
the generic arguments have not been provided yet. Any occurrence of an
unresolved lifetime after type checking it to be treated as a compiler
bug.

Inside TyTy, lifetimes are represented in the following ways. Named
lifetimes are enumerated. Anonymous lifetimes are assumed to be always
distinct (but they are represented by an identical object at this
stage). Early bound lifetimes are represented by the relative position
of the lifetime parameter to which they are bound. In generic types, the
lifetime arguments are stored together with the type arguments, which
ensures their automatic propagation. One issue with this automatic
propagation is that the bindings of early bound lifetimes are updated.
That means that by a simple inspection of the body of the generic type,
one would not be able to resolve the lifetimes. A trick resolves this
problem. Each TyTy type is identified by an ID. When generic arguments
are substituted, a clone of the type with a fresh ID is created. What we
would like to achieve is to have the same state that is in rustc: the
original body and an up-to-date list of generic arguments. This can be
achieved by storing the ID of the original type in addition to the
current ID. The original ID can be used to lookup the original type when
needed.\footnote{This was once revealed to me in a dream.} The analysis
can then traverse the original type, and when a type placeholder is
encountered, the appropriate argument is looked up in the current type.

\section{Borrow-checker IR Design}\label{borrow-checker-ir-design}

The borrow-checker IR (BIR) is a three-address code representation
designed to be close to a subset of rustc MIR. Like MIR, it represents
the body of a single function (or a function-like item, e.g., a closure)
since borrow-checking is performed on each function separately. It
ignores particular operations and merges them into a few abstract
operations focusing on data flow.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{fn}\NormalTok{ fib(\_1}\OperatorTok{:} \DataTypeTok{usize}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \DataTypeTok{i32} \OperatorTok{\{}
\NormalTok{        bb0}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{            \_4 }\OperatorTok{=}\NormalTok{ Operator(\_1}\OperatorTok{,} \KeywordTok{const} \DataTypeTok{usize}\NormalTok{)}\OperatorTok{;}
\NormalTok{            switchInt(\_4) }\OperatorTok{{-}\textgreater{}}\NormalTok{ [bb1}\OperatorTok{,}\NormalTok{ bb2]}\OperatorTok{;}
        \OperatorTok{\}}

        \OperatorTok{...} 

\NormalTok{        bb6}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{            \_8 }\OperatorTok{=}\NormalTok{ Operator(\_1}\OperatorTok{,} \KeywordTok{const} \DataTypeTok{usize}\NormalTok{)}\OperatorTok{;}
\NormalTok{            \_9 }\OperatorTok{=}\NormalTok{ Call(fib)(\_8}\OperatorTok{,}\NormalTok{ ) }\OperatorTok{{-}\textgreater{}}\NormalTok{ [bb7]}\OperatorTok{;}
        \OperatorTok{\}}

\NormalTok{        bb7}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{            \_10 }\OperatorTok{=}\NormalTok{ Operator(\_7}\OperatorTok{,}\NormalTok{ \_9)}\OperatorTok{;}
\NormalTok{            \_2 }\OperatorTok{=}\NormalTok{ \_10}\OperatorTok{;}
\NormalTok{            goto }\OperatorTok{{-}\textgreater{}}\NormalTok{ bb8}\OperatorTok{;}
        \OperatorTok{\}}

\NormalTok{        bb8}\OperatorTok{:} \OperatorTok{\{}
\NormalTok{            \_0 }\OperatorTok{=}\NormalTok{ \_2}\OperatorTok{;}
            \ControlFlowTok{return}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} A shortened example of a BIR dump of a simple Rust
program. The program computes the n-th Fibonacci number. The source
code, full dump, and legend can be found in
\hyperref[appendix-c-bir-dump-example]{\emph{appendix C}}. This example
comes from the ``BIR Design Notes'' document, which is part of the
source tree and which provides an introduction to developers getting
familiar with the basic aspects of the borrow-checker implementation.
\end{quote}

The BIR of a single function is composed of basic metadata about the
function (such as arguments, return type, or explicit lifetimes), a list
of basic blocks, and a list of places.

A basic block is identified by its index in the function's basic block
list. It contains a list of BIR statements and a list of successor basic
block indices in the CFG. BIR statements are of three categories: An
assignment of an expression to a local (place), a control flow operation
(switch, return), or a special statement (not executable), which carries
additional information for the borrow-checker (explicit type
annotations, information about variable scope, etc.). BIR statements
correspond to the MIR \texttt{StatementKind} enum.

Expressions represent the executable parts of the rust code. Many
different Rust constructs are represented by a single expression. Only
data (and lifetime) flow needs to be tracked. Some expressions are
differentiated only to allow for a better debugging experience. BIR
expressions correspond to the MIR \texttt{RValue} enum.

Expressions and statements operate on places. A place is an abstract
representation of a memory location. It is either a variable, a field,
an index, or a dereference of another place. For simplicity, constants
are also represented as places. Since exact values are not important for
borrow-checking and constants are, from principle, immutable with static
storage duration, a single place can represent all constants of a single
type. Rustc MIR cannot afford this simplification, and it keeps
constants separate. The \texttt{Operand} enum is a common interface for
places and constants. However, since operations use constants and
lvalues the same way, MIR introduces a special layer of lvalues.

Places are identified by the index in the place database. The database
stores a list of places and their properties. The properties include an
identifier, used to always resolve the same variable (field, index,
etc.) to the same place, move and copy flags, type, a list of fresh
regions (lifetimes), and a relationship to other places (e.g., a field
of a struct). Temporaries are treated just like variables but are
differentiated in the place database because of place lookup. The place
database also keeps track of scopes and existing loans. The place
database structure is based on rustc
\href{https://rustc-dev-guide.rust-lang.org/borrow_check/moves_and_initialization/move_paths.html}{\texttt{MovePathData}}.
It combines the handling of places done by both MIR and borrow-checker
separately in rustc.

It is important to highlight that different fields are assigned to
different places; however, all indices are assigned to the same place
(both in gccrs and rustc). This fact has a strong impact on the strength
and complexity of the analysis; since the number of fields is static and
typically small, the size of arrays is unbound and depends on runtime
information.

\begin{quote}
\textbf{Structure of BIR Function}

\begin{itemize}
\tightlist
\item
  basic block list

  \begin{itemize}
  \tightlist
  \item
    \texttt{Statement}

    \begin{itemize}
    \tightlist
    \item
      \texttt{Assignment}

      \begin{itemize}
      \tightlist
      \item
        \texttt{InitializerExpr}
      \item
        \texttt{Operator\textless{}ARITY\textgreater{}}
      \item
        \texttt{BorrowExpr}
      \item
        \texttt{AssignmentExpr} (copy)
      \item
        \texttt{CallExpr}
      \end{itemize}
    \item
      \texttt{Switch}
    \item
      \texttt{Goto}
    \item
      \texttt{Return}
    \item
      \texttt{StorageLive} (start of variable scope)
    \item
      \texttt{StorageDead} (end of variable scope)
    \item
      \texttt{UserTypeAsscription} (explicit type annotation)
    \end{itemize}
  \end{itemize}
\item
  place database
\item
  arguments
\item
  return type
\item
  universal lifetimes
\item
  universal lifetime constraints
\end{itemize}
\end{quote}

\section{BIR Building}\label{bir-building}

The BIR is built by visiting the HIR tree of the function. There are
specialized visitors for expressions and statements, patterns, and a
top-level visitor that handles function headers (arguments, return,
lifetimes, etc.). Whenever a new place is created in the compilation
database, a list of fresh regions\footnote{In this text, we use the term
  lifetime for the syntactic object in the code and region for the
  semantic object in the analysis. It is called a region because it
  represents a set of points in the control flow graph (CFG). At this
  point, the set is not yet known. It is the main task of the
  borrow-checker analysis engine to compute the set of points for each
  region.} is created for it. At this point, we need to figure out the
number of lifetimes mentioned in a type. For basic types, this is
achieved by traversing the type and counting the number of lifetime
parameters. For generic types, the inner structure is ignored, and only
the lifetime and type parameters are considered. Note that the type
parameters can be generic, creating a structure known as
\href{https://rustc-dev-guide.rust-lang.org/what-does-early-late-bound-mean.html\#early-and-late-bound-parameter-definitions}{higher-kinded}
lifetimes. This counting is performed (as a side product) during the
variance analysis (explained below) to simplify the type traversing
code. All types are independently queried for each node from HIR (they
are not derived inside the BIR).

\begin{quote}
Example: For a BIR code that reads a field from a variable, the type is
not computed from the variable. Rather, it is queried from the HIR for
both the variable and the field.
\end{quote}

BIR building itself is fairly straightforward. However, some extra
handling was added to produce a code that is more similar to
\texttt{rustc}'s MIR. For example, instead of eagerly assigning computed
expressions to temporaries, it is checked whether the caller did not
provide a destination place. This transformation removes some of the
\texttt{\_10\ =\ \_11} statements from the BIR dump. The BIR dump also
renumbers all places to produce a closer match with the BIR dump. This
can cause some confusion during debugging because Polonius is receiving
the original place numbers. When debugging using the Polonius debug
output, the dump can be switched to show the original place numbers.

\begin{quote}
This handling was especially important when testing the initial BIR
builder since it makes the dump more similar to the MIR dump and,
therefore, easier for manual comparison.
\end{quote}

\section{BIR Fact Collection and
Checking}\label{bir-fact-collection-and-checking}

The BIR fact collection extracts the Polonius facts from the BIR and
performs additional checks. Polonius is responsible for checking
lifetime (region) constraints, moves, and conflicts between borrows. For
lifetimes, it checks that the constraints are satisfied and that all
required constraints are present in the program. For moves, it checks
that each place is moved at most once. For borrows, it checks that any
two conflicting borrows (e.g., two mutable borrows of the same place)
are not alive at the same time. Sets of conflicting borrows have to be
supplied to Polonius manually. The borrow-checker itself is responsible
for violations that are not control-flow sensitive, like modification of
an immutably borrowed place or moving from behind a reference.

The fact collection is performed in two phases. First, static facts are
collected from the place database. Those include universal region
constraints (constraints corresponding to lifetime parameters of the
function) collected during BIR construction and facts collected from the
place database. Polonius needs to know which places correspond to
variables and which form paths (see definition below). Furthermore, it
needs to sanitize fresh regions of places that are related (e.g., a
field and a parent variable) by adding appropriate constraints between
them. Relations of the region depend on the variance of the region
within the type. (See Variance Analysis below.)

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{    Path }\OperatorTok{=}\NormalTok{ Variable}
         \OperatorTok{|}\NormalTok{ Path }\StringTok{"."}\NormalTok{ Field }\CommentTok{// field access}
         \OperatorTok{|}\NormalTok{ Path }\StringTok{"["} \StringTok{"]"}   \CommentTok{// index}
         \OperatorTok{|} \StringTok{"*"}\NormalTok{ Path}
\end{Highlighting}
\end{Shaded}

Formal definition of paths from the Polonius book{[}@polonius{]}.
\end{quote}

In the second phase, the BIR is traversed along the CFG, and dynamic
facts are collected. For each statement, two CFG nodes are added. Two
nodes are needed to model the parts of semantics where the statement
takes effect immediately or after the statement is executed. For each
statement and (if present) its expression, Polonius facts are collected.
Those include generic facts related to read and write operations, as
well as facts specific to borrows and function calls. For the function,
we need to instantiate fresh regions for the function's lifetime
parameters, which need to be correctly bound together.

\subsection{Subtyping and Variance}\label{subtyping-and-variance}

In the basic interpretation of Rust language semantics (one used by
programmers to reason about their code, not the one used by the
compiler), lifetimes are part of the type and are always present. If a
lifetime is not mentioned in the program explicitly, it is inferred the
same way as a part of type would be (e.g.,
\texttt{let\ a\ =\ (\_,\ i32)\ =\ (true,\ 5);} completes the type to
\texttt{(bool,\ i32)}) Note that it is actually impossible to write
those lifetimes. In the Rust program, all explicit lifetime annotations
correspond to any borrow that happened \textbf{outside} the function,
and therefore, it is alive for the whole body of the function. Explicit
lifetime annotations corresponding to regions spanning only a part of
the function body would be pointless. Borrows inside a function can be
analysed precisely by the borrow-checker. Explicit annotations are only
used to represent constraints following from the code that the
borrow-checker cannot see.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ x}\OperatorTok{;}
    \ControlFlowTok{if}\NormalTok{ (b) }\OperatorTok{\{}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;} \CommentTok{// a: \&\textquotesingle{}a T}
    \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;} \CommentTok{// b: \&\textquotesingle{}b T}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Example:} We need to infer the type of x, such that it is a
subtype of both \texttt{\&\textquotesingle{}a\ T} and
\texttt{\&\textquotesingle{}b\ T}. We need to make sure that if we
further use x, that is safe with regard to all loans that it can contain
(here \texttt{a} or \texttt{b}).
\end{quote}

In Rust, unlike in object-oriented languages like Java or C++, the only
subtyping relation other than identity is caused by
lifetimes\footnote{During the type inference computation, there can also
  be a subtyping relation with a general kind of types (like ), which is
  mostly used for not annotated literals, where we know it is ``some
  kind'' of integer, but we do not yet know which one}. Two regions
(corresponding to lifetimes) can be either unrelated, a subset of each
other (in terms of a set of CFG nodes) (denoted
\texttt{\textquotesingle{}a:\ \textquotesingle{}b}), or equal (typically
a result of \texttt{\textquotesingle{}a:\ \textquotesingle{}b} and
\texttt{\textquotesingle{}b:\ \textquotesingle{}a}). The dependency of
subtyping on the inner parameter is called variance.

\begin{quote}
\texttt{F\textless{}T\textgreater{}} is covariant over \texttt{T} if
\texttt{T} being a subtype of \texttt{U} implies that
\texttt{F\textless{}T\textgreater{}} is a subtype of
\texttt{F\textless{}U\textgreater{}} (subtyping ``passes through'')

\texttt{F\textless{}T\textgreater{}} is contravariant over \texttt{T} if
\texttt{T} being a subtype of \texttt{U} implies that
\texttt{F\textless{}U\textgreater{}} is a subtype of F

\texttt{F\textless{}T\textgreater{}} is invariant over \texttt{T}
otherwise (no subtyping relation can be derived)

{[}@reference{]}
\end{quote}

Let us see what that means on an example specific to lifetimes. For a
simple reference type \texttt{\&\textquotesingle{}a\ T}, the lifetime
parameter \texttt{\textquotesingle{}a} is covariant. That means that if
we have a reference \texttt{\&\textquotesingle{}a\ T} we can coerce it
to \texttt{\&\textquotesingle{}b\ T}, then \texttt{\textquotesingle{}a}
is a subtype of \texttt{\textquotesingle{}b}. In other words, if we are
storing a reference to some memory, it is sound to assign it to a
reference that lives for a shorter period of time. That is, if it is
safe to dereference a reference within any point of period
\texttt{\textquotesingle{}a}, it is also safe to dereference it within
any point of period \texttt{\textquotesingle{}b},
(\texttt{\textquotesingle{}}b\texttt{is\ a\ subset\ of}'\texttt{a})
\footnote{A subset of CFG nodes.}.

The situation is different when we pass a reference to a function as an
argument. In that case, the lifetime parameter is contravariant. For
function parameters, we need to ensure that the parameter lives as long
as the function needs it to. If we have a function pointer of type
\texttt{fn\ foo\textless{}\textquotesingle{}a\textgreater{}(x:\ \&\textquotesingle{}a\ T)},
we can coerce it to
\texttt{fn\ foo\textless{}\textquotesingle{}b\textgreater{}(x:\ \&\textquotesingle{}b\ T)},
where \texttt{\textquotesingle{}b} lives longer than
\texttt{\textquotesingle{}a}. This conversion is safe because it only
restricts the possible values of the parameter \texttt{x}.

Let us look at that visually. In the following code, we have region
\texttt{\textquotesingle{}a}, where it is safe to reference the storage
of \texttt{x}, and region \texttt{\textquotesingle{}b} where it is safe
to reference the storage of \texttt{y}. If a function safely works with
a reference of lifetime \texttt{\textquotesingle{}b}, it will also
safely work with a reference of lifetime \texttt{\textquotesingle{}a}.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]

    \KeywordTok{let}\NormalTok{ x }\OperatorTok{=} \DecValTok{5}\OperatorTok{;}        \CommentTok{// region \textquotesingle{}a}
    \OperatorTok{\{}                 \CommentTok{//}
        \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \DecValTok{7}\OperatorTok{;}    \CommentTok{//            // region \textquotesingle{}b        }
    \OperatorTok{\}}                 \CommentTok{//}
\end{Highlighting}
\end{Shaded}
\end{quote}

The return type of the function is effectively an assignment to a local
variable (just across function boundaries) and, therefore, is covariant.

The situation gets interesting when the two rules are combined. Let us
have a function
\texttt{fn\ foo\textless{}\textquotesingle{}a\textgreater{}(x:\ \&\textquotesingle{}a\ T)\ -\textgreater{}\ \&\textquotesingle{}a\ T}.
The return type requires the function to be covariant over
\texttt{\textquotesingle{}a}, while the parameter requires it to be
contravariant. This is called \emph{invariance}.

For non-generic types, its variance immediately follows from the type
definition. For generic types, the situation is more complex.

\subsection{Variance of Generic Types}\label{variance-of-generic-types}

There are multiple approaches to the variance of generic types. It can
be either derived from the usage of the type or its
definition{[}@Altidor2011{]}. For non-generic types, use-site variance
is used.\footnote{For \texttt{\&\textquotesingle{}a\ T}, if the
  reference is used as a function parameter, it is contravariant; if it
  is used as a return type, it is covariant.} For generic types, Rust
uses definition-site variance. That means that the variance is computed
solely from the definition of the type (effectively, usage constraint to
the body of the type), not from its usage (inside functions). The
situation gets complicated when a generic type is used inside another
generic type, possibly even in a recursive fashion. In that situation,
the variance has to be computed using a fixed-point algorithm (further
referred to as the ``variance analysis'').

\subsubsection{Variance Analysis}\label{variance-analysis}

Both rustc and gccrs variance analysis implementation is based on
Section 4 of the paper {[}@Altidor2011{]}. Notation from the paper is
followed in the documentation of both compilers, their documentation,
and in this text. The paper primarily focuses on complex type variance,
like in the case of Java, but it introduces an effective formal
calculus, which works nicely with higher-kinded lifetimes.

The exact rules are best understood from the paper and from the code
itself. Therefore, we will only provide a simple overview here. The
analysis uses an iterative fixed-point computation, where variables form
a semi-lattice with an additional binary operation. A single variable
corresponds to a single lifetime or type parameter. Variables are
initialized as bivariant.

The visitor traverses each type with the current variance of the visited
expression as an input. Each member of a type is in a covariant
position. Each member of a function parameter is in a contravariant
position. The return type is in the covariant position. The generic
argument position is determined by the variance of the generic parameter
(a variable of this computation). The variance of the current node
within the type is computed by the \texttt{transform} function, taking
the variance of the parent node and the variance based on the position
of the current node and building and expression. When a lifetime or type
parameter is encountered, then if the current variance expression is
constant, the variable is updated to the new variance using the join
operation with the current value. For an expression containing at least
one variable, the expression is added to the list of constraints. Here,
the fixed-point computation requirement arises.

Once all types in the crate are processed, the constraints are solved
using a fixed-point computation. Note that the current crate can use
generic types from other crates, and therefore, it has to export/load
the variance of public types.

\begin{quote}
\textbf{Example of Algorithm Execution}

\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{struct}\NormalTok{ Foo}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{,} \OtherTok{\textquotesingle{}b}\OperatorTok{,}\NormalTok{ T}\OperatorTok{\textgreater{}} \OperatorTok{\{}
\NormalTok{        x}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}a}\NormalTok{ T}\OperatorTok{,}
\NormalTok{        y}\OperatorTok{:}\NormalTok{ Bar}\OperatorTok{\textless{}}\NormalTok{T}\OperatorTok{\textgreater{},}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Struct foo has three generic parameters, leading to 3 variables.
  \texttt{f0=o}, \texttt{f1=o} and \texttt{f2=o}.
\item
  \texttt{x} is processed first, in covariant position.

  \begin{itemize}
  \tightlist
  \item
    \texttt{\&\textquotesingle{}a\ T} is in covariant position,
    therefore variables are updated to \texttt{f0=+} and \texttt{f2=+}.
  \end{itemize}
\item
  \texttt{y} is processed second, in covariant position.

  \begin{itemize}
  \tightlist
  \item
    \texttt{Bar\textless{}T\textgreater{}} is in covariant position.

    \begin{itemize}
    \tightlist
    \item
      \texttt{T} is inside a generic argument, therefore, its position
      is computed as a term \texttt{transform(+,\ b0)}.

      \begin{itemize}
      \tightlist
      \item
        New constant \texttt{f2\ =\ join(f2,\ transform(+,\ b0))} is
        added.
      \end{itemize}
    \end{itemize}
  \end{itemize}
\item
  All types are processed. Let us assume that \texttt{Bar} is an
  external type with variances \texttt{{[}-{]}} Now a fixed-point
  computation is performed.

  \begin{itemize}
  \tightlist
  \item
    Iteration 1:

    \begin{itemize}
    \tightlist
    \item
      Current values are \texttt{f0=+}, \texttt{f1=o} and \texttt{f2=+}
    \item
      Processing constraint \texttt{f2\ =\ join(f2,\ transform(+,\ b0))}
    \item
      \texttt{transform(+,\ b0)} where \texttt{b0=-} yields \texttt{-}
    \item
      \texttt{join(+,\ -)} yields \texttt{*}
    \item
      \texttt{f2} is updated, therefore, another iteration is needed.
    \end{itemize}
  \item
    Iteration 2:

    \begin{itemize}
    \tightlist
    \item
      Current values are \texttt{f0=+}, \texttt{f1=o} and \texttt{f2=*}
    \item
      Processing constraint \texttt{f2\ =\ join(f2,\ transform(+,\ b0))}
    \item
      \texttt{transform(+,\ b0)} where \texttt{b0=-} yields \texttt{-}
    \item
      \texttt{join(*,\ -)} yields \texttt{*}
    \item
      \texttt{f2} is not updated, therefore, the computation is
      finished.
    \end{itemize}
  \end{itemize}
\item
  The final variance is \texttt{f0=+}, \texttt{f1=o} and \texttt{f2=*}:

  \begin{itemize}
  \tightlist
  \item
    \texttt{f0} is evident,
  \item
    \texttt{f1} stayed bivariant, because it was not mentioned in the
    type,
  \item
    \texttt{f2} is invariant, because it s is used in both covariant and
    contravariant position.
  \end{itemize}
\end{itemize}
\end{quote}

\section{Error Reporting}\label{error-reporting}

As each function is analyzed separately, the compiler can easily report
which functions violate the rules. Currently, only the kind of violation
is communicated from the Polonius engine to the compiler. More detailed
reporting is an issue for future work.

There are three possible ways the more detailed reporting could be
implemented.

The first is to pass all the violations back to the compiler to be
processed as a return value of the Polonius FFI invocation. This variant
provides a simple separation of roles between the compiler and the
analysis engine. However, it might be difficult to implement correctly
with regard to memory ownership around the FFI boundary since Polonius
would need to allocate dynamically sized memory to pass the result.
Polonius would need to implement a special API to release the memory.

The second variant is to pass a callback function for reporting the
found errors to the Polonius engine, which would be called for each
violation. However, Polonius only has information in terms of the
enumerated nodes of the control flow graph. Therefore, a pointer to an
instance of the borrow checker would need to be passed to the Polonius
engine to be used in combination with the callback to resolve the nodes
to the actual code. The separation of roles, where Polonius and Polonius
FFI are used just as external computation engines, is broken.

A compromise between these variants would be to provide Polonius with
callback functions, which would send the violations to the compiler one
by one, leaving the allocation on the compiler side only.

Moreover, the borrow-checker currently does not store information to map
the nodes back to source code locations. This issue is clearly technical
only, and the functionality can be added easily with local changes only.
Since this work has an experimental character, work on the analysis
itself was prioritized over more detailed error reporting.

The final stage of the borrow-checker development would be to implement
heuristics to guess the reason for the error and suggest possible fixes.

\chapter{Current State}\label{current-state}

\textbf{TODO}

This section describes the current state of the borrow checker. As
explained in the introduction, this work was experimental, and it
focused on exploring as many aspects of the problem as possible. Given
the complexity of the Rust language and the borrow-checking itself,
there are many parts of the borrow-borrow checker that have not been
implemented or have been implemented using a temporary solution.

This project has demonstrated the feasibility of the selected approach
and mapped the work necessary to create a production-ready solution. It
has designed the infrastructure needed to solve the problem as the
unimplemented parts are mostly technical.

\section{Kind of Detected Errors}\label{kind-of-detected-errors}

\section{Parsing}\label{parsing}

Parsing handles both explicit and implicit lifetimes correctly.

Parsing of special lifetimes (\texttt{\textquotesingle{}static} and
\texttt{\textquotesingle{}\_}) was fixed. Handling of implicit lifetimes
was added.

\section{AST to HIR Lowering}\label{ast-to-hir-lowering}

\section{Type Checking (TyTy
Representation)}\label{type-checking-tyty-representation}

The resolution of named lifetimes to their binding clauses was added.
\texttt{TyTy} types were refactored from the usage of named lifetimes to
resolved regions. Previously, the handling of lifetimes in generic types
was completely missing, and the representation of regions inside generic
types was added. Also, a mechanism to map original types to substituted
ones, preserving information about parameter position, was added.

\section{Borrow-checker Scheduling}\label{borrow-checker-scheduling}

All top-level functions which are

\section{BIR Building}\label{bir-building-1}

The BIR builder can handle

The following constructs are not handled by the BIR builder and should
be removed from HIR and desugared on the AST-\textgreater HIR boundary:
\texttt{ErrorPropagationExpr} (question mark operator),
\texttt{WhileLetExpr}. Other constructs requiring pattern matching
(\texttt{MatchExpr}, \texttt{IfLetExpr}, \texttt{IfLetConseqElse}) are
not implemented. They require pattern validation to be implemented in
BIR. Pattern destructuring is implemented except for the
\texttt{AltPattern} (not supported by the rest of the compiler). Pattern
destruction when no initial expression is provided is partly implemented
(this construct is almost useless, and therefore, it has little
priority).

\subsection{BIR Dump}\label{bir-dump}

The BIR dump can display the BIR in a fashion very similar to MIR. It
performs some transformation, like place renumbering, to produce a
result closer to MIR. Those transformations can be easily turned off in
the code. In addition to MIR, statement numbers within basic blocks is
displayed to simplify debugging. All BIR constructs are supported.

Examples of BIR dump and MIR dump of the same program can be found in
the appendix.

\section{BIR Fact Collection}\label{bir-fact-collection}

\section{Polonius FFI}\label{polonius-ffi}

Interface with Polonius is realized using C ABI implemented in gccrs and
a in a Rust crate ``ffi-polonius''

\section{Error Reporting}\label{error-reporting-1}

The borrow-checker report detected errors on the function level. It
differentiates three kinds of errors: general loan errors, which are
triggered by loan invalidations; subset errors, when insufficient
constraints are specified; and move errors, following from possible use
of uninitialized/deinitialized variables. Debug output can be used to
link the error to BIR objects.

Further work is needed to transfer violated facts from Polonius to
gccrs, translate them to source code locations, and figure out the
reasons for those errors. Rustc also sorts the errors based on the
reason priority to display only the useful ones to the user. For
example, errors on temporary variables created by the compiler have very
low priority.

\appendix

\chapter{Rustc Intermediate Representations
Examples}\label{rustc-intermediate-representations-examples}

\section{Rust source code}\label{rust-source-code}

\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{struct}\NormalTok{ Foo(i31)}\OperatorTok{;}

    \KeywordTok{fn}\NormalTok{ foo(x}\OperatorTok{:}\NormalTok{ i31) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Foo }\OperatorTok{\{}
\NormalTok{        Foo(x)}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\small

\begin{verbatim}
Fn {
    defaultness: Final,
    generics: Generics {
        params: [],
        where_clause: WhereClause {
            has_where_token: false,
            predicates: [],
            span: example.rs:3:22: 3:22 (#0),
        },
        span: example.rs:3:7: 3:7 (#0),
    },
    sig: FnSig {
        header: FnHeader { unsafety: No, asyncness: No, constness: No, ext: None },
        decl: FnDecl {
            inputs: [
                Param {
                    attrs: [],
                    ty: Ty {
                        id: NodeId(4294967040),
                        kind: Path(
                            None,
                            Path {
                                span: example.rs:3:11: 3:14 (#0),
                                segments: [
                                    PathSegment {
                                        ident: i32#0,
                                        id: NodeId(4294967040),
                                        args: None,
                                    },
                                ],
                                tokens: None,
                            },
                        ),
                        span: example.rs:3:11: 3:14 (#0),
                        tokens: None,
                    },
                    pat: Pat {
                        id: NodeId(4294967040),
                        kind: Ident(
                            BindingAnnotation(No, Not),
                            x#0,
                            None,
                        ),
                        span: example.rs:3:8: 3:9 (#0),
                        tokens: None,
                    },
                    id: NodeId(4294967040),
                    span: example.rs:3:8: 3:14 (#0),
                    is_placeholder: false,
                },
            ],
            output: Ty(
                Ty {
                    id: NodeId(4294967040),
                    kind: Path(
                        None,
                        Path {
                            span: example.rs:3:19: 3:22 (#0),
                            segments: [
                                PathSegment {
                                    ident: Foo#0,
                                    id: NodeId(4294967040),
                                    args: None,
                                },
                            ],
                            tokens: None,
                        },
                    ),
                    span: example.rs:3:19: 3:22 (#0),
                    tokens: None,
                },
            ),
        },
        span: example.rs:3:1: 3:22 (#0),
    },
    body: Some(
        Block {
            stmts: [
                Stmt {
                    id: NodeId(4294967040),
                    kind: Expr(
                        Expr {
                            id: NodeId(4294967040),
                            kind: Call(
                                Expr {
                                    id: NodeId(4294967040),
                                    kind: Path(
                                        None,
                                        Path {
                                            span: example.rs:4:5: 4:8 (#0),
                                            segments: [
                                                PathSegment {
                                                    ident: Foo#0,
                                                    id: NodeId(4294967040),
                                                    args: None,
                                                },
                                            ],
                                            tokens: None,
                                        },
                                    ),
                                    span: example.rs:4:5: 4:8 (#0),
                                    attrs: [],
                                    tokens: None,
                                },
                                [
                                    Expr {
                                        id: NodeId(4294967040),
                                        kind: Path(
                                            None,
                                            Path {
                                                span: example.rs:4:9: 4:10 (#0),
                                                segments: [
                                                    PathSegment {
                                                        ident: x#0,
                                                        id: NodeId(4294967040),
                                                        args: None,
                                                    },
                                                ],
                                                tokens: None,
                                            },
                                        ),
                                        span: example.rs:4:9: 4:10 (#0),
                                        attrs: [],
                                        tokens: None,
                                    },
                                ],
                            ),
                            span: example.rs:4:5: 4:11 (#0),
                            attrs: [],
                            tokens: None,
                        },
                    ),
                    span: example.rs:4:5: 4:11 (#0),
                },
            ],
            id: NodeId(4294967040),
            rules: Default,
            span: example.rs:3:23: 5:2 (#0),
            tokens: None,
            could_be_bare_literal: false,
        },
    ),
}
\end{verbatim}

\normalsize

\chapter{HIR Dump Example}\label{hir-dump-example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// }\AlertTok{TODO}
\end{Highlighting}
\end{Shaded}

\chapter{BIR Dump Example}\label{bir-dump-example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// }\AlertTok{TODO}
\end{Highlighting}
\end{Shaded}

\chapter{Examples of Errors Detected by the
Borrow-checker}\label{examples-of-errors-detected-by-the-borrow-checker}

A faulty program from gccrs test suite together with a fixed alternative
(when applicable) is presented. Expected errors are marked using special
comments used by the DejaGnu compiler testing framework.

\section{Move Errors}\label{move-errors}

A simple test, where an instance of type A, which is not trivially
copiable (does not implement the compy trait) is moved twice.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found move errors in function test\_move" \}}
    \KeywordTok{struct}\NormalTok{ A }\OperatorTok{\{}
\NormalTok{        i}\OperatorTok{:} \DataTypeTok{i32}\OperatorTok{,}
    \OperatorTok{\}}
    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=}\NormalTok{ A }\OperatorTok{\{}\NormalTok{ i}\OperatorTok{:} \DecValTok{1} \OperatorTok{\};}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_fixed() }\OperatorTok{\{}
    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// a is now primitive and can be copied}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

More complex text test, where moves the occurence of the error depends
on runtime values. Error is raised bacause for some values, the
violation is possible

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_conditional(b1}\OperatorTok{:} \DataTypeTok{bool}\OperatorTok{,}\NormalTok{ b2}\OperatorTok{:}\DataTypeTok{bool}\NormalTok{) }\OperatorTok{\{}
     \CommentTok{// \{ dg{-}error "Found move errors in function test\_move" \}}
    \KeywordTok{struct}\NormalTok{ A }\OperatorTok{\{}
\NormalTok{        i}\OperatorTok{:} \DataTypeTok{i32}\OperatorTok{,}
    \OperatorTok{\}}

    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=}\NormalTok{ A }\OperatorTok{\{}\NormalTok{ i}\OperatorTok{:} \DecValTok{1} \OperatorTok{\};}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if}\NormalTok{ b1 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if}\NormalTok{ b2 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ test\_move\_fixed(b1}\OperatorTok{:} \DataTypeTok{bool}\OperatorTok{,}\NormalTok{ b2}\OperatorTok{:}\DataTypeTok{bool}\NormalTok{) }\OperatorTok{\{}

    \KeywordTok{let}\NormalTok{ a }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// a is now primitive and can be copied}
    \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if}\NormalTok{ b1 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ b }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if}\NormalTok{ b2 }\OperatorTok{\{}
        \KeywordTok{let}\NormalTok{ c }\OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\section{Subset Errors}\label{subset-errors}

TODO

\section{Loan Error}\label{loan-error}

TODO

The following test were used when Polonius was first experimentally
integrated into rustc.

In this test \texttt{s} is moved while it is borrowed. The test checks
that facts are corectly propagated through the function call.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn}\NormalTok{ foo}\OperatorTok{\textless{}}\OtherTok{\textquotesingle{}a}\OperatorTok{,} \OtherTok{\textquotesingle{}b}\OperatorTok{\textgreater{}}\NormalTok{(p}\OperatorTok{:} \OperatorTok{\&}\OtherTok{\textquotesingle{}b} \OperatorTok{\&}\OtherTok{\textquotesingle{}a} \KeywordTok{mut} \DataTypeTok{usize}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \OperatorTok{\&}\OtherTok{\textquotesingle{}b}\OperatorTok{\&}\OtherTok{\textquotesingle{}a} \KeywordTok{mut} \DataTypeTok{usize} \OperatorTok{\{}
\NormalTok{    p}
\OperatorTok{\}}

\KeywordTok{fn}\NormalTok{ well\_formed\_function\_inputs() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found loan errors in function well\_formed...}
    \KeywordTok{let}\NormalTok{ s }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \DecValTok{1}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ r }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \OperatorTok{*}\NormalTok{s}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ foo(}\OperatorTok{\&}\NormalTok{r  )}\OperatorTok{;}
\NormalTok{    s}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
\NormalTok{    tmp}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

This test check that variable cannot be used while borrowed.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ use\_while\_mut() }\OperatorTok{\{}
    \CommentTok{// \{ dg{-}error "Found loan errors in function use\_while\_mut" \}}
    \KeywordTok{let} \KeywordTok{mut}\NormalTok{ x }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut}\NormalTok{ x}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ z }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
    \KeywordTok{let}\NormalTok{ w }\OperatorTok{=}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

This test is similar to the previous one but uses a reborrow of a
reference passed as an argument.

\begin{quote}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn}\NormalTok{ use\_while\_mut\_fr(x}\OperatorTok{:} \OperatorTok{\&}\KeywordTok{mut} \DataTypeTok{i32}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \OperatorTok{\&}\KeywordTok{mut} \DataTypeTok{i32} \OperatorTok{\{} 
    \CommentTok{// \{ dg{-}error "Found loan errors in function use\_while\_mut\_fr" \}}
    \KeywordTok{let}\NormalTok{ y }\OperatorTok{=} \OperatorTok{\&}\KeywordTok{mut} \OperatorTok{*}\NormalTok{x}\OperatorTok{;}
    \KeywordTok{let}\NormalTok{ z }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \CommentTok{//\textasciitilde{} ERROR}
\NormalTok{    y}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
\end{quote}

\chapter{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\bibitem[\citeproctext]{ref-nsa}
\CSLLeftMargin{1. }%
\CSLRightInline{\emph{{{``Software Memory Safety''}} {C}ybersecurity
{I}nformation {S}heet}. The National Security Agency, 2022. }

\bibitem[\citeproctext]{ref-danglingpointer}
\CSLLeftMargin{2. }%
\CSLRightInline{MITRE. \emph{CWE-416: Use after free}.
\url{https://cwe.mitre.org/data/definitions/416.html}. }

\bibitem[\citeproctext]{ref-reference}
\CSLLeftMargin{3. }%
\CSLRightInline{\emph{The rust reference}. rust-lang.org, 2023. }%
\CSLRightInline{\url{https://doc.rust-lang.org/reference/}}

\bibitem[\citeproctext]{ref-rfc2094nll}
\CSLLeftMargin{4. }%
\CSLRightInline{MATSAKIS, Niko. 2094-nll. In~: \emph{The rust RFC book}.
\url{https://rust-lang.github.io/rfcs/2094-nll.html}, 2017. }

\bibitem[\citeproctext]{ref-Stjerna2020}
\CSLLeftMargin{5. }%
\CSLRightInline{STJERNA, Albin. \emph{Modelling rust's reference
ownership analysis declaratively in datalog}. Online. Master's thesis.
Uppsala University, 2020. Available from:
\url{https://www.diva-portal.org/smash/get/diva2:1684081/FULLTEXT01.pdf}}

\bibitem[\citeproctext]{ref-polonius2}
\CSLLeftMargin{6. }%
\CSLRightInline{\emph{{P}olonius revisited, part 1 \&\#x{B}7; baby steps
--- smallcultfollowing.com}.
\url{https://smallcultfollowing.com/babysteps/blog/2023/09/22/polonius-part-1/}.
}%
\CSLRightInline{{[}Accessed 19-12-2023{]}}

\bibitem[\citeproctext]{ref-polonius}
\CSLLeftMargin{7. }%
\CSLRightInline{MATSAKIS, Niko, RAKIC, R√©my and OTHERS. \emph{The
polonius book}. rust-lang.org, 2021. }

\bibitem[\citeproctext]{ref-llvm}
\CSLLeftMargin{8. }%
\CSLRightInline{\emph{Reference}.
\url{https://llvm.org/docs/Reference.html}. LLVM Project, 2023. }

\bibitem[\citeproctext]{ref-gccint}
\CSLLeftMargin{9. }%
\CSLRightInline{STALLMAN, Richard M. and GCC DEVELOPER COMMUNITY, the.
\emph{GNU compiler collection internals}. Free Software Foundation,
2023. }

\bibitem[\citeproctext]{ref-devguide}
\CSLLeftMargin{10. }%
\CSLRightInline{\emph{{R}ust {C}ompiler {D}evelopment {G}uide}.
rust-lang.org; \url{https://rustc-dev-guide.rust-lang.org/index.html},
{[}no date{]}. }

\bibitem[\citeproctext]{ref-zulip}
\CSLLeftMargin{11. }%
\CSLRightInline{\url{https://gcc-rust.zulipchat.com/\#narrow/stream/281658-compiler-development/topic/Borrowchecking.20vs.20.28H.29IR}.
}

\bibitem[\citeproctext]{ref-Altidor2011}
\CSLLeftMargin{12. }%
\CSLRightInline{ALTIDOR, John, HUANG, Shan Shan and SMARAGDAKIS, Yannis.
Taming the wildcards: Combining definition- and use-site variance.
\emph{ACM SIGPLAN Notices}. June 2011. Vol.~46, no.~6, p.~602--613.
DOI~\href{https://doi.org/10.1145/1993316.1993569}{10.1145/1993316.1993569}.
}

\end{CSLReferences}

\end{document}
